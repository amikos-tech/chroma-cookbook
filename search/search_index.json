{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ChromaDB Cookbook","text":"<p>This is a collection of small guides and recipes to help you get started with ChromaDB.</p> <p>Critical Fix in 0.5.13</p> <p>If you are using Chroma <code>&gt;=0.5.7</code> and <code>&lt;=0.5.13</code> please upgrade to <code>0.5.13+</code> or later as there is a critical bug that can cause data loss. Read more on the GH Issue #2922.</p> <p>Latest ChromaDB version: 0.6.3</p>"},{"location":"#new-and-noteworthy","title":"New and Noteworthy","text":"<ul> <li>\ud83d\udd04 Chroma Maintenance - Learn how to keep your Chroma database in tip-top shape - \ud83d\udcc5<code>08-Feb-2025</code></li> <li>\u2692\ufe0f Configuration - Updated descriptions and added examples of Chroma configuration options - \ud83d\udcc5<code>21-Nov-2024</code></li> <li>\ud83c\udfce\ufe0f Performance Tips - Learn how to optimize the performance of yourChroma - \ud83d\udcc5<code>16-Oct-2024</code></li> <li>\u2049\ufe0fFAQs - Updated FAQ sections - \ud83d\udcc5<code>15-Oct-2024</code></li> <li>\ud83d\udd25 SSL-Terminating Proxies - Learn how to secure Chroma server with <code>Envoy</code> or <code>Nginx</code> proxies - \ud83d\udcc5<code>31-Jul-2024</code></li> <li>\ud83d\uddd1\ufe0f WAL Pruning - Learn how to prune (cleanup) your Chroma database (WAL) with Chroma's built-in CLI <code>vacuum</code> command - \ud83d\udcc5<code>30-Jul-2024</code></li> <li>\u2728 Multi-Category Filtering - Learn how to filter data based on multiple categories - \ud83d\udcc5<code>15-Jul-2024</code></li> <li>\ud83d\udd12 Chroma Auth - Learn how to secure your Chroma deployment with Authentication - \ud83d\udcc5<code>11-Jul-2024</code></li> <li>\ud83d\udce6 Async Http Client - Chroma now supports async HTTP clients - \ud83d\udcc5<code>19-Jun-2024</code></li> <li>\ud83d\udd12 Security - Learn how to secure your Chroma deployment - \ud83d\udcc5<code>13-Jun-2024</code></li> <li>\ud83d\udd27 Installation - Learn about the different ways to install Chroma - \ud83d\udcc5<code>08-Jun-2024</code></li> <li>\ud83e\udde0 Memory Management - Learn how to manage memory in ChromaDB - \ud83d\udcc5<code>30-May-2024</code></li> <li>\ud83d\udcd0 Resource Requirements - Recently updated with temporary storage requirements - \ud83d\udcc5<code>28-May-2024</code></li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>We suggest you first head to the Concepts section to get familiar with ChromaDB concepts, such as Documents, Metadata, Embeddings, etc.</p> <p>Once you're comfortable with the concepts, you can jump to the Installation section to install ChromaDB.</p> <p>Core Topics:</p> <ul> <li>Filters - Learn to filter data in ChromaDB using metadata and document filters</li> <li>Resource Requirements - Understand the resource requirements for running ChromaDB</li> <li>\u2728Multi-Tenancy - Learn how to implement multi-tenancy in ChromaDB</li> </ul>"},{"location":"#running-chromadb","title":"Running ChromaDB","text":"<ul> <li>CLI - Running ChromaDB via the CLI</li> <li>Docker - Running ChromaDB in Docker</li> <li>Docker Compose - Running ChromaDB in Docker Compose</li> <li>Kubernetes - Running ChromaDB in Kubernetes (Minikube)</li> </ul>"},{"location":"#integrations","title":"Integrations","text":"<ul> <li>\u2728LangChain - Integrating ChromaDB with LangChain</li> <li>\u2728LlamaIndex - Integrating ChromaDB with LlamaIndex</li> <li>\u2728Ollama - Integrating ChromaDB with Ollama</li> </ul>"},{"location":"#the-ecosystem","title":"The Ecosystem","text":""},{"location":"#clients","title":"Clients","text":"<p>Below is a list of available clients for ChromaDB.</p> <ul> <li>Python Client (Official Chroma client)</li> <li>JavaScript Client (Official Chroma client)</li> <li>Ruby Client (Community maintained)</li> <li>Java Client (Community maintained)</li> <li>Go Client (Community maintained)</li> <li>C# Client (Microsoft maintained)</li> <li>Rust Client (Community maintained)</li> <li>Elixir Client (Community maintained)</li> <li>Dart Client (Community maintained)</li> <li>PHP Client (Community maintained)</li> <li>PHP (Laravel) Client (Community maintained)</li> </ul>"},{"location":"#user-interfaces","title":"User Interfaces","text":"<ul> <li>VectorAdmin (MintPlex Labs) - An open-source web-based admin   interface for vector databases, including ChromaDB</li> <li>ChromaDB UI (Community maintained) - A web-based UI for ChromaDB</li> </ul>"},{"location":"#cli-tooling","title":"CLI Tooling","text":"<ul> <li>Chroma CLI (Community maintained) - Early Alpha</li> <li>Chroma Data Pipes (Community maintained) - A CLI tool for   importing and exporting data from ChromaDB</li> <li>Chroma Ops (Community maintained) - A maintenance CLI tool for ChromaDB</li> </ul>"},{"location":"#strategies","title":"Strategies","text":"<ul> <li>Backup - Backing up ChromaDB data</li> <li>Batch Imports - Importing data in batches</li> <li>Multi-Tenancy - Running multiple ChromaDB instances</li> <li>Keyword Search - Searching for keywords in ChromaDB</li> <li>Memory Management - Managing memory in ChromaDB</li> <li>Time-based Queries - Querying data based on timestamps</li> <li>\u2728 <code>Coming Soon</code> Testing with Chroma - learn how to test your GenAI apps that include Chroma.</li> <li>\u2728 <code>Coming Soon</code> Monitoring Chroma - learn how to monitor your Chroma instance.</li> <li>\u2728 <code>Coming Soon</code> Building Chroma clients - learn how to build clients for Chroma.</li> <li>\u2728 <code>Coming Soon</code> Creating the perfect Embedding Function (wrapper) - learn the best practices for creating your own   embedding function.</li> <li>\u2728 Multi-User Basic Auth Plugin - learn how to build a multi-user   basic authentication plugin for Chroma.</li> <li>\u2728 CORS Configuration For JS Browser apps - learn how to configure CORS for Chroma.</li> <li>\u2728 Running Chroma with SystemD - learn how to start Chroma upon system boot.</li> </ul>"},{"location":"#get-help","title":"Get Help","text":"<p>Missing something? Let us know by opening an issue, reach out on Discord (look for <code>@taz</code>).</p>"},{"location":"contributing/getting-started/","title":"Getting Started with Contributing to Chroma","text":""},{"location":"contributing/getting-started/#overview","title":"Overview","text":"<p>Here are some steps to follow:</p> <ul> <li>Fork the repository (if you are part of an organization to which you cannot grant permissions it might be advisable to fork under your own user account to allow other community members to contribute by granting them permissions, something that is a bit more difficult at organizational level)</li> <li>Clone your forked repo locally (git clone ...) under a dir with an apt name for the change you want to make e.g. <code>my_awesome_feature</code></li> <li>Create a branch for your change (git checkout -b my_awesome_feature)</li> <li>Make your changes</li> <li>Test (see Testing)</li> <li>Lint (see Linting)</li> <li>Commit your changes (git commit -am 'Added some feature')</li> <li>Push to the branch (git push origin my_awesome_feature)</li> <li>Create a new Pull Request (PR) from your forked repository to the main Chroma repository</li> </ul>"},{"location":"contributing/getting-started/#testing","title":"Testing","text":"<p>It is generally good to test your changes before submitting a PR.</p> <p>To run the full test suite:</p> <pre><code>pip install -r requirements_dev.txt\npytest\n</code></pre> <p>To run a specific test:</p> <pre><code>pytest chromadb/tests/test_api.py::test_get_collection\n</code></pre> <p>If you want to see the output of print statements in the tests, you can run:</p> <pre><code>pytest -s\n</code></pre> <p>If you want your pytest to stop on first failure, you can run:</p> <pre><code>pytest -x\n</code></pre>"},{"location":"contributing/getting-started/#integration-tests","title":"Integration Tests","text":"<p>You can only run the integration tests by running:</p> <pre><code>sh bin/bin/integration-test\n</code></pre> <p>The above will create a docker container and will run the integration tests against it. This will also include JS client.</p>"},{"location":"contributing/getting-started/#linting","title":"Linting","text":""},{"location":"contributing/useful-shortcuts/","title":"Useful Shortcuts for Contributors","text":""},{"location":"contributing/useful-shortcuts/#git","title":"Git","text":""},{"location":"contributing/useful-shortcuts/#aliases","title":"Aliases","text":""},{"location":"contributing/useful-shortcuts/#create-venv-and-install-dependencies","title":"Create venv and install dependencies","text":"<p>Add the following to your <code>.bashrc</code>, <code>.zshrc</code> or <code>.profile</code>:</p> <pre><code>alias chroma-init='python -m virtualenv venv &amp;&amp; source venv/bin/activate &amp;&amp; pip install -r requirements.txt &amp;&amp; pip install -r requirements_dev.txt'\n</code></pre>"},{"location":"core/api/","title":"Chroma API","text":"<p>In this article we will cover the Chroma API in an indepth details.</p>"},{"location":"core/api/#accessing-the-api","title":"Accessing the API","text":"<p>If you are running a Chroma server you can access its API at - <code>http://&lt;chroma_server_host&gt;:&lt;chroma_server_port&gt;/docs</code> ( e.g. <code>http://localhost:8000/docs</code>).</p>"},{"location":"core/api/#api-endpoints","title":"API Endpoints","text":"<p>TBD</p>"},{"location":"core/api/#generating-clients","title":"Generating Clients","text":"<p>While Chroma ecosystem has client implementations for many languages, it may be the case you want to roll out your own. Below we explain some of the options available to you:</p>"},{"location":"core/api/#using-openapi-generator","title":"Using OpenAPI Generator","text":"<p>The fastest way to build a client is to use the OpenAPI Generator the API spec.</p>"},{"location":"core/api/#manually-creating-a-client","title":"Manually Creating a Client","text":"<p>If you more control over things, you can create your own client by using the API spec as guideline.</p> <p>For your convenience we provide some data structures in various languages to help you get started. The important structures are:</p> <ul> <li>Client</li> <li>Collection</li> <li>Embedding</li> <li>Document</li> <li>ID</li> <li>Metadata</li> <li>QueryRequest/QueryResponse</li> <li>Include</li> <li>Where Filter</li> <li>WhereDocument Filter</li> </ul>"},{"location":"core/api/#python","title":"Python","text":""},{"location":"core/api/#typescript","title":"Typescript","text":""},{"location":"core/api/#golang","title":"Golang","text":""},{"location":"core/api/#java","title":"Java","text":""},{"location":"core/api/#rust","title":"Rust","text":""},{"location":"core/api/#elixir","title":"Elixir","text":""},{"location":"core/clients/","title":"Chroma Clients","text":"<p>Chroma Settings Object</p> <p>The below is only a partial list of Chroma configuration options. For full list check the code <code>chromadb.config.Settings</code> or the ChromaDB Configuration page.</p>"},{"location":"core/clients/#persistent-client","title":"Persistent Client","text":"<p>To create your a local persistent client use the <code>PersistentClient</code> class. This client will store all data locally in a directory on your machine at the path you specify.</p> <p>Authentication</p> <p>For authentication details see the Chroma-native Authentication section.</p> <pre><code>import chromadb\nfrom chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n\nclient = chromadb.PersistentClient(\n    path=\"test\",\n    settings=Settings(),\n    tenant=DEFAULT_TENANT,\n    database=DEFAULT_DATABASE,\n)\n</code></pre> <p>Parameters:</p> <ol> <li><code>path</code> - parameter must be a local path on the machine where Chroma is running. If the path does not exist, it will    be created. The path can be relative or absolute. If the path is not specified, the default is <code>./chroma</code> in the    current working directory.</li> <li><code>settings</code> - Chroma settings object.</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code> - the database to use. Default is <code>default_database</code>.</li> </ol> <p>Positional Parameters</p> <p>Chroma <code>PersistentClient</code> parameters are positional, unless keyword arguments are used.</p>"},{"location":"core/clients/#uses-of-persistent-client","title":"Uses of Persistent Client","text":"<p>The persistent client is useful for:</p> <ul> <li>Local development: You can use the persistent client to develop locally and test out ChromaDB.</li> <li>Embedded applications: You can use the persistent client to embed ChromaDB in your application. This means that   you can ship Chroma bundled with your product or services, thus simplifying the deployment process.</li> <li>Simplicity: If you do not wish to incur the complexities associated with setting up and operating a Chroma   server (arguably Hosted-Chroma will resolve this).</li> <li>Data privacy: If you are working with sensitive data and do not want to store it on a remote server.</li> <li>Optimize performance: If you want to reduce latency.</li> </ul> <p>The right tool for the job</p> <p>When evaluating the use of local <code>PersistentClient</code> one should always factor in the scale of the application.  Similar to SQLite vs Posgres/MySQL, <code>PersistentClient</code> vs <code>HTTPClient</code> with Chroma server, application architectural characteristics (such as complexity, scale, performance etc) should be considered when deciding to use one or the other.</p>"},{"location":"core/clients/#http-client","title":"HTTP Client","text":"<p>Chroma also provides HTTP Client, suitable for use in a client-server mode. This client can be used to connect to a remote ChromaDB server. The HTTP client can operate in synchronous or asynchronous mode (see examples below).</p> <p>Authentication</p> <p>For authentication details see the Chroma-native Authentication section.</p> Python SyncPython AsyncJavaScriptGoLang <pre><code>import chromadb\nfrom chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n\nclient = chromadb.HttpClient(\n    host=\"localhost\",\n    port=8000,\n    ssl=False,\n    headers=None,\n    settings=Settings(),\n    tenant=DEFAULT_TENANT,\n    database=DEFAULT_DATABASE,\n)\n</code></pre> <p>Parameters:</p> <ol> <li><code>host</code> - The host of the remote server. If not specified, the default is <code>localhost</code>.</li> <li><code>port</code> - The port of the remote server. If not specified, the default is <code>8000</code>.</li> <li><code>ssl</code> - If <code>True</code>, the client will use HTTPS. If not specified, the default is <code>False</code>.</li> <li><code>headers</code> - (optional): The headers to be sent to the server. The setting can be used to pass additional headers to the     server. An example of this can be auth headers.</li> <li><code>settings</code> - Chroma settings object.</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code> - the database to use. Default is <code>default_database</code>.</li> </ol> <p>Positional Parameters</p> <p>Chroma <code>HttpClient</code> parameters are positional, unless keyword arguments are used.</p> <pre><code>import asyncio\nimport chromadb\n# Apply nest_asyncio to allow running nested event loops in jupyter notebook\n# import nest_asyncio # import this if running in jupyter notebook\n# nest_asyncio.apply() # apply this if running in jupyter notebook\nasync def list_collections():\nclient = await chromadb.AsyncHttpClient(\n    host=\"localhost\",\n    port=8000,\n    ssl=False,\n    headers=None,\n    settings=Settings(),\n    tenant=DEFAULT_TENANT,\n    database=DEFAULT_DATABASE,\n)\nreturn await client.list_collections()\n\nresult = asyncio.get_event_loop().run_until_complete(list_collections())\nprint(result)\n</code></pre> <p>Parameters:</p> <ol> <li><code>host</code> - The host of the remote server. If not specified, the default is <code>localhost</code>.</li> <li><code>port</code> - The port of the remote server. If not specified, the default is <code>8000</code>.</li> <li><code>ssl</code> - If <code>True</code>, the client will use HTTPS. If not specified, the default is <code>False</code>.</li> <li><code>headers</code> - (optional): The headers to be sent to the server. The setting can be used to pass additional headers to the     server. An example of this can be auth headers.</li> <li><code>settings</code> - Chroma settings object.</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code> - the database to use. Default is <code>default_database</code>.</li> </ol> <p>Positional Parameters</p> <p>Chroma <code>AsyncHttpClient</code> parameters are positional, unless keyword arguments are used.</p> <pre><code>import {ChromaClient}  from \"chromadb\";\nconst client = new ChromaClient({\n    path: \"http://localhost:8000\",\n    auth: {\n        provider: \"token\",\n        credentials: \"your_token_here\",\n        tokenHeaderType: \"AUTHORIZATION\",\n    },\n    tenant: \"default_tenant\",\n    database: \"default_database\",\n});\n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code> - The Chroma endpoint</li> <li><code>auth</code> - Chroma authentication object</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code> - the database to use. Default is <code>default_database</code>.</li> </ul> <p><pre><code>go get github.com/amikos-tech/chroma-go\n</code></pre> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"os\"\n\n    chroma \"github.com/amikos-tech/chroma-go\"\n    \"github.com/amikos-tech/chroma-go/collection\"\n    openai \"github.com/amikos-tech/chroma-go/pkg/embeddings/openai\"\n    \"github.com/amikos-tech/chroma-go/types\"\n)\n\nfunc main() {\n    // Create new OpenAI embedding function\n\n    openaiEf, err := openai.NewOpenAIEmbeddingFunction(os.Getenv(\"OPENAI_API_KEY\"))\n    if err != nil {\n        log.Fatalf(\"Error creating OpenAI embedding function: %s \\n\", err)\n    }\n    // Create a new Chroma client\n    client := chroma.NewClient(\n        \"localhost:8000\",\n        chroma.WithTenant(types.DefaultTenant),\n        chroma.WithDatabase(types.DefaultDatabase),\n        chroma.WithAuth(types.NewTokenAuthCredentialsProvider(\"my-token\", types.AuthorizationTokenHeader))\n    )\n\n    // Create a new collection with options\n    newCollection, err := client.NewCollection(\n        context.TODO(),\n        \"test-collection\",\n        collection.WithMetadata(\"key1\", \"value1\"),\n        collection.WithEmbeddingFunction(openaiEf),\n        collection.WithHNSWDistanceFunction(types.L2),\n    )\n    if err != nil {\n        log.Fatalf(\"Error creating collection: %s \\n\", err)\n    }\n}\n</code></pre> Parameters:</p> <ul> <li>Chroma endpoint - the chroma endpoint URL e.g. <code>http://localhost:8000</code>. This is a required parameter.</li> <li><code>WithAuth()</code> - Chroma authentication provider (see more here).</li> <li><code>WithTenant()</code> - the tenant to use. Default is <code>default_tenant</code> or constant <code>types.DefaultTenant</code>.</li> <li><code>WithDatabase()</code> - the database to use. Default is <code>default_database</code> or constant <code>types.DefaultDatabase</code>.</li> </ul>"},{"location":"core/clients/#uses-of-http-client","title":"Uses of HTTP Client","text":"<p>The HTTP client is ideal for when you want to scale your application or move off of local machine storage. It is important to note that there are trade-offs associated with using HTTP client:</p> <ul> <li>Network latency - The time it takes to send a request to the server and receive a response.</li> <li>Serialization and deserialization overhead - The time it takes to convert data to a format that can be sent over the   network and then convert it back to its original format.</li> <li>Security - The data is sent over the network, so it is important to ensure that the connection is secure (we recommend   using both HTTPS and authentication).</li> <li>Availability - The server must be available for the client to connect to it.</li> <li>Bandwidth usage - The amount of data sent over the network.</li> <li>Data privacy and compliance - Storing data on a remote server may require compliance with data protection laws and   regulations.</li> <li>Difficulty in debugging - Debugging network issues can be more difficult than debugging local issues. The same applies   to server-side issues.</li> </ul>"},{"location":"core/clients/#host-parameter-special-cases-python-only","title":"Host parameter special cases (Python-only)","text":"<p>The <code>host</code> parameter supports a more advanced syntax than just the hostname. You can specify the whole endpoint ULR ( without the API paths), e.g. <code>https://chromadb.example.com:8000/my_server/path/</code>. This is useful when you want to use a reverse proxy or load balancer in front of your ChromaDB server.</p>"},{"location":"core/clients/#ephemeral-client","title":"Ephemeral Client","text":"<p>Ephemeral client is a client that does not store any data on disk. It is useful for fast prototyping and testing. To get started with an ephemeral client, use the <code>EphemeralClient</code> class.</p> <pre><code>import chromadb\nfrom chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n\nclient = chromadb.EphemeralClient(\n    settings=Settings(),\n    tenant=DEFAULT_TENANT,\n    database=DEFAULT_DATABASE,\n)\n</code></pre> <p>Parameters:</p> <ol> <li><code>settings</code> - Chroma settings object.</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code>  - the database to use. Default is <code>default_database</code>.</li> </ol> <p>Positional Parameters</p> <p>Chroma <code>PersistentClient</code> parameters are positional, unless keyword arguments are used.</p>"},{"location":"core/clients/#environmental-variable-configured-client","title":"Environmental Variable Configured Client","text":"<p>You can also configure the client using environmental variables. This is useful when you want to configure any of the client configurations listed above via environmental variables.</p> <pre><code>import chromadb\nfrom chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n\nclient = chromadb.Client(\n    settings=Settings(),\n    tenant=DEFAULT_TENANT,\n    database=DEFAULT_DATABASE,\n)\n</code></pre> <p>Parameters:</p> <ol> <li><code>settings</code> - Chroma settings object.</li> <li><code>tenant</code> - the tenant to use. Default is <code>default_tenant</code>.</li> <li><code>database</code> - the database to use. Default is <code>default_database</code>.</li> </ol> <p>Positional Parameters</p> <p>Chroma <code>PersistentClient</code> parameters are positional, unless keyword arguments are used.</p>"},{"location":"core/collections/","title":"Collections","text":"<p>Collections are the grouping mechanism for embeddings, documents, and metadata.</p>"},{"location":"core/collections/#collection-basics","title":"Collection Basics","text":""},{"location":"core/collections/#collection-properties","title":"Collection Properties","text":"<p>Each collection is characterized by the following properties:</p> <ul> <li><code>name</code>: The name of the collection. The name can be changed as long as it is unique within the database (   use <code>collection.modify(name=\"new_name\")</code> to change the name of the collection</li> <li><code>metadata</code>: A dictionary of metadata associated with the collection. The metadata is a dictionary of key-value pairs.   Keys can be strings, values can be strings, integers, floats, or booleans. Metadata can be changed   using <code>collection.modify(metadata={\"key\": \"value\"})</code> (Note: Metadata is always overwritten when modified)</li> <li><code>embedding_function</code>: The embedding function used to embed documents in the collection.</li> </ul> <p>Defaults:</p> <ul> <li>Embedding Function - by default if <code>embedding_function</code> parameter is not provided at <code>get()</code> or <code>create_collection()</code>   or <code>get_or_create_collection()</code> time, Chroma uses <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> which   uses the <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> to embed documents. The default embedding   function uses Onnx Runtime   with <code>all-MiniLM-L6-v2</code> model.</li> <li>distance metric - by default Chroma use L2 (Euclidean Distance Squared) distance metric for newly created collection.   You can change it at creation   time using <code>hnsw:space</code> metadata key. Possible values are <code>l2</code>, <code>cosine</code>, and 'ip' (inner product). (Note: <code>cosine</code> value returns <code>cosine distance</code> rather then <code>cosine similarity</code>. Ie. values close to 0 means the embeddings are more similar.)</li> <li>Batch size, defined by <code>hnsw:batch_size</code> metadata key. Default is 100. The batch size defines the size of the   in-memory bruteforce index. Once the threshold is reached, vectors are added to the HNSW index and the bruteforce   index is cleared. Greater values may improve ingest performance. When updating also consider changing sync threshold</li> <li>Sync threshold, defined by <code>hnsw:sync_threshold</code> metadata key. Default 1000. The sync threshold defines the limit at   which the HNSW index is synced to disk. This limit only applies to newly added vectors.</li> </ul> <p>Keep in Mind</p> <p>Collection distance metric cannot be changed after the collection is created.  To change the distance metric see #cloning-a-collection</p> <p>Name Restrictions</p> <p>Collection names in Chroma must adhere to the following restrictions:</p> <p>(1) contains 3-63 characters (2) starts and ends with an alphanumeric character (3) otherwise contains only alphanumeric characters, underscores or hyphens (-) (4) contains no two consecutive periods (..) (5) is not a valid IPv4 address</p>"},{"location":"core/collections/#creating-a-collection","title":"Creating a collection","text":"<p>Official Docs</p> <p>For more information on the <code>create_collection</code> or <code>get_or_create_collection</code> methods, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to create. Parameter is required N/A String <code>metadata</code> Metadata associated with the collection. This is an optional parameter <code>None</code> Dictionary <code>embedding_function</code> Embedding function to use for the collection. This is an optional parameter <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> EmbeddingFunction <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.create_collection(\"test\")\n</code></pre> <p>Alternatively you can use the <code>get_or_create_collection</code> method to create a collection if it doesn't exist already.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\", metadata={\"key\": \"value\"})\n</code></pre> <p>Metadata with <code>get_or_create_collection()</code></p> <p>If the collection exists and metadata is provided in the method it will attempt to overwrite the existing metadata. This behaviour may be fixed by this GH issue</p>"},{"location":"core/collections/#deleting-a-collection","title":"Deleting a collection","text":"<p>Official Docs</p> <p>For more information on the <code>delete_collection</code> method, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to delete. Parameter is required N/A String <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\nclient.delete_collection(\"test\")\n</code></pre>"},{"location":"core/collections/#listing-all-collections","title":"Listing all collections","text":"<p>Official Docs</p> <p>For more information on the <code>list_collections</code> method, see the official ChromaDB documentation.</p> <p>Breaking Change in 0.6.0</p> <p>In ChromaDB 0.6.0, the <code>list_collections</code> method was updated to return a list of collection names (<code>Sequence[CollectionName]</code> where <code>CollectionName</code> is a string) instead of collection objects.</p> <p>Parameters:</p> Name Description Default Value Type <code>offset</code> The starting offset for listing collections. This is an optional parameter <code>None</code> Positive Integer <code>limit</code> The number of collections to return. If the remaining collections from <code>offset</code> are fewer than this number then returned collection will also be fewer. This is an optional parameter <code>None</code> Positive Integer <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncollections = client.list_collections() # in &lt;0.6.0 returns the list of collection objects, in &gt;=0.6.0 returns the list of collection names\n</code></pre>"},{"location":"core/collections/#getting-a-collection","title":"Getting a collection","text":"<p>Official Docs</p> <p>For more information on the <code>get_collection</code> method, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to get. Parameter is required N/A String <code>embedding_function</code> Embedding function to use for the collection. This is an optional parameter <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> EmbeddingFunction <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_collection(\"test\")\n</code></pre>"},{"location":"core/collections/#modifying-a-collection","title":"Modifying a collection","text":"<p>Official Docs</p> <p>For more information on the <code>modify</code> method, see the official ChromaDB documentation.</p> <p>Modify method on collection</p> <p>As the reader will observe <code>modify</code> method is called on the collection and node on the client as the rest of the collection lifecycle methods.</p> <p>Metadata Overwrite</p> <p>Metadata is always overwritten when modified. If you want to add a new key-value pair to the metadata, you must first get the existing metadata and then add the new key-value pair to it.</p> <p>Changin HNSW parameters</p> <p>While as of current version (<code>0.6.3</code>) you can create a collection and supply HNSW parameters in the metadata, it is not possible to change the HNSW parameters after initial creation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> The new name of the collection. Parameter is required N/A String <code>metadata</code> Metadata associated with the collection. This is an optional parameter <code>None</code> Dictionary <p>Both collection properties (<code>name</code> and <code>metadata</code>) can be modified, separately ot together.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_collection(\"test\")\ncol.modify(name=\"test2\", metadata={\"key\": \"value\"})\n</code></pre>"},{"location":"core/collections/#counting-collections","title":"Counting Collections","text":"<p>Returns the number of collections for the currently configured tenant and database.</p> <p>Official Docs</p> <p>For more information on the <code>count_collections</code> method, see the official ChromaDB documentation.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection\n\ncollections_count = client.count_collections() # int\n</code></pre>"},{"location":"core/collections/#iterating-over-a-collection","title":"Iterating over a Collection","text":"<pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")  # or HttpClient()\n\ncollection = client.get_or_create_collection(\"local_collection\")\ncollection.add(\n    ids=[f\"{i}\" for i in range(1000)],\n    documents=[f\"document {i}\" for i in range(1000)],\n    metadatas=[{\"doc_id\": i} for i in range(1000)])\nexisting_count = collection.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = collection.get(\n        include=[\"metadatas\", \"documents\", \"embeddings\"],\n        limit=batch_size,\n        offset=i)\n    print(batch)  # do something with the batch\n</code></pre>"},{"location":"core/collections/#collection-utilities","title":"Collection Utilities","text":""},{"location":"core/collections/#copying-collections","title":"Copying Collections","text":"Local To RemoteLocal To Local <p>The following example demonstrates how to copy a local collection to a remote ChromaDB server. (it also works in reverse)</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")\nremote_client = chromadb.HttpClient()\n\ncollection = client.get_or_create_collection(\"local_collection\")\ncollection.add(\n    ids=[\"1\", \"2\"],\n    documents=[\"hello world\", \"hello ChromaDB\"],\n    metadatas=[{\"a\": 1}, {\"b\": 2}])\nremote_collection = remote_client.get_or_create_collection(\"remote_collection\",\n                                                           metadata=collection.metadata)\nexisting_count = collection.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = collection.get(\n        include=[\"metadatas\", \"documents\", \"embeddings\"],\n        limit=batch_size,\n        offset=i)\n    remote_collection.add(\n        ids=batch[\"ids\"],\n        documents=batch[\"documents\"],\n        metadatas=batch[\"metadatas\"],\n        embeddings=batch[\"embeddings\"])\n</code></pre> <p>Using ChromaDB Data Pipes</p> <p>Using ChromaDB Data Pipes package you can achieve the same result.</p> <pre><code>pip install chromadb-data-pipes\ncdp export \"file://path/to_local_data/local_collection\" | \\\ncdp import \"http://remote_chromadb:port/remote_collection\" --create\n</code></pre> <p>Following shows an example of how to copy a collection from one local persistent DB to another local persistent DB.</p> <pre><code>import chromadb\n\nlocal_client = chromadb.PersistentClient(path=\"source\")\nremote_client = chromadb.PersistentClient(path=\"target\")\n\ncollection = local_client.get_or_create_collection(\"my_source_collection\")\ncollection.add(\n    ids=[\"1\", \"2\"],\n    documents=[\"hello world\", \"hello ChromaDB\"],\n    metadatas=[{\"a\": 1}, {\"b\": 2}])\nremote_collection = remote_client.get_or_create_collection(\"my_target_collection\",\n                                                           metadata=collection.metadata)\nexisting_count = collection.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = collection.get(\n        include=[\"metadatas\", \"documents\", \"embeddings\"],\n        limit=batch_size,\n        offset=i)\n    remote_collection.add(\n        ids=batch[\"ids\"],\n        documents=batch[\"documents\"],\n        metadatas=batch[\"metadatas\"],\n        embeddings=batch[\"embeddings\"])\n</code></pre> <p>Using ChromaDB Data Pipes</p> <p>You can achieve the above with ChromaDB Data Pipes package.</p> <pre><code>pip install chromadb-data-pipes\ncdp export \"file://source_persist_dir/target_collection\" | \\\ncdp import \"file://target_persist_dir/target_collection\" --create\n</code></pre>"},{"location":"core/collections/#cloning-a-collection","title":"Cloning a collection","text":"<p>Here are some reasons why you might want to clone a collection:</p> <ul> <li>Change distance function (via metadata - <code>hnsw:space</code>)</li> <li>Change HNSW hyper parameters (<code>hnsw:M</code>, <code>hnsw:construction_ef</code>, <code>hnsw:search_ef</code>)</li> </ul> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection with L2 (default)\n\ncol.add(ids=[f\"{i}\" for i in range(1000)], documents=[f\"document {i}\" for i in range(1000)])\nnewCol = client.get_or_create_collection(\"test1\", metadata={\n    \"hnsw:space\": \"cosine\"})  # let's change the distance function to cosine\n\nexisting_count = col.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = col.get(include=[\"metadatas\", \"documents\", \"embeddings\"], limit=batch_size, offset=i)\n    newCol.add(ids=batch[\"ids\"], documents=batch[\"documents\"], metadatas=batch[\"metadatas\"],\n               embeddings=batch[\"embeddings\"])\n\nprint(newCol.count())\nprint(newCol.get(offset=0, limit=10))  # get first 10 documents\n</code></pre>"},{"location":"core/collections/#changing-the-embedding-function","title":"Changing the embedding function","text":"<p>To change the embedding function of a collection, it must be cloned to a new collection with the desired embedding function.</p> <pre><code>import os\nimport chromadb\nfrom chromadb.utils.embedding_functions import OpenAIEmbeddingFunction, DefaultEmbeddingFunction\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ndefault_ef = DefaultEmbeddingFunction()\ncol = client.create_collection(\"default_ef_collection\",embedding_function=default_ef)\nopenai_ef = OpenAIEmbeddingFunction(api_key=os.getenv(\"OPENAI_API_KEY\"), model_name=\"text-embedding-3-small\")\ncol.add(ids=[f\"{i}\" for i in range(1000)], documents=[f\"document {i}\" for i in range(1000)])\nnewCol = client.get_or_create_collection(\"openai_ef_collection\", embedding_function=openai_ef)\n\nexisting_count = col.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = col.get(include=[\"metadatas\", \"documents\"], limit=batch_size, offset=i)\n    newCol.add(ids=batch[\"ids\"], documents=batch[\"documents\"], metadatas=batch[\"metadatas\"])\n# get first 10 documents with their OpenAI embeddings\nprint(newCol.get(offset=0, limit=10,include=[\"metadatas\", \"documents\", \"embeddings\"])) \n</code></pre>"},{"location":"core/collections/#cloning-a-subset-of-a-collection-with-query","title":"Cloning a subset of a collection with query","text":"<p>The below example demonstrates how to select a slice of an existing collection by using <code>where</code> and <code>where_document</code> query and creating a new collection with the selected slice.</p> <p>Race Condition</p> <p>The below example is not atomic and if data is changed between the initial selection query (<code>select_ids = col.get(...)</code> and the subsequent insertion query (<code>batch = col.get(...)</code>) the new collection may not contain the expected data.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection with L2 (default)\n\ncol.add(ids=[f\"{i}\" for i in range(1000)], documents=[f\"document {i}\" for i in range(1000)])\nnewCol = client.get_or_create_collection(\"test1\", metadata={\n    \"hnsw:space\": \"cosine\", \"hnsw:M\": 32})  # let's change the distance function to cosine and M to 32\nquery_where = {\"metadata_key\": \"value\"}\nquery_where_document = {\"$contains\": \"document\"}\nselect_ids = col.get(where_document=query_where_document, where=query_where, include=[])  # get only IDs\nbatch_size = 10\nfor i in range(0, len(select_ids[\"ids\"]), batch_size):\n    batch = col.get(include=[\"metadatas\", \"documents\", \"embeddings\"], limit=batch_size, offset=i, where=query_where,\n                    where_document=query_where_document)\n    newCol.add(ids=batch[\"ids\"], documents=batch[\"documents\"], metadatas=batch[\"metadatas\"],\n               embeddings=batch[\"embeddings\"])\n\nprint(newCol.count())\nprint(newCol.get(offset=0, limit=10))  # get first 10 documents\n</code></pre>"},{"location":"core/collections/#updating-documentrecord-metadata","title":"Updating Document/Record Metadata","text":"<p>In this example we loop through all documents of a collection and strip all metadata fields of leading and trailing whitespace. Change the <code>update_metadata</code> function to suit your needs.</p> <pre><code>from chromadb import Settings\nimport chromadb\n\nclient = chromadb.PersistentClient(path=\"test\", settings=Settings(allow_reset=True))\nclient.reset()  # reset the database so we can run this script multiple times\ncol = client.get_or_create_collection(\"test\")\ncount = col.count()\n\n\ndef update_metadata(metadata: dict):\n    return {k: v.strip() for k, v in metadata.items()}\n\n\nfor i in range(0, count, 10):\n    batch = col.get(include=[\"metadatas\"], limit=10, offset=i)\n    col.update(ids=batch[\"ids\"], metadatas=[update_metadata(metadata) for metadata in batch[\"metadatas\"]])\n</code></pre>"},{"location":"core/collections/#tips-and-tricks","title":"Tips and Tricks","text":""},{"location":"core/collections/#getting-ids-only","title":"Getting IDs Only","text":"<p>The below example demonstrates how to get only the IDs of a collection. This is useful if you need to work with IDs without the need to fetch any additional data. Chroma will accept and empty <code>include</code> array indicating that no other data than the IDs is returned.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")\ncol = client.get_or_create_collection(\"my_collection\")\nids_only_result = col.get(include=[])\nprint(ids_only_result['ids'])\n</code></pre>"},{"location":"core/concepts/","title":"Concepts","text":""},{"location":"core/concepts/#tenancy-and-db-hierarchies","title":"Tenancy and DB Hierarchies","text":"<p>The following picture illustrates the tenancy and DB hierarchy in Chroma:</p> <p></p> <p>Storage</p> <p>In Chroma single-node, all data about tenancy, databases, collections and documents is stored in a single SQLite database.</p>"},{"location":"core/concepts/#tenants","title":"Tenants","text":"<p>A tenant is a logical grouping for a set of databases. A tenant is designed to model a single organization or user. A tenant can have multiple databases.</p>"},{"location":"core/concepts/#databases","title":"Databases","text":"<p>A database is a logical grouping for a set of collections. A database is designed to model a single application or project. A database can have multiple collections.</p>"},{"location":"core/concepts/#collections","title":"Collections","text":"<p>Collections are the grouping mechanism for embeddings, documents, and metadata.</p>"},{"location":"core/concepts/#documents","title":"Documents","text":"<p>Chunks of text</p> <p>Documents in ChromaDB lingo are chunks of text that fits within the embedding model's context window.  Unlike other frameworks that use the term \"document\" to mean a file,  ChromaDB uses the term \"document\" to mean a chunk of text.</p> <p>Documents are raw chunks of text that are associated with an embedding. Documents are stored in the database and can be queried for.</p>"},{"location":"core/concepts/#metadata","title":"Metadata","text":"<p>Metadata is a dictionary of key-value pairs that can be associated with an embedding. Metadata is stored in the database and can be queried for.</p> <p>Metadata values can be of the following types:</p> <ul> <li>strings</li> <li>integers</li> <li>floats (float32)</li> <li>booleans</li> </ul>"},{"location":"core/concepts/#embedding-function","title":"Embedding Function","text":"<p>Also referred to as embedding model, embedding functions in ChromaDB are wrappers that expose a consistent interface for generating embedding vectors from documents or text queries.</p> <p>For a list of supported embedding functions see Chroma's official documentation.</p>"},{"location":"core/concepts/#distance-function","title":"Distance Function","text":"<p>Distance functions help in calculating the difference (distance) between two embedding vectors. ChromaDB supports the following distance functions:</p> <ul> <li>Cosine - Useful for text similarity</li> <li>Euclidean (L2) - Useful for text similarity, more sensitive to noise than <code>cosine</code></li> <li>Inner Product (IP) - Recommender systems</li> </ul>"},{"location":"core/concepts/#embedding-model","title":"Embedding Model","text":""},{"location":"core/concepts/#embeddings","title":"Embeddings","text":"<p>A representation of a document in the embedding model's latent space in te form of a vector, list of 32-bit floats (or ints).</p>"},{"location":"core/concepts/#metadata-segment","title":"Metadata Segment","text":"<p>The metadata segment holds both the documents and their respective metadata fields (if any). The metadata segment is stored in sqlite3 under <code>&lt;persistent_dir&gt;/chroma.sqlite3</code>.</p>"},{"location":"core/concepts/#vector-segment","title":"Vector Segment","text":"<p>Segment or Index?</p> <p>In the below paragraphs we use, the terms \"segment\" and \"index\" are used interchangeably.</p> <p>Under the hood Chroma uses its own fork HNSW lib for indexing and searching vectors.</p> <p>In a single-node mode, Chroma will create a single vector index for each collection. The index is stored in a UUID-named subdir in your persistent dir, named after the vector segment of the collection.</p> <p>The HNSW lib uses fast ANN algo to search the vectors in the index.</p> <p>In addition to the HNSW index, Chroma uses Brute Force index to buffer embeddings in memory before they are added to the HNSW index (see <code>batch_size</code>). As the name suggests the search in the Brute Force index is done by iterating over all the vectors in the index and comparing them to the query using the distance_function. Brute Force index search is exhaustive and works well on small datasets.</p>"},{"location":"core/configuration/","title":"Configuration","text":"<p>Work in Progress</p> <p>This page is a work in progress and may not be complete.</p>"},{"location":"core/configuration/#common-configurations-options","title":"Common Configurations Options","text":""},{"location":"core/configuration/#server-configuration","title":"Server Configuration","text":""},{"location":"core/configuration/#core","title":"Core","text":""},{"location":"core/configuration/#is_persistent","title":"<code>IS_PERSISTENT</code>","text":"<p>Defines whether Chroma should persist data or not.</p> <p>Possible values:</p> <ul> <li><code>TRUE</code></li> <li><code>FALSE</code></li> </ul> <p>Default: <code>FALSE</code></p> <p>How to use:</p> CLIPythonDocker <pre><code>export IS_PERSISTENT=TRUE\nchroma run --path ./chroma\n</code></pre> <pre><code>from chromadb.config import Settings\nsettings = Settings(is_persistent=True)\n# run the server with the settings\n</code></pre> <pre><code>docker run -d --rm --name chromadb -v ./chroma:/chroma/chroma -e IS_PERSISTENT=TRUE chromadb/chroma:0.6.3\n</code></pre>"},{"location":"core/configuration/#persist_directory","title":"<code>PERSIST_DIRECTORY</code>","text":"<p>Defines the directory where Chroma should persist data. This can be relative or absolute path. The directory must be writeable to Chroma process.</p> <p>Default: <code>./chroma</code></p>"},{"location":"core/configuration/#allow_reset","title":"<code>ALLOW_RESET</code>","text":"<p>Defines whether Chroma should allow resetting the index (delete all data).</p> <p>Possible values:</p> <ul> <li><code>TRUE</code></li> <li><code>FALSE</code></li> </ul> <p>Default: <code>FALSE</code></p>"},{"location":"core/configuration/#chroma_memory_limit_bytes","title":"<code>CHROMA_MEMORY_LIMIT_BYTES</code>","text":""},{"location":"core/configuration/#chroma_segment_cache_policy","title":"<code>CHROMA_SEGMENT_CACHE_POLICY</code>","text":""},{"location":"core/configuration/#telemetry-and-observability","title":"Telemetry and Observability","text":"<p>In the current Chroma version (as of time or writing <code>0.6.3</code>) the only type of telemetry supported are traces.</p> <p>The following configuration options allow you to configure the tracing service that accepts OpenTelemetry traces via the OLTP GRPC endpoint.</p> <p>In addition to traces Chroma also performs anonymized product telemetry. The product telemetry is enabled by default.</p>"},{"location":"core/configuration/#chroma_otel_collection_endpoint","title":"<code>CHROMA_OTEL_COLLECTION_ENDPOINT</code>","text":"<p>Defines the endpoint of the tracing service that accepts OpenTelemetry traces via the OLTP GRPC endpoint.</p> <p>Value type: <code>Valid URL</code></p> <p>Default: None</p> <p>Example:</p> <pre><code>export CHROMA_OTEL_COLLECTION_ENDPOINT=http://localhost:4317\n</code></pre>"},{"location":"core/configuration/#chroma_otel_service_name","title":"<code>CHROMA_OTEL_SERVICE_NAME</code>","text":"<p>Defines the name of the service that will be used in the tracing service.</p> <p>Default: <code>chroma</code></p> <p>Example:</p> <pre><code>export CHROMA_OTEL_SERVICE_NAME=chroma-dev\n</code></pre>"},{"location":"core/configuration/#chroma_otel_collection_headers","title":"<code>CHROMA_OTEL_COLLECTION_HEADERS</code>","text":"<p>Defines the headers that will be sent with each trace/span.</p> <p>Default: None</p> <p>Example:</p> <pre><code>export CHROMA_OTEL_COLLECTION_HEADERS='{\"X-API-KEY\":\"1234567890\"}'\n</code></pre>"},{"location":"core/configuration/#chroma_otel_granularity","title":"<code>CHROMA_OTEL_GRANULARITY</code>","text":"<p>Defines the granularity of the traces.</p> <p>Possible values:</p> <ul> <li><code>none</code> - No spans are emitted.</li> <li><code>operation</code> - Spans are emitted for each operation.</li> <li><code>operation_and_segment</code> - Spans are emitted for almost all method calls.</li> <li><code>all</code> - Spans are emitted for almost all method calls.</li> </ul> <p>Default: <code>none</code></p> <p>Example:</p> <pre><code>export CHROMA_OTEL_GRANULARITY=all\n</code></pre>"},{"location":"core/configuration/#chroma_product_telemetry_impl","title":"<code>CHROMA_PRODUCT_TELEMETRY_IMPL</code>","text":"<p>Do not change</p> <p>Do not change the default implementation as it may impact Chroma stability, instead use the <code>ANONYMIZED_TELEMETRY</code> configuration.</p> <p>Defines the implementation of the product telemetry.</p> <p>Default: <code>chromadb.telemetry.product.posthog.Posthog</code></p>"},{"location":"core/configuration/#chroma_telemetry_impl","title":"<code>CHROMA_TELEMETRY_IMPL</code>","text":"<p>This is identical to <code>CHROMA_PRODUCT_TELEMETRY_IMPL</code> but for the anonymized telemetry but is kept for backwards compatibility.</p>"},{"location":"core/configuration/#anonymized_telemetry","title":"<code>ANONYMIZED_TELEMETRY</code>","text":"<p>Enables or disables anonymized product telemetry.</p> <p>Possible values:</p> <ul> <li><code>TRUE</code> - Enables anonymized telemetry.</li> <li><code>FALSE</code> - Disables anonymized telemetry.</li> </ul> <p>Default: <code>TRUE</code> (enabled)</p> <p>Read more about how Chroma uses telemetry here.</p> <p>Example:</p> <pre><code>export ANONYMIZED_TELEMETRY=FALSE\n</code></pre>"},{"location":"core/configuration/#maintenance","title":"Maintenance","text":""},{"location":"core/configuration/#migrations","title":"<code>MIGRATIONS</code>","text":"<p>Defines how schema migrations are handled in Chroma.</p> <p>Possible values:</p> <ul> <li><code>none</code> - No migrations are applied.</li> <li><code>validate</code> - Existing schema is validated.</li> <li><code>apply</code> - Migrations are applied.</li> </ul> <p>Default: <code>apply</code></p>"},{"location":"core/configuration/#migrations_hash_algorithm","title":"<code>MIGRATIONS_HASH_ALGORITHM</code>","text":"<p>Defines the algorithm used to hash the migrations. This configuration was introduces as some organizations have strict policies around use of cryptographic algorithms, considering the default <code>md5</code> being a weak hashing algorithm.</p> <p>Possible values:</p> <ul> <li><code>sha256</code> - Uses SHA-256 to hash the migrations.</li> <li><code>md5</code> - Uses MD5 to hash the migrations.</li> </ul> <p>Default: <code>md5</code></p> <p>Example:</p> <pre><code>export MIGRATIONS_HASH_ALGORITHM=sha256\n</code></pre>"},{"location":"core/configuration/#operations-and-distributed","title":"Operations and Distributed","text":""},{"location":"core/configuration/#chroma_sysdb_impl","title":"<code>CHROMA_SYSDB_IMPL</code>","text":""},{"location":"core/configuration/#chroma_producer_impl","title":"<code>CHROMA_PRODUCER_IMPL</code>","text":""},{"location":"core/configuration/#chroma_consumer_impl","title":"<code>CHROMA_CONSUMER_IMPL</code>","text":""},{"location":"core/configuration/#chroma_segment_manager_impl","title":"<code>CHROMA_SEGMENT_MANAGER_IMPL</code>","text":""},{"location":"core/configuration/#chroma_segment_directory_impl","title":"<code>CHROMA_SEGMENT_DIRECTORY_IMPL</code>","text":""},{"location":"core/configuration/#chroma_memberlist_provider_impl","title":"<code>CHROMA_MEMBERLIST_PROVIDER_IMPL</code>","text":""},{"location":"core/configuration/#worker_memberlist_name","title":"<code>WORKER_MEMBERLIST_NAME</code>","text":""},{"location":"core/configuration/#chroma_coordinator_host","title":"<code>CHROMA_COORDINATOR_HOST</code>","text":""},{"location":"core/configuration/#chroma_server_grpc_port","title":"<code>CHROMA_SERVER_GRPC_PORT</code>","text":""},{"location":"core/configuration/#chroma_logservice_host","title":"<code>CHROMA_LOGSERVICE_HOST</code>","text":""},{"location":"core/configuration/#chroma_logservice_port","title":"<code>CHROMA_LOGSERVICE_PORT</code>","text":""},{"location":"core/configuration/#chroma_quota_provider_impl","title":"<code>CHROMA_QUOTA_PROVIDER_IMPL</code>","text":""},{"location":"core/configuration/#chroma_rate_limiting_provider_impl","title":"<code>CHROMA_RATE_LIMITING_PROVIDER_IMPL</code>","text":""},{"location":"core/configuration/#authentication","title":"Authentication","text":""},{"location":"core/configuration/#chroma_auth_token_transport_header","title":"<code>CHROMA_AUTH_TOKEN_TRANSPORT_HEADER</code>","text":""},{"location":"core/configuration/#chroma_client_auth_provider","title":"<code>CHROMA_CLIENT_AUTH_PROVIDER</code>","text":""},{"location":"core/configuration/#chroma_client_auth_credentials","title":"<code>CHROMA_CLIENT_AUTH_CREDENTIALS</code>","text":""},{"location":"core/configuration/#chroma_server_auth_ignore_paths","title":"<code>CHROMA_SERVER_AUTH_IGNORE_PATHS</code>","text":""},{"location":"core/configuration/#chroma_overwrite_singleton_tenant_database_access_from_auth","title":"<code>CHROMA_OVERWRITE_SINGLETON_TENANT_DATABASE_ACCESS_FROM_AUTH</code>","text":""},{"location":"core/configuration/#chroma_server_authn_provider","title":"<code>CHROMA_SERVER_AUTHN_PROVIDER</code>","text":""},{"location":"core/configuration/#chroma_server_authn_credentials","title":"<code>CHROMA_SERVER_AUTHN_CREDENTIALS</code>","text":""},{"location":"core/configuration/#chroma_server_authn_credentials_file","title":"<code>CHROMA_SERVER_AUTHN_CREDENTIALS_FILE</code>","text":""},{"location":"core/configuration/#authorization","title":"Authorization","text":""},{"location":"core/configuration/#chroma_server_authz_provider","title":"<code>CHROMA_SERVER_AUTHZ_PROVIDER</code>","text":""},{"location":"core/configuration/#chroma_server_authz_config","title":"<code>CHROMA_SERVER_AUTHZ_CONFIG</code>","text":""},{"location":"core/configuration/#chroma_server_authz_config_file","title":"<code>CHROMA_SERVER_AUTHZ_CONFIG_FILE</code>","text":""},{"location":"core/configuration/#client-configuration","title":"Client Configuration","text":""},{"location":"core/configuration/#authentication_1","title":"Authentication","text":""},{"location":"core/configuration/#hnsw-configuration","title":"HNSW Configuration","text":"<p>HNSW is the underlying library for Chroma vector indexing and search. Chroma exposes a number of parameters to configure HNSW for your use case. All HNSW parameters are configured as metadata for a collection.</p> <p>Changing HNSW parameters</p> <p>Some HNSW parameters cannot be changed after index creation via the standard method shown below.  If you which to change these parameters, you will need to clone the collection see an example here.</p>"},{"location":"core/configuration/#hnswspace","title":"<code>hnsw:space</code>","text":"<p>Description: Controls the distance metric of the HNSW index. The space cannot be changed after index creation.</p> <p>Default: <code>l2</code></p> <p>Constraints:</p> <ul> <li>Possible values: <code>l2</code>, <code>cosine</code>, <code>ip</code></li> <li>Parameter cannot be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>res = client.create_collection(\"my_collection\", metadata={ \"hnsw:space\": \"cosine\"})\n</code></pre>"},{"location":"core/configuration/#hnswconstruction_ef","title":"<code>hnsw:construction_ef</code>","text":"<p>Description: Controls the number of neighbours in the HNSW graph to explore when adding new vectors. The more neighbours HNSW explores the better and more exhaustive the results will be. Increasing the value will also increase memory consumption.</p> <p>Default: <code>100</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter cannot be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:construction_ef\": 100}\n)\n</code></pre>"},{"location":"core/configuration/#hnswm","title":"<code>hnsw:M</code>","text":"<p>Description: Controls the maximum number of neighbour connections (M), a newly inserted vector. A higher value results in a mode densely connected graph. The impact on this is slower but more accurate searches with increased memory consumption.</p> <p>Default: <code>16</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter cannot be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:M\": 16}\n)\n</code></pre>"},{"location":"core/configuration/#hnswsearch_ef","title":"<code>hnsw:search_ef</code>","text":"<p>Description: Controls the number of neighbours in the HNSW graph to explore when searching. Increasing this requires more memory for the HNSW algo to explore the nodes during knn search.</p> <p>Default: <code>10</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter can be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:search_ef\": 10}\n)\n</code></pre>"},{"location":"core/configuration/#hnswnum_threads","title":"<code>hnsw:num_threads</code>","text":"<p>Description: Controls how many threads HNSW algo use.</p> <p>Default: <code>&lt;number of CPU cores&gt;</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter can be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:num_threads\": 4}\n)\n</code></pre>"},{"location":"core/configuration/#hnswresize_factor","title":"<code>hnsw:resize_factor</code>","text":"<p>Description: Controls the rate of growth of the graph (e.g. how many node capacity will be added) whenever the current graph capacity is reached.</p> <p>Default: <code>1.2</code></p> <p>Constraints:</p> <ul> <li>Values must be positive floating point numbers.</li> <li>Parameter can be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:resize_factor\": 1.2}\n)\n</code></pre>"},{"location":"core/configuration/#hnswbatch_size","title":"<code>hnsw:batch_size</code>","text":"<p>Description: Controls the size of the Bruteforce (in-memory) index. Once this threshold is crossed vectors from BF gets transferred to HNSW index. This value can be changed after index creation. The value must be less than <code>hnsw:sync_threshold</code>.</p> <p>Default: <code>100</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter can be changed after index creation.</li> </ul> <p>Example:</p> <pre><code>client.create_collection(\n    \"my_collection\", \n    metadata={ \"hnsw:batch_size\": 100}\n)\n</code></pre>"},{"location":"core/configuration/#hnswsync_threshold","title":"<code>hnsw:sync_threshold</code>","text":"<p>Description: Controls the threshold when using HNSW index is written to disk.</p> <p>Default: <code>1000</code></p> <p>Constraints:</p> <ul> <li>Values must be positive integers.</li> <li>Parameter can be changed after index creation.</li> </ul>"},{"location":"core/configuration/#examples","title":"Examples","text":"<p>Configuring HNSW parameters at creation time</p> <pre><code>import chromadb\n\nclient = chromadb.HttpClient()  # Adjust as per your client\nclient.create_collection(\n    \"my_collection\", \n    metadata={\n        \"hnsw:space\": \"cosine\",\n        \"hnsw:construction_ef\": 100,\n        \"hnsw:M\": 16,\n        \"hnsw:search_ef\": 10,\n        \"hnsw:num_threads\": 4,\n        \"hnsw:resize_factor\": 1.2,\n        \"hnsw:batch_size\": 100,\n        \"hnsw:sync_threshold\": 1000,\n    }\n)\n</code></pre> <p>Updating HNSW parameters after creation</p> <p>Updating HNSW parameters</p> <p>Updating HNSW parameters after index creation is not supported as of version <code>0.5.5</code>.</p>"},{"location":"core/document-ids/","title":"Document IDs","text":"<p>Chroma is unopinionated about document IDs and delegates those decisions to the user. This frees users to build semantics around their IDs.</p>"},{"location":"core/document-ids/#note-on-compound-ids","title":"Note on Compound IDs","text":"<p>While you can choose to use IDs that are composed of multiple sub-IDs (e.g. <code>user_id</code> + <code>document_id</code>), it is important to highlight that Chroma does not support querying by partial ID.</p>"},{"location":"core/document-ids/#common-practices","title":"Common Practices","text":"chromadbx <p>We provide a convinient wrapper for in the form of <code>chromadbx</code> package that provides ID generators for UUIDs, ULIDs,  NonoIDs, and Hashes, among others functions.  You can install it with <code>pip install chromadbx</code>.</p>"},{"location":"core/document-ids/#uuids","title":"UUIDs","text":"<p>UUIDs are a common choice for document IDs. They are unique, and can be generated in a distributed fashion. They are also opaque, which means that they do not contain any information about the document itself. This can be a good thing, as it allows you to change the document without changing the ID.</p> chromadbxPython <pre><code>import chromadb\nfrom chromadbx import UUIDGenerator\n\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=UUIDGenerator(len(my_docs)), documents=my_docs)\n</code></pre> <pre><code>import uuid\nimport chromadb\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\ncollection = client.get_or_create_collection(\"collection\")\ncollection.add(ids=[f\"{uuid.uuid4()}\" for _ in range(len(my_documents))], documents=my_documents)\n</code></pre>"},{"location":"core/document-ids/#caveats","title":"Caveats","text":"<p>Predictable Ordering</p> <p>UUIDs especially v4 are not lexicographically sortable. In its current version (0.4.x-0.5.10) Chroma orders responses  of <code>get()</code> by the ID of the documents. Therefore, if you need predictable ordering, you may want to consider a different ID strategy. In version <code>0.5.11</code> ordering is done on internal IDs</p> <p>Storage and Performance Overhead</p> <p>Chroma stores Document IDs as strings and UUIDs are 36 characters long, which can be a lot of overhead if you have a  large number of documents. If you are concerned  about storage overhead, you may want to consider a different ID strategy. Additionally Chroma uses the document IDs when sorting results which also incurs a performance hit.</p>"},{"location":"core/document-ids/#ulids","title":"ULIDs","text":"<p>ULIDs are a variant of UUIDs that are lexicographically sortable. They are also 128 bits long, like UUIDs, but they are encoded in a way that makes them sortable. This can be useful if you need predictable ordering of your documents.</p> <p>ULIDs are also shorter than UUIDs, which can save you some storage space. They are also opaque, like UUIDs, which means that they do not contain any information about the document itself.</p> <p>Install the <code>ulid-py</code> package to generate ULIDs.</p> <pre><code>pip install ulid-py\n</code></pre> chromadbxPython <pre><code>import chromadb\nfrom chromadbx import ULIDGenerator\nimport ulid\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=ULIDGenerator(len(my_docs)), documents=my_docs)\n</code></pre> <pre><code>from ulid import ULID\nimport chromadb\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n_ulid = ULID()\n\nclient = chromadb.Client()\n\ncollection = client.get_or_create_collection(\"name\")\n\ncollection.add(ids=[f\"{_ulid.generate()}\" for _ in range(len(my_documents))], documents=my_documents)\n</code></pre>"},{"location":"core/document-ids/#nanoids","title":"NanoIDs","text":"<p>NanoIDs provide a way to generate unique IDs that are shorter than UUIDs. They are not lexically sortable, but they are unique and can be generated in a distributed fashion. They are also opaque, with low collision rates - (collision probability calculator)[https://zelark.github.io/nano-id-cc/]</p> chromadbxPython <pre><code>import chromadb\nfrom chromadbx import NanoIDGenerator\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=NanoIDGenerator(len(my_docs)), documents=my_docs)\n</code></pre> <pre><code>from nanoid import generate\nimport chromadb\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=[f\"{generate()}\" for _ in range(my_docs)], documents=my_docs)\n</code></pre>"},{"location":"core/document-ids/#hashes","title":"Hashes","text":"<p>Hashes are another common choice for document IDs. They are unique, and can be generated in a distributed fashion. They are also opaque, which means that they do not contain any information about the document itself. This can be a good thing, as it allows you to change the document without changing the ID.</p> chromadbxPython <p>Random SHA256:</p> <pre><code>import chromadb\nfrom chromadbx import RandomSHA256Generator\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=RandomSHA256Generator(len(my_docs)), documents=my_docs)\n</code></pre> <p>Document-based SHA256:</p> <pre><code>import chromadb\nfrom chromadbx import DocumentSHA256Generator\nclient = chromadb.Client()\ncol = client.get_or_create_collection(\"test\")\nmy_docs = [f\"Document {_}\" for _ in range(10)]\ncol.add(ids=DocumentSHA256Generator(documents=my_docs), documents=my_docs)\n</code></pre> <p>Random SHA256:</p> <pre><code>import hashlib\nimport os\nimport chromadb\n\n\ndef generate_sha256_hash() -&gt; str:\n    # Generate a random number\n    random_data = os.urandom(16)\n    # Create a SHA256 hash object\n    sha256_hash = hashlib.sha256()\n    # Update the hash object with the random data\n    sha256_hash.update(random_data)\n    # Return the hexadecimal representation of the hash\n    return sha256_hash.hexdigest()\n\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\ncollection = client.get_or_create_collection(\"collection\")\ncollection.add(ids=[generate_sha256_hash() for _ in range(len(my_documents))], documents=my_documents)\n</code></pre> <p>Document-based SHA256:</p> <p>It is also possible to use the document as basis for the hash, the downside of that is that when the document changes, and you have a semantic around the text as relating to the hash, you may need to update the hash.</p> <pre><code>import hashlib\nimport chromadb\n\n\ndef generate_sha256_hash_from_text(text) -&gt; str:\n    # Create a SHA256 hash object\n    sha256_hash = hashlib.sha256()\n    # Update the hash object with the text encoded to bytes\n    sha256_hash.update(text.encode('utf-8'))\n    # Return the hexadecimal representation of the hash\n    return sha256_hash.hexdigest()\n\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\ncollection = client.get_or_create_collection(\"collection\")\ncollection.add(ids=[generate_sha256_hash_from_text(my_documents[i]) for i in range(len(my_documents))],\n               documents=my_documents)\n</code></pre>"},{"location":"core/document-ids/#semantic-strategies","title":"Semantic Strategies","text":"<p>In this section we'll explore a few different use cases for building semantics around document IDs.</p> <ul> <li>URL Slugs - if your docs are web pages with permalinks (e.g. blog posts), you can use the URL slug as the document ID.</li> <li>File Paths - if your docs are files on disk, you can use the file path as the document ID.</li> </ul>"},{"location":"core/filters/","title":"Filters","text":"<p>Chroma provides two types of filters:</p> <ul> <li>Metadata - filter documents based on metadata using <code>where</code> clause in either <code>Collection.query()</code> or <code>Collection.get()</code></li> <li>Document - filter documents based on document content using <code>where_document</code> in <code>Collection.query()</code> or <code>Collection.get()</code>.</li> </ul> <p>Those familiar with MongoDB queries will find Chroma's filters very similar.</p>"},{"location":"core/filters/#metadata-filters","title":"Metadata Filters","text":""},{"location":"core/filters/#equality","title":"Equality","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": \"is_equal_to_this\"}\n)\n</code></pre> <p>Alternative syntax:</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$eq\": \"is_equal_to_this\"}}\n)\n</code></pre>"},{"location":"core/filters/#inequality","title":"Inequality","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$ne\": \"is_not_equal_to_this\"}}\n)\n</code></pre>"},{"location":"core/filters/#greater-than","title":"Greater Than","text":"<p>Greater Than</p> <p>The <code>$gt</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$gt\": 5}}\n)\n</code></pre>"},{"location":"core/filters/#greater-than-or-equal","title":"Greater Than or Equal","text":"<p>Greater Than or Equal</p> <p>The <code>$gte</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$gte\": 5.1}}\n)\n</code></pre>"},{"location":"core/filters/#less-than","title":"Less Than","text":"<p>Less Than</p> <p>The <code>$lt</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$lt\": 5}}\n)\n</code></pre>"},{"location":"core/filters/#less-than-or-equal","title":"Less Than or Equal","text":"<p>Less Than or Equal</p> <p>The <code>$lte</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$lte\": 5.1}}\n)\n</code></pre>"},{"location":"core/filters/#in","title":"In","text":"<p>In works on all data types - string, int, float, and bool.</p> <p>In</p> <p>The <code>$in</code> operator is only supported for list of values of the same type.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$in\": [\"value1\", \"value2\"]}}\n)\n</code></pre>"},{"location":"core/filters/#not-in","title":"Not In","text":"<p>Not In works on all data types - string, int, float, and bool.</p> <p>Not In</p> <p>The <code>$nin</code> operator is only supported for list of values of the same type.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$nin\": [\"value1\", \"value2\"]}}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-and","title":"Logical Operator: And","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$and\": [{\"metadata_field1\": \"value1\"}, {\"metadata_field2\": \"value2\"}]}\n)\n</code></pre> <p>Logical Operators can be nested.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$and\": [{\"metadata_field1\": \"value1\"}, {\"$or\": [{\"metadata_field2\": \"value2\"}, {\"metadata_field3\": \"value3\"}]}]}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-or","title":"Logical Operator: Or","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$or\": [{\"metadata_field1\": \"value1\"}, {\"metadata_field2\": \"value2\"}]}\n)\n</code></pre>"},{"location":"core/filters/#document-filters","title":"Document Filters","text":""},{"location":"core/filters/#contains","title":"Contains","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$contains\": \"search_string\"}\n)\n</code></pre>"},{"location":"core/filters/#not-contains","title":"Not Contains","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$not_contains\": \"search_string\"}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-and_1","title":"Logical Operator: And","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$and\": [{\"$contains\": \"search_string1\"}, {\"$contains\": \"search_string2\"}]}\n)\n</code></pre> <p>Logical Operators can be nested.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$and\": [{\"$contains\": \"search_string1\"}, {\"$or\": [{\"$not_contains\": \"search_string2\"}, {\"$not_contains\": \"search_string3\"}]}]}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-or_1","title":"Logical Operator: Or","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$or\": [{\"$not_contains\": \"search_string1\"}, {\"$not_contains\": \"search_string2\"}]}\n)\n</code></pre>"},{"location":"core/filters/#pagination","title":"Pagination","text":"<p><code>Collection.get()</code> allows users to specify page details <code>limit</code> and <code>offset</code>.</p> <pre><code>results = collection.get(limit=10, offset=20)\n</code></pre>"},{"location":"core/install/","title":"Installation","text":"<p>Chroma single node is split into two packages: <code>chromadb</code> and <code>chromadb-client</code>. The <code>chromadb</code> package is the core package that provides the database functionality, while the <code>chromadb-client</code> package provides the Python client for interacting with the database.</p> <p>In addition to the python packages Chroma also provides a JS/TS client package.</p>"},{"location":"core/install/#core-python-single-node","title":"Core (Python) - Single Node","text":"<p>The core Chroma package installs the full Chroma version which can be uses for local development and testing.</p> Backward compatibility <p>While Chroma strives to be as compatible with older versions as possible, certain releases introduce breaking changes and most importantly database migrations. All database migrations are irreversible and once upgraded to a new version of Chroma, you cannot downgrade to an older version.</p> Releases <p>You can find Chroma releases in PyPI here.</p> Latest ReleaseLatest main branchSpecific VersionFrom PR Branch <pre><code>pip install chromadb\n</code></pre> <p>Directly from  Github:</p> <pre><code>pip install git+https://github.com/chroma-core/chroma.git@main\n</code></pre> <p>From test PyPI:</p> <pre><code>pip install --index-url https://test.pypi.org/simple/ chromadb\n</code></pre> <p>Installing a specific version of Chroma is useful when you want to ensure that your code works with a specific  version of Chroma. To install a specific version of Chroma, run:</p> <p>From PyPI:</p> <pre><code>pip install chromadb==&lt;x.y.z&gt;\n</code></pre> <p>Directly from  Github (replace <code>x.y.z</code> with the tag of the version you want to install):</p> <pre><code>pip install git+https://github.com/chroma-core/chroma.git@x.y.z\n</code></pre> <p>It is sometimes useful to install a version of Chroma that has still some unrelease functionality. Like a PR that either fixes a bug or brings in a new functionality you may need. To test such unreleased code it is possible to install directly from GH PR branch.</p> <pre><code>pip install git+https://github.com/chroma-core/chroma.git@&lt;branch_name&gt;\n</code></pre>"},{"location":"core/install/#chromadb-python-client","title":"ChromaDB Python Client","text":"<p>Chroma python client package <code>chromadb-client</code> provides a thin client for interacting with the Chroma database. The client interface is fully compatible with the core Chroma package so it can be interchangeably used with the core package.</p> Releases <p>You can find Chroma releases in PyPI here.</p> Latest ReleaseLatest main branchSpecific Version <pre><code>pip install chromadb-client\n</code></pre> <p>From test PyPI:</p> <pre><code>pip install --index-url https://test.pypi.org/simple/ chromadb-client\n</code></pre> <p>Installing a specific version of Chroma is useful when you want to ensure that your code works with a specific  version of Chroma. To install a specific version of Chroma, run:</p> <pre><code>pip install chromadb==&lt;x.y.z&gt;\n</code></pre> Default Embedding Function <p>The thin client is light-weight in terms of dependencies and as such the Default Embedding Function is not supported. It is possible to install <code>onnxruntime</code> dependency and use the <code>chromadb.utils.embedding_functions.ONNXMiniLM_L6_V2</code>  EF in place of <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code>. It is not recommended to run inference (local EFs like the default EF) in resource constrained environments.</p>"},{"location":"core/install/#chroma-jsts-client","title":"Chroma JS/TS Client","text":"<p>To install the Chroma JS/TS client package, use the following command depending on your package manager.</p> YarnNPMPNPMGitHub <pre><code>yarn add chromadb chromadb-default-embed\n</code></pre> <pre><code>npm install --save chromadb chromadb-default-embed\n</code></pre> <pre><code>pnpm add chromadb chromadb-default-embed\n</code></pre> <p>To install from GitHub, visit https://github.com/chroma-core/chroma/pkgs/npm/chromadb.</p> NPM Auth <p>GitHub requires npm authentication to fetch packages. To authenticate with the GitHub NPM registry, you need to create a <code>.npmrc</code> file in your project directory with the following content:</p> <pre><code>//npm.pkg.github.com/:_authToken=TOKEN\n@chroma-core:registry=https://npm.pkg.github.com\n</code></pre> <p>Replace <code>TOKEN</code> with your GitHub token. More info can be found here.</p> <pre><code>npm install --save @chroma-core/chromadb\n</code></pre>"},{"location":"core/resources/","title":"Resource Requirements","text":"<p>Chroma makes use of the following compute resources:</p> <ul> <li>RAM - Chroma stores the vector HNSW index in-memory. This allows it to perform blazing fast semantic searches.</li> <li>Disk - Chroma persists all data to disk. This includes the vector HNSW index, metadata index, system DB, and the   write-ahead log (WAL).</li> <li>CPU - Chroma uses CPU for indexing and searching vectors.</li> </ul> <p>Here are some formulas and heuristics to help you estimate the resources you need to run Chroma.</p>"},{"location":"core/resources/#ram","title":"RAM","text":"<p>Once you select your embedding model, use the following formula for calculating RAM storage requirements for the vector HNSW index:</p> <p><code>number of vectors</code> * <code>dimensionality of vectors</code> * <code>4 bytes</code> = <code>RAM required</code></p> <ul> <li><code>number of vectors</code> - This is the number of vectors you plan to index. These are the documents in your Chroma   collection (or chunks if you use LlamaIndex or LangChain terminology).</li> <li><code>dimensionality of vectors</code> - This is the dimensionality of the vectors output by your embedding model. For example,   if you use the <code>sentence-transformers/paraphrase-MiniLM-L6-v2</code> model, the dimensionality of the vectors is 384.</li> <li><code>4 bytes</code> - This is the size of each component of a vector. Chroma relies on HNSW lib implementation that uses 32bit   floats.</li> </ul>"},{"location":"core/resources/#disk","title":"Disk","text":"<p>Disk storage requirements mainly depend on what metadata you store and the number of vectors you index. The heuristics is at least 2-4x the RAM required for the vector HNSW index.</p> <p>WAL Cleanup</p> <p>Since version <code>0.5.6</code> Chroma automatically cleans up the WAL file.</p>"},{"location":"core/resources/#temporary-disk-space","title":"Temporary Disk Space","text":"<p>Chroma uses temporary storage for its SQLite3 related operations - sorting and buffering large queries. By default, SQLite3 uses <code>/tmp</code> for temporary storage.</p> <p>There are two guidelines to follow:</p> <ul> <li>Have enough space if your application intends to make large queries or has multiple concurrent queries.</li> <li>Ensure temporary storage is on a fast disk to avoid performance bottlenecks.</li> </ul> <p>You can configure the location of sqlite temp files with the <code>SQLITE_TMPDIR</code> environment variable.</p> <p>SQLite3 Temporary Storage</p> <p>You can read more about SQLite3 temporary storage in the SQLite3 documentation.</p>"},{"location":"core/resources/#cpu","title":"CPU","text":"<p>There are no hard requirements for the CPU, but it is recommended to use as much CPU as you can spare as it directly relates to index and search speeds.</p>"},{"location":"core/storage-layout/","title":"Storage Layout","text":"<p>When configured as <code>PersistentClient</code> or running as a server, Chroma persists its data under the provided <code>persist_directory</code>.</p> <p>For <code>PersistentClient</code> the persistent directory is usually passed as <code>path</code> parameter when creating the client, if not passed the default is <code>./chroma/</code> (relative path to where the client is started from).</p> <p>For the server, the persistent directory can be passed as environment variable <code>PERSIST_DIRECTORY</code> or as a command line argument <code>--path</code>. If not passed, the default is <code>./chroma/</code> (relative path to where the server is started).</p> <p>Once the client or the server is started a basic directory structure is created under the persistent directory containing the <code>chroma.sqlite3</code> file. Once collections are created and data is added, subdirectories are created for each collection. The subdirectories are UUID-named and refer to the vector segment.</p> Chroma Ops - Maintenance CLI <p>If you are looking maintenance CLI that can help you inspect, configure and improve the performance of your Chroma, try Chroma Ops.</p>"},{"location":"core/storage-layout/#directory-structure","title":"Directory Structure","text":"<p>The following diagram represents a typical Chroma persistent directory structure:</p> <p></p>"},{"location":"core/storage-layout/#chromasqlite3","title":"<code>chroma.sqlite3</code>","text":"<p>Note about the tables</p> <p>While we try to make it as accurate as possible chroma data layout inside the <code>slite3</code> database is subject to change. The following description is valid as of version <code>0.5.0</code>. The tables are also not representative of the distributed architecture of Chroma.</p> <p>The <code>chroma.sqlite3</code> is typical for Chroma single-node. The file contains the following four types of data:</p> <ul> <li>Sysdb - Chroma system database, responsible for storing tenant, database, collection and segment information.</li> <li>WAL - the write-ahead log, which is used to ensure durability of the data.</li> <li>Metadata Segment - all metadata and documents stored in Chroma.</li> <li>Migrations - the database schema migration scripts.</li> <li>Collections - each collection has its own subdirectory, a UUIDv4-named diretory which stores HNSW index and its metadata.</li> </ul>"},{"location":"core/storage-layout/#sysdb","title":"Sysdb","text":"<p>The system database comprises the following tables:</p> <ul> <li><code>tenants</code> - contains all the tenants in the system. Usually gets initialized with a single tenant - <code>default_tenant</code>.</li> <li><code>databases</code> - contains all the databases per tenant. Usually gets initialized with a single   database - <code>default_database</code> related to the <code>default_tenant</code>.</li> <li><code>collections</code> - contains all the collections per database.</li> <li><code>collection_metadata</code> - contains all the metadata associated with each collection. The metadata for a collection   consists of any user-specified key-value pairs and the <code>hnsw:*</code> keys that store   the HNSW index parameters.</li> <li><code>segments</code> - contains all the segments per collection. Each collection gets two segments - <code>metadata</code> and <code>vector</code>.</li> <li><code>segment_metadata</code> - contains all the metadata associated with each segment. This table   contains <code>hnsw:*</code> keys that store the HNSW index parameters for the vector   segment.</li> </ul>"},{"location":"core/storage-layout/#wal","title":"WAL","text":"<p>The write-ahead log is a table that stores all the changes made to the database. It is used to ensure that the data is durable and can be recovered in case of a crash. The WAL is composed of the following tables:</p> <ul> <li><code>embeddings_queue</code> - contains all data ingested into Chroma. Each row of the table represents an operation upon a   collection (add, update, delete, upsert). The row contains all the necessary information (embedding, document,   metadata and associated relationship to a collection) to replay the operation and ensure data consistency.</li> <li><code>embeddings_queue_config</code> - contains the configuration for the embedding queue. As of version <code>0.6.3</code> the configuration only pertains to automatic embedding queue purging.</li> <li><code>max_seq_id</code> - maintains the maximum sequence ID of the metadata segment that is used as a WAL replay starting point for   the metadata segment.</li> </ul> Example Queue Configuration<pre><code>{\n  \"automatically_purge\": true,\n  \"_type\": \"EmbeddingsQueueConfigurationInternal\"\n}\n</code></pre>"},{"location":"core/storage-layout/#metadata-segment","title":"Metadata Segment","text":"<p>The metadata segment is a table that stores all the metadata and documents stored in Chroma. The metadata segment is composed of the following tables:</p> <ul> <li><code>embeddings</code> - contains embedding listings for all collections.</li> <li><code>embedding_metadata</code> - contains all the metadata associated with each document and its embedding.</li> <li><code>embedding_fulltext_search</code> - document full-text search index. This is a virtual table and upon inspection of the sqlite   will appear as a series of tables starting with <code>embedding_fulltext_search_</code>. This is an FTS5 table and is used for   full-text search queries on documents stored in Chroma (via <code>where_document</code> filter in <code>query</code> and <code>get</code> methods).</li> </ul>"},{"location":"core/storage-layout/#migrations","title":"Migrations","text":"<p>The migrations table contains all schema migrations applied to the <code>chroma.sqlite3</code> database. The table is used for tracking applied migrations.</p>"},{"location":"core/storage-layout/#collection-subdirectories","title":"Collection Subdirectories","text":"<p>Each collection has its own subdirectory, a UUIDv4-named diretory which stores HNSW index and its metadata.</p> <ul> <li><code>header.bin</code> - Holds metadata about the index, such as its parameters and structure details.</li> <li><code>length.bin</code> - Records the number of links each node has, aiding in efficient traversal during searches.</li> <li><code>link_lists.bin</code> - Stores the adjacency lists for nodes, detailing their connections within the graph.</li> <li><code>data_level0.bin</code> - Contains the base layer of the hierarchical graph, storing the actual vectors and their connections.</li> <li><code>index_metadata.pickle</code> - Chroma specific metadata about mapping between ids in <code>embeddings</code> table and labels in the HNSW index.</li> </ul>"},{"location":"core/system_constraints/","title":"Chroma System Constraints","text":"<p>This section contains common constraints of Chroma.</p> <ul> <li>Chroma is thread-safe</li> <li>Chroma is not process-safe</li> <li>Multiple Chroma Clients (Ephemeral, Persistent, Http) can be created from one or more threads within the same process</li> <li>A collection's name is unique within a Tenant and DB</li> <li>A collection's dimensions cannot change after creation =&gt; you cannot change the embedding function after creation</li> <li>Chroma operates in two modes - standalone (PersistentClient, EphemeralClient) and client/server (HttpClient with   ChromaServer)</li> <li>The distance function cannot be changed after collection creation.</li> </ul>"},{"location":"core/system_constraints/#operational-modes","title":"Operational Modes","text":"<p>Chroma can be operated in two modes:</p> <ul> <li>Standalone - This allows embedding Chroma in your python application without the need to communicate with external   processes.</li> <li>Client/Server - This allows embedding Chroma in your python application as a thin-client with minimal dependencies and   communicating with it via REST API. This is useful when you want to use Chroma from multiple processes or even   multiple machines.</li> </ul> <p>Depending on the mode you choose, you will need to consider the following component responsibilities:</p> <ul> <li>Standalone:<ul> <li>Clients (Persistent, Ephemeral) - Responsible for persistence, embedding, querying</li> </ul> </li> <li>Client/Server:<ul> <li>Clients (HttpClient) - Responsible for embedding, communication with Chroma server via REST API</li> <li>Server - Responsible for persistence and querying</li> </ul> </li> </ul> <p></p>"},{"location":"core/tenants-and-databases/","title":"Tenants and Databases","text":"<p>Tenants and Databases are two grouping abstractions that provides means to organize and manage data in Chroma.</p>"},{"location":"core/tenants-and-databases/#tenants","title":"Tenants","text":"<p>A tenant is a logical grouping of databases.</p>"},{"location":"core/tenants-and-databases/#databases","title":"Databases","text":"<p>A database is a logical grouping of collections.</p>"},{"location":"core/advanced/queries/","title":"Chroma Queries","text":"<p>This document attempts to capture how Chroma performs queries.</p>"},{"location":"core/advanced/queries/#basic-concepts","title":"Basic concepts","text":"<p>Chroma uses two types of indices (segments) which it queries over:</p> <ul> <li>Metadata Index - this is stored in the <code>chroma.sqlite3</code> and queried with SQL. Chroma stores metadata for all   collections in this index.</li> <li>Vector Index - this is the <code>HNSW</code> index stored under the UUID-named dirs under chroma persistent dir (or in memory for   EphemeralClient). One index per collection.</li> </ul>"},{"location":"core/advanced/queries/#metadata-index","title":"Metadata Index","text":"<p>The metadata index consists of two tables:</p> <ul> <li><code>embeddings</code> - this is one-to-one mapping with the vectors stored in your collections</li> <li><code>embedding_metadata</code> - this is N+1 mapping to the vectors stored in your collections. Where <code>N</code> represents the number   of metadata fields per record and can vary for records. There is at least one entry in the <code>embedding_metadata</code> table   per embedding which represents the document.</li> </ul>"},{"location":"core/advanced/queries/#query-pipeline","title":"Query Pipeline","text":"<p>The query pipeline in Chroma:</p> <ul> <li>Validation - the query is validated</li> <li>Metadata pre-filter - Chroma plans a SQL query to select IDs to pass to KNN search. This step is skipped if <code>where</code>   or <code>where_document</code> are not provided.</li> <li>KNN search in HNSW index - Similarity search with based on the embedded user query(ies). If metadata pre-filter   returned any IDs to search on, only those IDs are searched. The KNN search will also return actual vectors should   <code>included</code> contain <code>embeddings</code>.</li> <li>Post-search query to fetch metadata - Fetch metadata for the IDs returned from the KNN search.</li> <li>Result aggregation - Aggregate the results from the metadata and the KNN search and ensure all <code>included</code> fields are   populated.</li> </ul> Query Pipeline? <p>Why is it called a pipeline? Because each step in the query process depends on its predecessor's output.</p> <p></p>"},{"location":"core/advanced/queries/#validation","title":"Validation","text":"<p>The following validations are performed:</p> <ul> <li>Validate <code>where</code> if present</li> <li>Validate <code>where_document</code> if present</li> <li>Ensure collection exists</li> <li>Validate query embeddings dimensions match that of the collection</li> </ul>"},{"location":"core/advanced/queries/#metadata-pre-filter","title":"Metadata Pre-Filter","text":"<p>TBD</p>"},{"location":"core/advanced/queries/#knn-search-in-hnsw-index","title":"KNN Search in HNSW Index","text":"<p>TBD</p>"},{"location":"core/advanced/queries/#post-search-query-to-fetch-metadata","title":"Post-Search Query to Fetch Metadata","text":"<p>TBD</p>"},{"location":"core/advanced/queries/#result-aggregation","title":"Result Aggregation","text":"<p>Result aggregation makes sure that results from the metadata fetch and the KNN search are fused together into the final result set.</p>"},{"location":"core/advanced/wal-pruning/","title":"Write-ahead Log (WAL) Pruning","text":"<p>Chroma Write-Ahead Log is unbounded by default and grows indefinitely. This can lead to high disk usage and slow performance. To prevent this, it is recommended to prune/cleanup the WAL periodically. Below we offer a couple of tools, including an official and recommended CLI tool, to help you prune your WAL.</p>"},{"location":"core/advanced/wal-pruning/#tooling","title":"Tooling","text":"<p>There are two ways to prune your WAL:</p> <ul> <li>Chroma CLI - this is the official tooling provided by Chroma and is the recommended way to prune your WAL. This   functionality is available either from <code>main</code> branch or Chroma release <code>&gt;0.5.5</code>.</li> <li>chroma-ops</li> </ul>"},{"location":"core/advanced/wal-pruning/#chroma-cli","title":"Chroma CLI","text":"<p>To prune your WAL you need to install Chroma CLI (it comes as part of the core Chroma package):</p> <pre><code>pip install chromadb\n\nchroma utils vacuum --path /path/to/persist_dir\n</code></pre> <p>Auto-pruning</p> <p>Running the above command will enable auto WAL pruning.  This means that Chroma will periodically prune the WAL during its normal operations.</p>"},{"location":"core/advanced/wal-pruning/#chroma-ops","title":"Chroma Ops","text":"<p>To prune your WAL you can run the following command:</p> <pre><code>pip install chroma-ops\nchops cleanup-wal /path/to/persist_dir\n</code></pre> <p>\u26a0\ufe0f IMPORTANT: It is always a good thing to backup your data before you prune the WAL.</p>"},{"location":"core/advanced/wal-pruning/#manual","title":"Manual","text":"<p>Steps:</p> <p>Stop Chroma</p> <p>It is vitally important that you stop Chroma before you prune the WAL.  If you don't stop Chroma you risk corrupting</p> <ul> <li>\u26a0\ufe0f Stop Chroma</li> <li>\ud83d\udcbe Create a backup of your <code>chroma.sqlite3</code> file in your persistent dir</li> <li>\ud83d\udc40 Check your current <code>chroma.sqlite3</code> size (e.g. <code>ls -lh /path/to/persist/dir/chroma.sqlite3</code>)</li> <li>\ud83d\udda5\ufe0f Run the script below</li> <li>\ud83d\udd2d Check your current <code>chroma.sqlite3</code> size again to verify that the WAL has been pruned</li> <li>\ud83d\ude80 Start Chroma</li> </ul> <p>Script (store it in a file like <code>compact-wal.sql</code>)</p> wal_clean.py<pre><code>#!/usr/bin/env python3\n# Call the script: python wal_clean.py ./chroma-test-compact\nimport os\nimport sqlite3\nfrom typing import cast, Optional, Dict\nimport argparse\nimport pickle\n\n\nclass PersistentData:\n    \"\"\"Stores the data and metadata needed for a PersistentLocalHnswSegment\"\"\"\n\n    dimensionality: Optional[int]\n    total_elements_added: int\n    max_seq_id: int\n\n    id_to_label: Dict[str, int]\n    label_to_id: Dict[int, str]\n    id_to_seq_id: Dict[str, int]\n\n\ndef load_from_file(filename: str) -&gt; \"PersistentData\":\n    \"\"\"Load persistent data from a file\"\"\"\n    with open(filename, \"rb\") as f:\n        ret = cast(PersistentData, pickle.load(f))\n        return ret\n\n\ndef clean_wal(chroma_persist_dir: str):\n    if not os.path.exists(chroma_persist_dir):\n        raise Exception(f\"Persist {chroma_persist_dir} dir does not exist\")\n    if not os.path.exists(f'{chroma_persist_dir}/chroma.sqlite3'):\n        raise Exception(\n            f\"SQL file not found int persist dir {chroma_persist_dir}/chroma.sqlite3\")\n    # Connect to SQLite database\n    conn = sqlite3.connect(f'{chroma_persist_dir}/chroma.sqlite3')\n\n    # Create a cursor object\n    cursor = conn.cursor()\n\n    # SQL query\n    query = \"SELECT id,topic FROM segments where scope='VECTOR'\"  # Replace with your query\n\n    # Execute the query\n    cursor.execute(query)\n\n    # Fetch the results (if needed)\n    results = cursor.fetchall()\n    wal_cleanup_queries = []\n    for row in results:\n        # print(row)\n        metadata = load_from_file(\n            f'{chroma_persist_dir}/{row[0]}/index_metadata.pickle')\n        wal_cleanup_queries.append(\n            f\"DELETE FROM embeddings_queue WHERE seq_id &lt; {metadata.max_seq_id} AND topic='{row[1]}';\")\n\n    cursor.executescript('\\n'.join(wal_cleanup_queries))\n    # Close the cursor and connection\n    cursor.close()\n    conn.close()\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('persist_dir', type=str)\n    arg = parser.parse_args()\n    print(arg.persist_dir)\n    clean_wal(arg.persist_dir)\n</code></pre> <p>Run the script</p> <pre><code># Let's create a backup\ntar -czvf /path/to/persist/dir/chroma.sqlite3.backup.tar.gz /path/to/persist/dir/chroma.sqlite3\nlsof /path/to/persist/dir/chroma.sqlite3 # make sure that no process is using the file\npython wal_clean.py /path/to/persist/dir/\n# start chroma\n</code></pre>"},{"location":"core/advanced/wal/","title":"Write-ahead Log (WAL)","text":"<p>Chroma uses WAL to ensure data durability, even if things go wrong (e.g. server crashes). To achieve the latter Chroma uses what is known in the DB-industry as WAL or Write-Ahead Log. The purpose of the WAL is to ensure that each user request (aka transaction) is safely stored before acknowledging back to the user. Subsequently, in fact immediately after writing to the WAL, the data is also written to the index. This enables Chroma to serve as real-time search engine, where the data is available for querying immediately after it is written to the WAL.</p> <p>Below is a diagram that illustrates the WAL in ChromaDB (ca. 0.6.3):</p> <p></p>"},{"location":"core/advanced/wal/#vector-indices-overview","title":"Vector Indices Overview","text":"<p>The diagram below illustrates how data gets transferred from the WAL to the binary vector indices (Bruteforce and HNSW):</p> <p></p> <p>For each collection Chroma maintains two binary indices - Bruteforce (in-memory, fast) and HNSW lib (persisted to disk, slow when adding new vectors and persisting). As you can imagine, the BF index serves the role of a buffer that holds the uncommitted to HNWS persisted index portion of the WAL. The HNSW index itself has a max sequence id counter, stored in a metadata file, that indicates from which position in the WAL the buffering to the BF index should begin. The latter buffering usually happens when the collection is first accessed.</p> <p>There are two transfer points (in the diagram, sync threshold) for BF to HNSW:</p> <ul> <li><code>hnsw:batch_size</code> - forces the BF vectors to be added to HNSW in-memory (this is a slow operation)</li> <li> <p><code>hnsw:sync_threshold</code> - forces Chroma to dump the HNSW in-memory index to disk (this is a slow operation)</p> </li> <li> <p>Both of the above sync points are controlled via Collection-level metadata with respective named params. It is   customary <code>hnsw:sync_threshold</code> &gt; <code>hnsw:batch_size</code></p> </li> </ul>"},{"location":"core/advanced/wal/#metadata-indices-overview","title":"Metadata Indices Overview","text":"<p>The following diagram illustrates how data gets transferred from the WAL to the metadata index:</p> <p></p>"},{"location":"core/advanced/wal/#further-reading","title":"Further Reading","text":"<p>For the DevOps minded folks we have a few more resources:</p> <ul> <li>WAL Pruning - Clean up your WAL</li> </ul>"},{"location":"ecosystem/clients/","title":"Chroma Ecosystem Clients","text":""},{"location":"ecosystem/clients/#python","title":"Python","text":"Maintainer Chroma Core team Repo https://github.com/chroma-core/chroma Status \u2705 Stable Version <code>0.5.5.dev0</code> (PyPi Link) Docs https://docs.trychroma.com/reference/py-client Compatibility Python: <code>3.8+</code>, Chroma API Version: <code>0.5.x</code> <p>Feature Support:</p> Feature Supported Create Tenant \u2705 Get Tenant \u2705 Create DB \u2705 Get DB \u2705 Create Collection \u2705 Get Collection \u2705 List Collection \u2705 Count Collection \u2705 Delete Collection \u2705 Add Documents \u2705 Delete Documents \u2705 Update Documents \u2705 Query Documents \u2705 Get Document \u2705 Count Documents \u2705 Auth - Basic \u2705 Auth - Token \u2705 Reset \u2705 <p>Embedding Function Support:</p> Embedding Function Supported OpenAI \u2705 Sentence Transformers \u2705 HuggingFace Inference API \u2705 Cohere \u2705 Google Vertex AI \u2705 Google Generative AI (Gemini) \u2705 OpenCLIP (Multi-modal) \u2705 <p>Embedding Functions</p> <p>The list above is not exhaustive. Check  official docs for up-to-date information.</p>"},{"location":"ecosystem/clients/#javascript","title":"JavaScript","text":"Maintainer Chroma Core team Repo https://github.com/chroma-core/chroma Status \u2705 Stable Version <code>1.8.1</code> (NPM Link) Docs https://docs.trychroma.com/reference/js-client Compatibility Python: <code>3.7+</code>, Chroma API Version: <code>TBD</code> <p>Feature Support:</p> Feature Supported Create Tenant \u2705 Get Tenant \u2705 Create DB \u2705 Get DB \u2705 Create Collection \u2705 Get Collection \u2705 List Collection \u2705 Count Collection \u2705 Delete Collection \u2705 Add Documents \u2705 Delete Documents \u2705 Update Documents \u2705 Query Documents \u2705 Get Document \u2705 Count Documents \u2705 Auth - Basic \u2705 Auth - Token \u2705 Reset \u2705 <p>Embedding Function Support:</p> Embedding Function Supported OpenAI \u2705 Sentence Transformers \u2705 HuggingFace Inference API \u2705 Cohere \u2705 Google Vertex AI \u2705 Google Generative AI (Gemini) \u2705 OpenCLIP (Multi-modal) \u2705 <p>Embedding Functions</p> <p>The list above is not exhaustive. Check  official docs for up-to-date information.</p>"},{"location":"ecosystem/clients/#ruby-client","title":"Ruby Client","text":"<p>https://github.com/mariochavez/chroma</p>"},{"location":"ecosystem/clients/#java-client","title":"Java Client","text":"<p>https://github.com/amikos-tech/chromadb-java-client</p>"},{"location":"ecosystem/clients/#go-client","title":"Go Client","text":"Maintainer Amikos Tech (Chroma Core contributor) Repo https://github.com/amikos-tech/chroma-go Status \u2705 Stable Version <code>0.1.4</code> (Go Pkg Link) Docs https://go-client.chromadb.dev/ Compatibility Go: <code>1.21+</code>, Chroma API Version: <code>0.5.x</code> <p>Feature Support:</p> Feature Supported Create Tenant \u2705 Get Tenant \u2705 Create DB \u2705 Get DB \u2705 Create Collection \u2705 Get Collection \u2705 List Collection \u2705 Count Collection \u2705 Delete Collection \u2705 Add Documents \u2705 Delete Documents \u2705 Update Documents \u2705 Query Documents \u2705 Get Document \u2705 Count Documents \u2705 Auth - Basic \u2705 Auth - Token \u2705 Reset \u2705 <p>Embedding Function Support:</p> Embedding Function Supported OpenAI \u2705 HuggingFace Inference API \u2705 Cohere \u2705 Google Generative AI (Gemini) \u2705 Mistral AI \u2705 Cloudflare Workers AI) \u2705 Together AI \u2705 Ollama \u2705 Nomic AI \u2705 Hugging Face Embedding Inference Server \u2705"},{"location":"ecosystem/clients/#c-client","title":"C# Client","text":"<p>https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Chroma</p>"},{"location":"ecosystem/clients/#rust-client","title":"Rust Client","text":"<p>https://crates.io/crates/chromadb</p>"},{"location":"ecosystem/clients/#elixir-client","title":"Elixir Client","text":"<p>https://hex.pm/packages/chroma/</p>"},{"location":"ecosystem/clients/#dart-client","title":"Dart Client","text":"<p>https://pub.dev/packages/chromadb</p>"},{"location":"ecosystem/clients/#php-client","title":"PHP Client","text":"<p>https://github.com/CodeWithKyrian/chromadb-php</p>"},{"location":"ecosystem/clients/#php-laravel-client","title":"PHP (Laravel) Client","text":"<p>https://github.com/helgeSverre/chromadb</p>"},{"location":"embeddings/bring-your-own-embeddings/","title":"Creating your own embedding function","text":"<pre><code>from chromadb.api.types import (\n    Documents,\n    EmbeddingFunction,\n    Embeddings\n)\n\n\nclass MyCustomEmbeddingFunction(EmbeddingFunction[Documents]):\n    def __init__(\n            self,\n            my_ef_param: str\n    ):\n        \"\"\"Initialize the embedding function.\"\"\"\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        \"\"\"Embed the input documents.\"\"\"\n        return self._my_ef(input)\n</code></pre> <p>Now let's break the above down.</p> <p>First you create a class that inherits from <code>EmbeddingFunction[Documents]</code>. The <code>Documents</code> type is a list of <code>Document</code> objects. Each <code>Document</code> object has a <code>text</code> attribute that contains the text of the document. Chroma also supports multi-modal</p>"},{"location":"embeddings/bring-your-own-embeddings/#example-implementation","title":"Example Implementation","text":"<p>Below is an implementation of an embedding function that works with <code>transformers</code> models.</p> <p>Note</p> <p>This example requires the <code>transformers</code> and <code>torch</code> python packages. You can install them with <code>pip install transformers torch</code>.</p> <p>By default, all <code>transformers</code> models on HF are supported are also supported by the <code>sentence-transformers</code> package. For which Chroma provides out of the box support.</p> <pre><code>import importlib\nfrom typing import Optional, cast\n\nimport numpy as np\nimport numpy.typing as npt\nfrom chromadb.api.types import EmbeddingFunction, Documents, Embeddings\n\n\nclass TransformerEmbeddingFunction(EmbeddingFunction[Documents]):\n    def __init__(\n            self,\n            model_name: str = \"dbmdz/bert-base-turkish-cased\",\n            cache_dir: Optional[str] = None,\n    ):\n        try:\n            from transformers import AutoModel, AutoTokenizer\n\n            self._torch = importlib.import_module(\"torch\")\n            self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n            self._model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)\n        except ImportError:\n            raise ValueError(\n                \"The transformers and/or pytorch python package is not installed. Please install it with \"\n                \"`pip install transformers` or `pip install torch`\"\n            )\n\n    @staticmethod\n    def _normalize(vector: npt.NDArray) -&gt; npt.NDArray:\n        \"\"\"Normalizes a vector to unit length using L2 norm.\"\"\"\n        norm = np.linalg.norm(vector)\n        if norm == 0:\n            return vector\n        return vector / norm\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        inputs = self._tokenizer(\n            input, padding=True, truncation=True, return_tensors=\"pt\"\n        )\n        with self._torch.no_grad():\n            outputs = self._model(**inputs)\n        embeddings = outputs.last_hidden_state.mean(dim=1)  # mean pooling\n        return [e.tolist() for e in self._normalize(embeddings)]\n</code></pre>"},{"location":"embeddings/cross-encoders/","title":"Cross-Encoders Reranking","text":"<p>Work in Progress</p> <p>This page is a work in progress and may not be complete.</p> <p>For now this is just a tiny snippet how to use a cross-encoder to rerank results returned from Chroma. Soon we will provide a more detailed guide to the usefulness of cross-encoders/rerankers.</p>"},{"location":"embeddings/cross-encoders/#hugging-face-cross-encoders","title":"Hugging Face Cross Encoders","text":"<pre><code>from sentence_transformers import CrossEncoder\nimport numpy as np\nimport chromadb\nclient = chromadb.Client()\ncollection = client.get_or_create_collection(\"my_collection\")\n# add some documents \ncollection.add(ids=[\"doc1\", \"doc2\", \"doc3\"], documents=[\"Hello, world!\", \"Hello, Chroma!\", \"Hello, Universe!\"])\n# query the collection\nquery = \"Hello, world!\"\nresults = collection.query(query_texts=[query], n_results=3)\n\n\n\nmodel = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512)\n# rerank the results with original query and documents returned from Chroma\nscores = model.predict([(query, doc) for doc in results[\"documents\"][0]])\n# get the highest scoring document\nprint(results[\"documents\"][0][np.argmax(scores)])\n</code></pre>"},{"location":"embeddings/embedding-models/","title":"Embedding Models","text":"<p>Work in Progress</p> <p>This page is a work in progress.</p> <p>Embedding Models are your best friends in the world of Chroma, and vector databases in general. They take something you understand in the form of text, images, audio etc. and turn it into a list of numbers (embeddings), which a machine learning model can understand. This process makes documents interpretable by a machine learning model.</p> <p>The goal of this page is to arm you with enough knowledge to make an informed decision about which embedding model to choose for your use case.</p> <p>The importance of a model</p> <p>GenAI moves pretty fast therefore we recommend not to over-rely on models too much. When creating your solution create the necessary abstractions and tests to be able to quickly experiment and change things up (don't overdo it on the abstraction though).</p> <p></p>"},{"location":"embeddings/embedding-models/#characteristics-of-an-embedding-model","title":"Characteristics of an Embedding Model","text":"<ul> <li>Modality - the type of data each model is designed to work with. For example, text, images, audio, video. Note: Some   models can work with multiple modalities (e.g. OpenAI's CLIP).</li> <li>Context - The maximum number of tokens the model can process at once.</li> <li>Tokenization - The model's tokenizer or the way a model turns text into tokens to process.</li> <li>Dimensionality - The number of dimensions in the output embeddings/vectors.</li> <li>Training Data - The data the model was trained on.</li> <li>Execution Environment - How the model is run (e.g. local, cloud, API).</li> <li>Loss Function - The function used to train the model e.g. how well the model is doing in predicting the embeddings,   compared to the actual embeddings.</li> </ul>"},{"location":"embeddings/embedding-models/#model-categories","title":"Model Categories","text":"<p>There are several ways to categorize embedding models other than the above characteristics:</p> <ul> <li>Execution environment e.g. API vs local</li> <li>Licensing e.g. open-source vs proprietary</li> <li>Privacy e.g. on-premises vs cloud</li> </ul>"},{"location":"embeddings/embedding-models/#execution-environment","title":"Execution Environment","text":"<p>The execution environment is probably the first choice you should consider when creating your GenAI solution. Can I afford my data to leave the confines of my computer, cluster, organization? If the answer is yes and you are still in the experimentation phase of your GenAI journey we recommend using API-based embedding models.</p>"},{"location":"embeddings/gpu-support/","title":"Embedding Functions GPU Support","text":"<p>By default, Chroma does not require GPU support for embedding functions. However, if you want to use GPU support, some of the functions, especially those running locally provide GPU support.</p>"},{"location":"embeddings/gpu-support/#default-embedding-functions-onnxruntime","title":"Default Embedding Functions (Onnxruntime)","text":"<p>To use the default embedding functions with GPU support, you need to install <code>onnxruntime-gpu</code> package. You can install it with the following command:</p> <pre><code>pip install onnxruntime-gpu\n</code></pre> <p>Note: To ensure no conflicts, you can uninstall <code>onnxruntime</code> (e.g. <code>pip uninstall onnxruntime</code>) in a separate environment.</p> <p>List available providers:</p> <pre><code>import onnxruntime\n\nprint(onnxruntime.get_available_providers())\n</code></pre> <p>Select the desired provider and set it as preferred before using the embedding functions (in the below example, we use <code>CUDAExecutionProvider</code>):</p> <pre><code>import time\nfrom chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2\n\nef = ONNXMiniLM_L6_V2(preferred_providers=['CUDAExecutionProvider'])\n\ndocs = []\nfor i in range(1000):\n    docs.append(f\"this is a document with id {i}\")\n\nstart_time = time.perf_counter()\nembeddings = ef(docs)\nend_time = time.perf_counter()\nprint(f\"Elapsed time: {end_time - start_time} seconds\")\n</code></pre> <p>IMPORTANT OBSERVATION: Our observations are that for GPU support using sentence transformers with model <code>all-MiniLM-L6-v2</code> outperforms onnxruntime with GPU support. In practical terms on a Colab T4 GPU, the onnxruntime example above runs for about 100s whereas the equivalent sentence transformers example runs for about 1.8s.</p>"},{"location":"embeddings/gpu-support/#sentence-transformers","title":"Sentence Transformers","text":"<pre><code>import time\nfrom chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n# This will download the model to your machine and set it up for GPU support\nef = SentenceTransformerEmbeddingFunction(model_name=\"thenlper/gte-small\", device=\"cuda\")\n\n# Test with 10k documents\ndocs = []\nfor i in range(10000):\n    docs.append(f\"this is a document with id {i}\")\n\nstart_time = time.perf_counter()\nembeddings = ef(docs)\nend_time = time.perf_counter()\nprint(f\"Elapsed time: {end_time - start_time} seconds\")\n</code></pre> <p>Note: You can run the above example in google Colab - see the notebook</p>"},{"location":"embeddings/gpu-support/#openclip","title":"OpenCLIP","text":"<p>Prior to PR #1806, we simply used the <code>torch</code> package to load the model and run it on the GPU.</p> <pre><code>import chromadb\nfrom chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\nfrom chromadb.utils.data_loaders import ImageLoader\nimport toch\nimport os\n\nIMAGE_FOLDER = \"images\"\ntoch.device(\"cuda\")\n\nembedding_function = OpenCLIPEmbeddingFunction()\nimage_loader = ImageLoader()\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")\ncollection = client.create_collection(\n    name='multimodal_collection',\n    embedding_function=embedding_function,\n    data_loader=image_loader)\n\nimage_uris = sorted([os.path.join(IMAGE_FOLDER, image_name) for image_name in os.listdir(IMAGE_FOLDER)])\nids = [str(i) for i in range(len(image_uris))]\ncollection.add(ids=ids, uris=image_uris)\n</code></pre> <p>After PR #1806:</p> <pre><code>from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\nembedding_function = OpenCLIPEmbeddingFunction(device=\"cuda\")\n</code></pre>"},{"location":"faq/","title":"Frequently Asked Questions and Commonly Encountered Issues","text":"<p>This section provides answers to frequently asked questions and information on commonly encountered problem when working with Chroma. These information below is based on interactions with the Chroma community.</p> <p>404 Answer Not Found</p> <p>If you have a question that is not answered here, please reach out to us on our Discord @taz or GitHub Issues</p>"},{"location":"faq/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"faq/#distances-and-similarity","title":"Distances and Similarity","text":"<p>Chroma uses distance metrics to measure how dissimilar a result is from a query. A distance of 0 indicates that the two items are identical, while larger distances indicate greater dissimilarity. This approach starts at 0 and increases upward, aligning with the intuitive notion of distance.</p> <p>In contrast, similarity metrics measure how similar two items are, often on a scale where higher values represent greater similarity. For example:</p> <ul> <li>Cosine Similarity ranges from -1 to 1, where:<ul> <li>1 indicates identical orientation (maximum similarity),</li> <li>0 indicates orthogonality (no similarity),</li> <li>-1 indicates opposite orientation (maximum dissimilarity).</li> </ul> </li> <li>Dot Product can range from negative to positive infinity, depending on the vectors' magnitudes and directions. When vectors are normalized and non-negative, the dot product ranges from 0 to 1.</li> </ul>"},{"location":"faq/#why-does-chroma-use-distance-metrics","title":"Why Does Chroma Use Distance Metrics?","text":"<p>Chroma uses distance metrics because they provide a straightforward way to quantify dissimilarity between vectors. Consistency is another key aspect - irrespecitve of the distance metric used, distance results follow the same conceptual framework. Finally, distance is is an intuitive metric which makes Chroma more accessible to a wider audience.</p>"},{"location":"faq/#what-does-chroma-use-to-index-embedding-vectors","title":"What does Chroma use to index embedding vectors?","text":"<p>Chroma uses its own fork of HNSW lib for indexing and searching embeddings. In addition to HNSW, Chroma also uses a Brute Force index, which acts as a buffer (prior to updating the HNSW graph) and performs exhaustive search using the same distance metric as the HNSW index.</p> <p>Alternative Questions:</p> <ul> <li>What library does Chroma use for vector index and search?</li> <li>What algorithm does Chroma use for vector search?</li> </ul>"},{"location":"faq/#how-to-set-dimensionality-of-my-collections","title":"How to set dimensionality of my collections?","text":"<p>When creating a collection, its dimensionality is determined by the dimensionality of the first embedding added to it. Once the dimensionality is set, it cannot be changed. Therefore, it is important to consistently use embeddings of the same dimensionality when adding or querying a collection.</p> <p>Example:</p> <pre><code>import chromadb\n\nclient = chromadb.Client()\n\ncollection = client.create_collection(\"name\")  # dimensionality is not set yet\n\n# add an embedding to the collection\ncollection.add(ids=[\"id1\"], embeddings=[[1, 2, 3]])  # dimensionality is set to 3\n</code></pre> <p>Alternative Questions:</p> <ul> <li>Can I change the dimensionality of a collection?</li> </ul>"},{"location":"faq/#can-i-use-transformers-models-with-chroma","title":"Can I use <code>transformers</code> models with Chroma?","text":"<p>Generally, yes you can use <code>transformers</code> models with Chroma. Although Chroma does not provide a wrapper for this, you can use <code>SentenceTransformerEmbeddingFunction</code> to achieve the same result. The sentence-transformer library will implicitly do mean-pooling on the last hidden layer, and you'll get a warning about it - <code>No sentence-transformers model found with name [model name]. Creating a new one with MEAN pooling.</code></p> <p>Example:</p> <pre><code>from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n\nef = SentenceTransformerEmbeddingFunction(model_name=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")\n\nprint(ef([\"test\"]))\n</code></pre> <p>Warning</p> <p>Not all models will work with the above method. Also mean pooling may not be the best strategy for the model.  Read the model card and try to understand what if any pooling the creators recommend. You may also want to normalize the embeddings before adding them to Chroma (pass <code>normalize_embeddings=True</code> to the <code>SentenceTransformerEmbeddingFunction</code>  EF constructor).</p>"},{"location":"faq/#should-i-store-my-documents-in-chroma","title":"Should I store my documents in Chroma?","text":"<p>Note: This applies to Chroma single-node and local embedded clients. (Chroma version ca. 0.5.x)</p> <p>Chroma allows users to store both embeddings and documents, alongside metadata, in collections. Documents and metadata are both optional and depending on your use case you may choose to store them in Chroma or externally, or not at all.</p> <p>Here are some pros/cons to help you decide whether to store your documents in Chroma:</p> <p>Pros:</p> <ul> <li>Keeps all the data in the same place. You don't have to manage a separate DB for the documents</li> <li>Allows you to do keyword searches on the documents</li> </ul> <p>Cons:</p> <ul> <li>The database can grow substantially in size because documents are effectively duplicated - once for storing them as   metadata for queries and another for the FTS5 index.</li> <li>Queries performance hit</li> </ul>"},{"location":"faq/#dude-wheres-my-data","title":"\"Dude, where's my data?\"","text":"<p>If you are new to Chroma, you might be asking yourself: \"Where is my data been stored?\". As, per usual, the answer is: \"It depends\".</p> <p>Generally Chroma uses <code>PERSIST_DIRECTORY</code> to store the data, but when running in CLI mode, this is overridden by the CLI itself.</p> <ul> <li>Running in CLI mode (<code>--path</code> is not specified) data is stored in the <code>./chroma_data</code> directory.</li> <li>Running in Jupyter notebook, Colab or directly using <code>PersistentClient</code> (unless <code>path</code> is specified or env var <code>PERSIST_DIRECTORY</code> is set), data is stored in the <code>./chroma</code> directory.</li> <li>Running with docker compose (from source repo), the data is stored in docker volume named <code>chroma-data</code> (unless an explicit volume binding is specified)</li> <li>Running with <code>docker run</code> (no volume binding with <code>-v</code>) the data is stored in the container and is lost \u2620\ufe0f when the container is removed.</li> </ul> <p>In all other cases where env var, parameter or binding is specified, the data is stored in your specified directory.</p>"},{"location":"faq/#commonly-encountered-problems","title":"Commonly Encountered Problems","text":""},{"location":"faq/#collection-dimensionality-mismatch","title":"Collection Dimensionality Mismatch","text":"<p>Symptoms:</p> <p>This error usually exhibits in the following error message:</p> <p><code>chromadb.errors.InvalidDimensionException: Embedding dimension XXX does not match collection dimensionality YYY</code></p> <p>Context:</p> <p>When adding/upserting or querying Chroma collection. This error is more visible/pronounced when using the Python APIs, but will also show up in also surface in other clients.</p> <p>Cause:</p> <p>You are trying to add or query a collection with vectors of a different dimensionality than the collection was created with.</p> <p>Explanation/Solution:</p> <p>When you first create a collection <code>client.create_collection(\"name\")</code>, the collection will not have knowledge of its dimensionality so that allows you to add vectors of any dimensionality to it. However, once your first batch of embeddings is added to the collection, the collection will be locked to that dimensionality. Any subsequent query or add operation must use embeddings of the same dimensionality. The dimensionality of the embeddings is a characteristic of the embedding model (EmbeddingFunction) used to generate the embeddings, therefore it is important to consistently use the same EmbeddingFunction when adding or querying a collection.</p> <p>Tip</p> <p>If you do not specify an <code>embedding_function</code> when creating (<code>client.create_collection</code>) or getting (<code>client.get_or_create_collection</code>) a collection, Chroma wil use its default embedding function.</p>"},{"location":"faq/#large-distances-in-search-results","title":"Large Distances in Search Results","text":"<p>Symptoms:</p> <p>When querying a collection, you get results that are in the 10s or 100s.</p> <p>Context:</p> <p>Frequently when using you own embedding function.</p> <p>Cause:</p> <p>The embeddings are not normalized.</p> <p>Explanation/Solution:</p> <p><code>L2</code> (Euclidean distance) and <code>IP</code> (inner product) distance metrics are sensitive to the magnitude of the vectors. Chroma uses <code>L2</code> by default. Therefore, it is recommended to normalize the embeddings before adding them to Chroma.</p> <p>Here is an example how to normalize embeddings using L2 norm:</p> <pre><code>import numpy as np\n\n\ndef normalize_L2(vector):\n    \"\"\"Normalizes a vector to unit length using L2 norm.\"\"\"\n    norm = np.linalg.norm(vector)\n    if norm == 0:\n        return vector\n    return vector / norm\n</code></pre>"},{"location":"faq/#operationalerror-no-such-column-collectionstopic","title":"<code>OperationalError: no such column: collections.topic</code>","text":"<p>Symptoms:</p> <p>The error <code>OperationalError: no such column: collections.topic</code> is raised when trying to access Chroma locally or remotely.</p> <p>Context:</p> <p>After upgrading to Chroma <code>0.5.0</code> or accessing your Chroma persistent data with Chroma client version <code>0.5.0</code>.</p> <p>Cause:</p> <p>In version <code>0.5.x</code> Chroma has made some SQLite3 schema changes that are not backwards compatible with the previous versions. Once you access your persistent data on the server or locally with the new Chroma version it will automatically migrate to the new schema. This operation is not reversible.</p> <p>Explanation/Solution:</p> <p>To resolve this issue you will need to upgrade all your clients accessing the Chroma data to version <code>0.5.x</code>.</p> <p>Here's a link to the migration performed by Chroma - https://github.com/chroma-core/chroma/blob/main/chromadb/migrations/sysdb/00005-remove-topic.sqlite.sql</p>"},{"location":"faq/#sqlite3operationalerror-database-or-disk-is-full","title":"<code>sqlite3.OperationalError: database or disk is full</code>","text":"<p>Symptoms:</p> <p>The error <code>sqlite3.OperationalError: database or disk is full</code> is raised when trying to access Chroma locally or remotely. The error can occur in any of the Chroma API calls.</p> <p>Context:</p> <p>There are two contexts in which this error can occur:</p> <ul> <li>When the persistent disk space is full or the disk quota is reached - This is where your <code>PERSIST_DIRECTORY</code> points   to.</li> <li>When there is not enough space in the temporary director - frequently <code>/tmp</code> on your system or container.</li> </ul> <p>Cause:</p> <p>When inserting new data and your Chroma persistent disk space is full or the disk quota is reached, the database will not be able to write metadata to SQLite3 db thus raising the error.</p> <p>When performing large queries or multiple concurrent queries, the temporary disk space may be exhausted.</p> <p>Explanation/Solution:</p> <p>To work around the first issue, you can increase the disk space or clean up the disk space. To work around the second issue, you can increase the temporary disk space (works fine for containers but might be a problem for VMs) or point SQLite3 to a different temporary directory by using <code>SQLITE_TMPDIR</code> environment variable.</p> SQLite Temp File <p>More information on how sqlite3 uses temp files can be found here.</p>"},{"location":"faq/#runtimeerror-chroma-is-running-in-http-only-client-mode-and-can-only-be-run-with-chromadbapifastapifastapi","title":"<code>RuntimeError: Chroma is running in http-only client mode, and can only be run with 'chromadb.api.fastapi.FastAPI'</code>","text":"<p>Symptoms and Context:</p> <p>The following error is raised when trying to create a new <code>PersistentClient</code>, <code>EphemeralClient</code>, or <code>Client</code>:</p> <pre><code>RuntimeError: Chroma is running in http-only client mode, and can only be run with 'chromadb.api.fastapi.FastAPI' \nas the chroma_api_impl. see https://docs.trychroma.com/usage-guide?lang=py#using-the-python-http-only-client for more information.\n</code></pre> <p>Cause:</p> <p>There are two possible causes for this error:</p> <ul> <li><code>chromadb-client</code> is installed and you are trying to work with a local client.</li> <li>Dependency conflict with <code>chromadb-client</code> and <code>chromadb</code> packages.</li> </ul> <p>Explanation/Solution:</p> <p>Chroma (python) comes in two packages - <code>chromadb</code> and <code>chromadb-client</code>. The <code>chromadb-client</code> package is used to interact with a remote Chroma server. If you are trying to work with a local client, you should use the <code>chromadb</code> package. If you are planning to interact with remote server only it is recommended to use the <code>chromadb-client</code> package.</p> <p>If you intend to work locally with Chroma (e.g. embed in your app) then we suggest that you uninstall the <code>chromadb-client</code> package and install the <code>chromadb</code> package.</p> <p>To check which package you have installed:</p> <pre><code>pip list | grep chromadb\n</code></pre> <p>To uninstall the <code>chromadb-client</code> package:</p> <pre><code>pip uninstall chromadb-client\n</code></pre> Working with virtual environments <p>It is recommended to work with virtual environments to avoid dependency conflicts. To create a virtual environment  you can use the following snippet:</p> <p><pre><code>pip install virtualenv\npython -m venv myenv\nsource myenv/bin/activate\npip install chromadb # and other packages you need\n</code></pre> Alternatively you can use <code>conda</code> or <code>poetry</code> to manage your environments.</p> Default Embedding Function <p>Default embedding function - <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> - can only be used with <code>chromadb</code> package.</p>"},{"location":"faq/#valueerror-you-must-provide-an-embedding-function-to-compute-embeddings","title":"<code>ValueError: You must provide an embedding function to compute embeddings</code>","text":"<p>Symptoms and Context:</p> <p>The error <code>ValueError: You must provide an embedding function to compute embeddings.https://docs.trychroma.com/embeddings\"</code> is frequently raised when trying to add embeddings to a collection using Python thin client (<code>chromadb-client</code> package).</p> <p>Cause:</p> <p>To reduce the size of the <code>chromadb-client</code> package the default embedding function which requires <code>onnxruntime</code> package is not included and is instead aliased to <code>None</code>.</p> <p>Explanation/Solution:</p> <p>To resolve this issue you must always provide an embedding function when you call <code>get_collection</code> or <code>get_or_create_collection</code> methods to provide the Http client with the necessary information to compute embeddings.</p>"},{"location":"faq/#adding-documents-is-slow","title":"Adding documents is slow","text":"<p>Symptoms:</p> <p>Adding documents to Chroma appears slow.</p> <p>Context:</p> <p>You've tried adding documents to a collection using the <code>add()</code> or <code>upsert()</code> methods.</p> <p>Cause:</p> <p>There are several reasons why the addition may be slow:</p> <ul> <li>Very large batches</li> <li>Slow embeddings</li> <li>Slow network</li> </ul> <p>Let's break down each of the factors.</p> <p>Very large batches</p> <p>If you are trying to add 1000s or even 10,000s of documents at once and depending on how much data is already in your collection Chroma (specifically the HNSW graph updates) can become a bottleneck.</p> <p>To debug if this is the case you can reduce the size of the batch and see if the operation is faster. You can also check how many records are in the collection with <code>count()</code> method.</p> <p>Slow embeddings</p> <p>This is the most common reason for slow addition. Some embedding functions are slower than others. To debug this you can try the following example by adjusting the embeding function to your own. What the code tests is how much it takes to compute the embedings and then to add them to the collection in separate steps such that each can be measured independenty.</p> <pre><code>from chromadb.utils import embedding_functions\nimport chromadb\nimport uuid\n\nlist_of_sentences = [\"Hello world!\", \"How are you?\"] # this should be your list of documents to add\n\n# change the below EF definition to match your embedding function\ndefault_ef = embedding_functions.DefaultEmbeddingFunction() \n\nstart_time = time.perf_counter()\nembeddings=default_ef(list_of_sentences)\nend_time = time.perf_counter()\nprint(f\"Embedding time: {end_time - start_time}\")\n\nclient = chromadb.PersistentClient(path=\"my_chroma_data\")\ncollection = client.get_or_create_collection(\"my_collection\")\n\nstart_time = time.perf_counter()\n# this will add your documents and the generated embeddings without Chroma doing the embedding for you internally\ncollection.add(ids=[f\"{uuid.uuid4()}\" for _ in range(len(list_of_sentences))],documents=list_of_sentences, embeddings=embeddings)\nend_time = time.perf_counter()\nprint(f\"Chroma add time: {end_time - start_time}\")\n</code></pre> <p>Slow network</p> <p>If you are adding documents to a remote Chroma the network speed can become a bottleneck. To debug this you can with a local <code>PersistentClient</code> and see if the operation is faster.</p>"},{"location":"integrations/langchain/","title":"Chroma Integrations With LangChain","text":"<ul> <li>Embeddings - learn how to use Chroma Embedding functions with LC and vice versa</li> <li>Retrievers - learn how to use LangChain retrievers with Chroma</li> </ul>"},{"location":"integrations/langchain/embeddings/","title":"Langchain Embeddings","text":""},{"location":"integrations/langchain/embeddings/#embedding-functions","title":"Embedding Functions","text":"<p>Chroma and Langchain both offer embedding functions which are wrappers on top of popular embedding models.</p> <p>Unfortunately Chroma and LC's embedding functions are not compatible with each other. Below we offer two adapters to convert Chroma's embedding functions to LC's and vice versa.</p> <p>Links:</p> <ul> <li>Chroma Embedding Functions Definition</li> <li>Langchain Embedding Functions Definition</li> </ul>"},{"location":"integrations/langchain/embeddings/#chroma-built-in-langchain-adapter","title":"Chroma Built-in Langchain Adapter","text":"<p>As of version <code>0.5.x</code> Chroma offers a built-in two-way adapter to convert Langchain's embedding function to an adapted embeddings that can be used by both LC and Chroma. Implementation can be found here.</p> HuggingFaceOpenAI <p>Find out more about Langchain's HuggingFace embeddings here.</p> <pre><code># pip install chromadb langchain langchain-huggingface langchain-chroma\nimport chromadb\nfrom chromadb.utils.embedding_functions import create_langchain_embedding\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\nlangchain_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n\nef = create_langchain_embedding(langchain_embeddings)\nclient = chromadb.PersistentClient(path=\"./chroma-data\")\ncollection = client.get_or_create_collection(name=\"my_collection\", embedding_function=ef)\n\ncollection.add(ids=[\"1\"],documents=[\"test document goes here\"])\n</code></pre> <p>Find out more about Langchain's OpenAI embeddings here.</p> <pre><code># pip install chromadb langchain langchain-openai langchain-chroma\nimport chromadb\nfrom chromadb.utils.embedding_functions import create_langchain_embedding\nfrom langchain_openai import OpenAIEmbeddings\n\nlangchain_embeddings = OpenAIEmbeddings(\n    model=\"text-embedding-3-large\",\n    api_key=os.environ[\"OPENAI_API_KEY\"],\n)\nef = create_langchain_embedding(langchain_embeddings)\nclient = chromadb.PersistentClient(path=\"/chroma-data\")\ncollection = client.get_or_create_collection(name=\"my_collection\", embedding_function=ef)\n\ncollection.add(ids=[\"1\"],documents=[\"test document goes here\"])\n</code></pre>"},{"location":"integrations/langchain/embeddings/#custom-adapter","title":"Custom Adapter","text":"<p>Here is the adapter to convert Chroma's embedding functions to LC's:</p> <pre><code>from langchain_core.embeddings import Embeddings\nfrom chromadb.api.types import EmbeddingFunction\n\n\nclass ChromaEmbeddingsAdapter(Embeddings):\n    def __init__(self, ef: EmbeddingFunction):\n        self.ef = ef\n\n    def embed_documents(self, texts):\n        return self.ef(texts)\n\n    def embed_query(self, query):\n        return self.ef([query])[0]\n</code></pre> <p>Here is the adapter to convert LC's embedding function s to Chroma's:</p> <pre><code>from langchain_core.embeddings import Embeddings\nfrom chromadb.api.types import EmbeddingFunction, Documents\n\n\nclass LangChainEmbeddingAdapter(EmbeddingFunction[Documents]):\n    def __init__(self, ef: Embeddings):\n        self.ef = ef\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        # LC EFs also have embed_query but Chroma doesn't support that so we just use embed_documents\n        # TODO: better type checking\n        return self.ef.embed_documents(input)\n</code></pre>"},{"location":"integrations/langchain/embeddings/#example-usage","title":"Example Usage","text":"<p>Using Chroma Embedding Functions with Langchain:</p> <pre><code># pip install chromadb langchain langchain-huggingface langchain-chroma\nfrom langchain.vectorstores.chroma import Chroma\nfrom chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n\ntexts = [\"foo\", \"bar\", \"baz\"]\n\ndocs_vectorstore = Chroma.from_texts(\n    texts=texts,\n    collection_name=\"docs_store\",\n    embedding=ChromaEmbeddingsAdapter(SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")),\n)\n</code></pre> <p>Using Langchain Embedding Functions with Chroma:</p> <pre><code># pip install chromadb langchain langchain-huggingface langchain-chroma\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport chromadb\n\nclient = chromadb.Client()\n\ncollection = client.get_or_create_collection(\"test\", embedding_function=LangChainEmbeddingAdapter(\n    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")))\ncollection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"foo\", \"bar\", \"baz\"])\n</code></pre>"},{"location":"integrations/langchain/retrievers/","title":"\ud83e\udd9c\u26d3\ufe0f Langchain Retriever","text":"<p>TBD: describe what retrievers are in LC and how they work.</p>"},{"location":"integrations/langchain/retrievers/#vector-store-retriever","title":"Vector Store Retriever","text":"<p>In the below example we demonstrate how to use Chroma as a vector store retriever with a filter query.</p> <p>Note that the filter is supplied whenever we create the retriever object so the filter applies to all queries (<code>get_relevant_documents</code>).</p> <pre><code>from langchain.document_loaders import OnlinePDFLoader\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nfrom langchain.vectorstores import Chroma\nfrom typing import Dict, Any\nimport chromadb\nfrom langchain_core.embeddings import Embeddings\n\nclient = chromadb.PersistentClient(path=\"./chroma\")\n\ncol = client.get_or_create_collection(\"test\")\n\ncol.upsert([f\"{i}\" for i in range(10)],documents=[f\"This is document #{i}\" for i in range(10)],metadatas=[{\"id\":f\"{i}\"} for i in range(10)])\n\nef = chromadb.utils.embedding_functions.DefaultEmbeddingFunction()\n\nclass DefChromaEF(Embeddings):\n  def __init__(self,ef):\n    self.ef = ef\n\n  def embed_documents(self,texts):\n    return self.ef(texts)\n\n  def embed_query(self, query):\n    return self.ef([query])[0]\n\n\ndb = Chroma(client=client, collection_name=\"test\",embedding_function=DefChromaEF(ef))\n\nretriever = db.as_retriever(search_kwargs={\"filter\":{\"id\":\"1\"}})\n\ndocs = retriever.get_relevant_documents(\"document\")\n\nassert len(docs)==1\n</code></pre> <p>Ref: https://colab.research.google.com/drive/1L0RwQVVBtvTTd6Le523P4uzz3m3fm0pH#scrollTo=xROOfxLohE5j</p>"},{"location":"integrations/llamaindex/","title":"Chroma Integrations With LlamaIndex","text":"<ul> <li>Embeddings - learn how to use LlamaIndex embeddings functions with Chroma and vice versa</li> </ul>"},{"location":"integrations/llamaindex/embeddings/","title":"LlamaIndex Embeddings","text":""},{"location":"integrations/llamaindex/embeddings/#embedding-functions","title":"Embedding Functions","text":"<p>Chroma and LlamaIndex both offer embedding functions which are wrappers on top of popular embedding models.</p> <p>Unfortunately Chroma and LI's embedding functions are not compatible with each other. Below we offer an adapters to convert LI embedding function to Chroma one.</p> <pre><code>from llama_index.core.schema import TextNode\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\nfrom chromadb import EmbeddingFunction, Documents, Embeddings\n\n\nclass LlamaIndexEmbeddingAdapter(EmbeddingFunction):\n    def __init__(self, ef: BaseEmbedding):\n        self.ef = ef\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        return [node.embedding for node in self.ef([TextNode(text=doc) for doc in input])]\n</code></pre> <p>Text modality</p> <p>The above adapter assumes that the input documents are text. If you are using a different modality,  you will need to modify the adapter accordingly.</p> <p>An example of how to use the above with LlamaIndex:</p> <p>Prerequisites for example</p> <p>Run <code>pip install llama-index chromadb llama-index-embeddings-fastembed fastembed</code></p> <pre><code>import chromadb\nfrom llama_index.embeddings.fastembed import FastEmbedEmbedding\n\n# make sure to include the above adapter and imports\nembed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test_collection\", embedding_function=LlamaIndexEmbeddingAdapter(embed_model))\n\ncol.add(ids=[\"1\"], documents=[\"this is a test document\"])\n</code></pre>"},{"location":"integrations/ollama/","title":"Chroma Integrations With Ollama","text":"<ul> <li>Embeddings - learn how to use Ollama as embedder for Chroma documents</li> <li>\u2728<code>Coming soon</code> RAG with Ollama - a primer on how to build a simple RAG app with Ollama and Chroma</li> </ul>"},{"location":"integrations/ollama/embeddings/","title":"Ollama","text":"<p>Ollama offers out-of-the-box embedding API which allows you to generate embeddings for your documents. Chroma provides a convenient wrapper around Ollama's embedding API.</p>"},{"location":"integrations/ollama/embeddings/#ollama-embedding-models","title":"Ollama Embedding Models","text":"<p>While you can use any of the ollama models including LLMs to generate embeddings. We generally recommend using specialized models like <code>nomic-embed-text</code> for text embeddings. The latter models are specifically trained for embeddings and are more efficient for this purpose (e.g. the dimensions of the output embeddings are much smaller than those from LLMs e.g. 1024 - nomic-embed-text vs 4096 - llama3)</p> <p>Models:</p> Model Pull Ollama Registry Link <code>nomic-embed-text</code> <code>ollama pull nomic-embed-text</code> nomic-embed-text <code>mxbai-embed-large</code> <code>ollama pull mxbai-embed-large</code> mxbai-embed-large <code>snowflake-arctic-embed</code> <code>ollama pull snowflake-arctic-embed</code> snowflake-arctic-embed <code>all-minilm-l6-v2</code> <code>ollama pull chroma/all-minilm-l6-v2-f32</code> all-minilm-l6-v2-f32"},{"location":"integrations/ollama/embeddings/#basic-usage","title":"Basic Usage","text":"<p>First let's run a local docker container with Ollama. We'll pull <code>nomic-embed-text</code> model:</p> <pre><code>docker run -d --rm -v ./ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\ndocker exec -it ollama ollama run nomic-embed-text # press Ctrl+D to exit after model downloads successfully\n# test it\ncurl http://localhost:11434/api/embeddings -d '{\"model\": \"nomic-embed-text\",\"prompt\": \"Here is an article about llamas...\"}'\n</code></pre> <p>Ollama Docs</p> <p>For more information on Ollama, visit the Ollama GitHub repository.</p> <p>Using the CLI</p> <p>If you have or prefer to use the Ollama CLI, you can use the following command to get a model:</p> <pre><code>ollama pull nomic-embed-text\n</code></pre> <p>Now let's configure our OllamaEmbeddingFunction Embedding (python) function with the default Ollama endpoint:</p>"},{"location":"integrations/ollama/embeddings/#python","title":"Python","text":"<pre><code>import chromadb\nfrom chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n\nclient = chromadb.PersistentClient(path=\"ollama\")\n\n# create EF with custom endpoint\nef = OllamaEmbeddingFunction(\n    model_name=\"nomic-embed-text\",\n    url=\"http://localhost:11434/api/embeddings\",\n)\n\nprint(ef([\"Here is an article about llamas...\"]))\n</code></pre>"},{"location":"integrations/ollama/embeddings/#javascript","title":"JavaScript","text":"<p>For JS users, you can use the <code>OllamaEmbeddingFunction</code> class to create embeddings:</p> <pre><code>const {OllamaEmbeddingFunction} = require('chromadb');\nconst embedder = new OllamaEmbeddingFunction({\n    url: \"http://localhost:11434/api/embeddings\",\n    model: \"nomic-embed-text\"\n})\n\n// use directly\nconst embeddings = embedder.generate([\"Here is an article about llamas...\"])\n</code></pre>"},{"location":"integrations/ollama/embeddings/#golang","title":"Golang","text":"<p>For Golang you can use the <code>chroma-go</code> client's <code>OllamaEmbeddingFunction</code> embedding function to generate embeddings for your documents:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    ollama \"github.com/amikos-tech/chroma-go/ollama\"\n)\n\nfunc main() {\n    documents := []string{\n        \"Document 1 content here\",\n        \"Document 2 content here\",\n    }\n    // the `/api/embeddings` endpoint is automatically appended to the base URL\n    ef, err := ollama.NewOllamaEmbeddingFunction(ollama.WithBaseURL(\"http://127.0.0.1:11434\"), ollama.WithModel(\"nomic-embed-text\"))\n    if err != nil {\n        fmt.Printf(\"Error creating Ollama embedding function: %s \\n\", err)\n    }\n    resp, err := ef.EmbedDocuments(context.Background(), documents)\n    if err != nil {\n        fmt.Printf(\"Error embedding documents: %s \\n\", err)\n    }\n    fmt.Printf(\"Embedding response: %v \\n\", resp)\n}\n</code></pre> <p>Golang Client</p> <p>You can install the Golang client by running the following command:</p> <pre><code>go get github.com/amikos-tech/chroma-go\n</code></pre> <p>For more information visit https://go-client.chromadb.dev/</p>"},{"location":"running/deployment-patterns/","title":"Deployment Patterns","text":"<p>In this section we'll cover a patterns of how to deploy Chroma for your GenAI applications.</p>"},{"location":"running/deployment-patterns/#embedded-in-your-application","title":"Embedded in your application","text":""},{"location":"running/deployment-patterns/#standalone-server","title":"Standalone server","text":""},{"location":"running/deployment-patterns/#_1","title":"Deployment Patterns","text":""},{"location":"running/health-checks/","title":"Health Checks","text":""},{"location":"running/health-checks/#docker-compose","title":"Docker Compose","text":"<p>The simples form of health check is to use the <code>healthcheck</code> directive in the <code>docker-compose.yml</code> file. This is useful if you are deploying Chroma alongside other services that may depend on it.</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: server\n    build:\n      context: .\n      dockerfile: Dockerfile\n    volumes:\n      # Be aware that indexed data are located in \"/chroma/chroma/\"\n      # Default configuration for persist_directory in chromadb/config.py\n      # Read more about deployments: https://docs.trychroma.com/deployment\n      - chroma-data:/chroma/chroma\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n    ports:\n      - 8000:8000\n    healthcheck:\n      test: [ \"CMD\", \"/bin/bash\", \"-c\", \"cat &lt; /dev/null &gt; /dev/tcp/localhost/8001\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\nvolumes:\n  chroma-data:\n    driver: local\n</code></pre>"},{"location":"running/health-checks/#kubernetes","title":"Kubernetes","text":"<p>In kubernetes you can use the <code>livenessProbe</code> and <code>readinessProbe</code> to check the health of the server. This is useful if you are deploying Chroma in a kubernetes cluster.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chroma\n  labels:\n    app: chroma\nspec:\n    replicas: 1\n    selector:\n        matchLabels:\n          app: chroma\n    template:\n        metadata:\n            labels:\n                app: chroma\n        spec:\n            containers:\n              - name: chroma\n                image: &lt;chroma-image&gt;\n                ports:\n                - containerPort: 8000\n                livenessProbe:\n                    httpGet:\n                        path: /api/v1\n                        port: 8000\n                    initialDelaySeconds: 5\n                    periodSeconds: 5\n                readinessProbe:\n                    httpGet:\n                        path: /api/v1\n                        port: 8000\n                    initialDelaySeconds: 5\n                    periodSeconds: 5\n                startupProbe:\n                    httpGet:\n                      path: /api/v1\n                      port: 8000\n                    failureThreshold: 3\n                    periodSeconds: 60\n                    initialDelaySeconds: 60\n</code></pre> <p>Alternative to the <code>httpGet</code> you can also use <code>tcpSocket</code>:</p> <pre><code>          readinessProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            timeoutSeconds: 30\n            periodSeconds: 60\n          livenessProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            timeoutSeconds: 30\n            periodSeconds: 60\n          startupProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            periodSeconds: 60\n            initialDelaySeconds: 60\n</code></pre>"},{"location":"running/maintenance/","title":"Maintenance","text":"<p>This section describes maintenance tooling and procedures for running your Chroma database.</p>"},{"location":"running/maintenance/#chroma-ops-tooling","title":"Chroma Ops (Tooling)","text":"<p>Chroma Ops is a maintenance CLI for Chroma. It provides a set of commands for inspecting, configuring and improving the performance of your Chroma database.</p>"},{"location":"running/maintenance/#use-cases","title":"Use Cases","text":"<p>Chroma Ops is designed to help you maintain a healthy Chroma database. It can also be used for inspecting the state of your database. The following use cases are supported:</p> <ul> <li>\ud83d\udce6 Database Maintenance</li> <li><code>db info</code> - gathers general information about your Chroma persistent database</li> <li><code>db clean</code> - cleans up the database from unused files (for now only orphanated HNSW segment directories)</li> <li>\ud83d\udcdd Write-Ahead Log (WAL) Maintenance</li> <li><code>wal info</code> - gathers information about the Write-Ahead Log (WAL)</li> <li><code>wal commit</code> - commits the WAL to all collections with outstanding changes</li> <li><code>wal export</code> - exports the WAL to a <code>jsonl</code> file. This can be used for debugging and for auditing.</li> <li><code>wal config</code> - allows you to configure the WAL for your Chroma database.</li> <li><code>wal clean</code> - cleans up the WAL from old, committed transactions.</li> <li>\ud83d\udd0d Full Text Search (FTS) Maintenance</li> <li><code>fts rebuild</code> - rebuilds the FTS index for all collections or change the tokenizer.</li> <li>\ud83e\uddec Vector Index (HNSW) Maintenance</li> <li><code>hnsw info</code> - gathers information about the HNSW index for a given collection</li> <li><code>hnsw rebuild</code> - rebuilds the HNSW index for a given collection and allows the modification of otherwise immutable (construction-only) parameters. Useful command to keep your HNSW index healthy and prevent fragmentation.</li> <li><code>hnsw config</code> - allows you to configure the HNSW index for your Chroma database.</li> <li>\ud83d\udcf8 Collection Maintenance</li> <li><code>collection snapshot</code> - creates a snapshot of a collection. The snapshots are self-contained and are meant to be used for backup and restore.</li> </ul> <p>Need help/Need more?</p> <p>If you need help or need more features, please join the Discord server and let us know. Or just do a pull request on GitHub.</p>"},{"location":"running/maintenance/#installation","title":"Installation","text":"<p>Chroma Ops can be installed using pip:</p> <pre><code>pip install --upgrade chromadb-ops\n</code></pre>"},{"location":"running/maintenance/#usage","title":"Usage","text":""},{"location":"running/maintenance/#database-maintenance","title":"Database Maintenance","text":""},{"location":"running/maintenance/#database-info","title":"Database Info","text":"<p>What it does: Gathers general information about your Chroma persistent database (works only for local persistent databases).</p> <p>Why it's useful: Run this command to better understand the current state of your database. It can provide you with invaluable information about any potential issues and also helps us help you in debugging issues.</p> <pre><code>chops db info /path/to/persist_dir\n</code></pre> <p>Options:</p> <ul> <li><code>--skip-collection-names</code> (<code>-s</code>) - to skip specific collections</li> <li><code>--privacy-mode</code> (<code>-p</code>) - privacy mode hides paths and collection names so that the output can be shared without   exposing sensitive information</li> </ul> <p>When sharing larger outputs consider storing the output in a file:</p> <pre><code>chops db info /path/to/persist_dir -p &gt; chroma_info.txt\n</code></pre> <p>Example output:</p> <pre><code>chops db info smallc\n\n                                 General Info\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                    Property \u2503 Value                                          \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502              Chroma Version \u2502 0.5.5                                          \u2502\n\u2502        Number of Collection \u2502 1                                              \u2502\n\u2502           Persist Directory \u2502 /tmp/tmp9l3ceuvp                               \u2502\n\u2502      Persist Directory Size \u2502 142.2MiB                                       \u2502\n\u2502              SystemDB size: \u2502 81.6MiB (/tmp/tmp9l3ceuvp/chroma.sqlite3)      \u2502\n\u2502     Orphan HNSW Directories \u2502 []                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Collections \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 test \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                             'test' Collection Data\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503         Table Data \u2503 Value                                                   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502                 ID \u2502 9e80e4fd-fd4b-47b8-810c-e8ffa57c1912                    \u2502\n\u2502               Name \u2502 test                                                    \u2502\n\u2502           Metadata \u2502 None                                                    \u2502\n\u2502          Dimension \u2502 1536                                                    \u2502\n\u2502             Tenant \u2502 default_tenant                                          \u2502\n\u2502           Database \u2502 default_database                                        \u2502\n\u2502            Records \u2502 10,000                                                  \u2502\n\u2502        WAL Entries \u2502 10,000                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Segments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                            Metadata Segment (test)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                Property \u2503 Value                                              \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502              Segment ID \u2502 832fa2cd-6c40-4eee-ad7d-35f260acaaaa               \u2502\n\u2502                    Type \u2502 urn:chroma:segment/metadata/sqlite                 \u2502\n\u2502                   Scope \u2502 METADATA                                           \u2502\n\u2502        SysDB Max Seq ID \u2502 10,000                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              HNSW Segment (test)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503                     Property \u2503 Value                                         \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502                   Segment ID \u2502 13609103-d317-4556-a744-008c96229b72          \u2502\n\u2502                         Type \u2502 urn:chroma:segment/vector/hnsw-local-persist\u2026 \u2502\n\u2502                        Scope \u2502 VECTOR                                        \u2502\n\u2502                         Path \u2502 /tmp/tmp9l3ceuvp/13609103-d317-4556-a744-008\u2026 \u2502\n\u2502             SysDB Max Seq ID \u2502 0                                             \u2502\n\u2502                HNSW Dir Size \u2502 60.6MiB                                       \u2502\n\u2502     HNSW Metadata Max Seq ID \u2502 10,000                                        \u2502\n\u2502   HNSW Metadata Total Labels \u2502 10,000                                        \u2502\n\u2502                      WAL Gap \u2502 0                                             \u2502\n\u2502 HNSW Raw Total Active Labels \u2502 10,000                                        \u2502\n\u2502    HNSW Raw Allocated Labels \u2502 10,000                                        \u2502\n\u2502           HNSW Orphan Labels \u2502 set()                                         \u2502\n\u2502          Fragmentation Level \u2502 0.0                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>\u26a0\ufe0f Interesting things to look for:</p> <ul> <li>Fragmentation Level - the higher the value the more unnecessary memory and performance hits your HNSW index suffers.   It needs to be rebuilt.</li> <li>Orphan HNSW Directories - these are directories that are not associated with any collection. They can be safely   deleted.</li> <li>WAL Entries - high values usually means that you need prune your WAL. Use either this tool or   the official Chroma CLI.</li> <li>HNSW Orphan Labels - this must always be empty set, if you see anything else report it   in Discord @taz.</li> </ul> <p>How to Read the output</p> <p>General Info</p> <p>This section presents general Chroma persistent dir info.</p> <ul> <li>Chroma Version - the currently installed Chroma version.</li> <li>Number of Collection - the number of collections in the persistent dir.</li> <li>Persist Directory - the path to the persistent dir (if privacy mode is off).</li> <li>Persist Directory Size - the size of the persistent dir.</li> <li>SystemDB size - the size of the system database (if privacy mode is off the full path to the sqlite3 file is shown).</li> <li>Orphan HNSW Directories - a list of orphan HNSW directories. These directories are present in the persistent dir but   are not associated with any collection.</li> </ul> <p>Collections</p> <ul> <li>ID - the collection ID.</li> <li>Name - the collection name.</li> <li>Metadata - the metadata associated with the collection.</li> <li>Dimension - the dimension of the embeddings in the collection. (this can be None in case no vectors are present and   the collection is newly created).</li> <li>Tenant - the tenant of the collection.</li> <li>Database - the database of the collection.</li> <li>Records - the number of records in the collection.</li> <li>WAL Entries - the number of WAL entries in the collection (as of 0.5.5 for new instances Chroma will clean WAL for   each collection periodically).</li> </ul> <p>Metadata Segment</p> <ul> <li>Segment ID - the segment ID.</li> <li>Type - the segment type.</li> <li>Scope - the segment scope.</li> <li>SysDB Max Seq ID - the maximum sequence ID in the system database.</li> </ul> <p>HNSW Segment</p> <ul> <li>Segment ID - the segment ID.</li> <li>Type - the segment type.</li> <li>Scope - the segment scope.</li> <li>Path - the path to the HNSW directory.</li> <li>SysDB Max Seq ID - the maximum sequence ID in the system database.</li> <li>HNSW Dir Size - the size of the HNSW directory.</li> <li>HNSW Metadata Max Seq ID - the maximum sequence ID in the HNSW metadata.</li> <li>HNSW Metadata Total Labels - the total number of labels in the HNSW metadata.</li> <li>WAL Gap - the difference between the maximum sequence ID in the system database and the maximum sequence ID in the   HNSW   metadata. The gap usually represents the number of WAL entries that are not committed to the HNSW index.</li> <li>HNSW Raw Total Active Labels - the total number of active labels in the HNSW index.</li> <li>HNSW Raw Allocated Labels - the total number of allocated labels in the HNSW index.</li> <li>HNSW Orphan Labels - a set of orphan labels in the HNSW index. These are labels in the HNSW index that are not visible   to Chroma as they are not part of the metadata. This set should always be empty, if not please report it!!!</li> <li>Fragmentation Level - the fragmentation level of the HNSW index.</li> </ul>"},{"location":"running/maintenance/#database-clean","title":"Database Clean","text":"<p>What it does: Cleans up the database from unused files. It will remove all orphanated HNSW segment directories.</p> <p>Why it's useful: Orphanated HNSW segment directories sometimes are the byproduct of a filesystem failure to remove the HNSW segment directory, most commonly encountered on Windows systems, but any type of file loocking or disk operation failure can cause Chroma to leave behind these directories.</p> <pre><code>chops db clean /path/to/persist_dir\n</code></pre> <p>Supported options are:</p> <ul> <li><code>--dry-run</code> (<code>-d</code>) - to see what would be deleted without actually deleting anything.</li> </ul> <p>Example output:</p> <pre><code>chops db clean smallc\nChromaDB version: 0.6.2\nCleaning up orphanated segment dirs...\n\n                             Orphanated HNSW segment dirs                             \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Segment ID                           \u2503 Path                                        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 2E9021A8-A767-4339-B2C2-2F4B22C05F1D \u2502 smallc/2E9021A8-A767-4339-B2C2-2F4B22C05F1D \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to delete these segment dirs? [y/N]: \n</code></pre>"},{"location":"running/maintenance/#wal-maintenance","title":"WAL Maintenance","text":""},{"location":"running/maintenance/#wal-info","title":"WAL Info","text":"<p>What it does: Gathers information about the Write-Ahead Log (WAL).</p> <p>Why it's useful: Run this command to better understand the current state of the Write-Ahead Log (WAL). It can provide you with invaluable information about any potential issues and also helps us help you in debugging issues.</p> <pre><code>chops wal info /path/to/persist_dir\n</code></pre> <p>Example output:</p> <pre><code>chops wal info smallc\nChromaDB version: 0.6.2\n\nWAL config is set to: auto purge.\n                                         WAL Info                                         \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Collection \u2503 Topic                                                             \u2503 Count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 test       \u2502 persistent://default/default/97f5234e-d02a-43b8-9909-99447950c949 \u2502 20    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"running/maintenance/#wal-export","title":"WAL Export","text":"<p>What it does: Exports the Write-Ahead Log (WAL) to a <code>jsonl</code> file. This can be used for debugging and for auditing.</p> <p>Why it's useful: This command is useful for exporting the Write-Ahead Log (WAL) to a <code>jsonl</code> file. This can be used for debugging and for auditing.</p> <pre><code>chops wal export /path/to/persist_dir\n</code></pre> <p>Example output:</p> <pre><code>chops wal export smallc --out wal.jsonl\nChromaDB version: 0.6.2\n       Exporting WAL        \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Collection \u2503 WAL Entries \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 test       \u2502 20          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to export the WAL? [y/N]: y\nExported 20 rows\n</code></pre>"},{"location":"running/maintenance/#wal-commit","title":"WAL Commit","text":"<p>What it does: Commits the Write-Ahead Log (WAL) to all collections with outstanding changes.</p> <p>Why it's useful: This command is useful for committing the Write-Ahead Log (WAL) to all collections with outstanding changes.</p> <pre><code>chops wal commit /path/to/persist_dir\n</code></pre> <p>Options:</p> <ul> <li><code>--skip</code> (<code>-s</code>) - skip certain collections by running <code>chops wal commit /path/to/persist_dir --skip &lt;collection_name&gt;</code></li> <li><code>--yes</code> (<code>-y</code>) - skip confirmation prompt (default: <code>False</code>, prompt will be shown)</li> </ul> <p>Example output:</p> <pre><code>chops wal commit smallc\nChromaDB version: 0.6.2\n     WAL Commit Summary     \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Collection \u2503 WAL Entries \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 test       \u2502 20          \u2502\n\u2502 test1      \u2502 0           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n   Skipped    \n Collections  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Collection \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to commit the WAL in smallc? As part of the WAL commit action your database will be migrated to currently installed version 0.6.2. [y/N]: y\nProcessing index for collection test (0137d64b-8d71-42f5-b0d9-28716647b068) - total vectors in index 20\nWAL commit completed.\n</code></pre>"},{"location":"running/maintenance/#wal-clean","title":"WAL Clean","text":"<p>What it does: Cleans up the Write-Ahead Log (WAL) from committed transactions. Recent Chroma version automatically prune the WAL so this is not needed unless you have older version of Chroma or disabled automatic WAL pruning.</p> <p>Why it's useful: Keep your WAL in check so it doesn't grow too large (in case automatic WAL pruning is disabled).</p> <pre><code>chops wal clean /path/to/persist_dir\n</code></pre> <p>Options:</p> <ul> <li><code>--yes</code> (<code>-y</code>) - skip confirmation prompt (default: <code>False</code>, prompt will be shown)</li> </ul> <p>Example output:</p> <pre><code>chops wal clean smallc                                                                                                                                                                                                                                                                        11:33:36  \u2601  main \u2602 \u26a1 \u272d\nChromaDB version: 0.6.2\nSize before: 429596\n\nAre you sure you want to clean up the WAL in smallc? This action will delete all WAL entries that are not committed to the HNSW index. [y/N]: y\nCleaning up WAL\nWAL cleaned up. Size after: 388636\n</code></pre>"},{"location":"running/maintenance/#wal-configuration","title":"WAL Configuration","text":"<p>What it does: Configures the Write-Ahead Log (WAL) for your Chroma database.</p> <p>Why it's useful: This command is useful for configuring the Write-Ahead Log (WAL) for your Chroma database.</p> <pre><code>chops wal config /path/to/persist_dir --purge off\n</code></pre> <p>Options:</p> <ul> <li><code>--purge</code> option can be set to <code>auto</code> (automatically purge the WAL when the number of records in the collection exceeds the number of   records in the WAL) or <code>off</code> (disable automatic purge of the WAL). Automatic WAL purge is enabled by default. The automatic purge keeps your slite3 file smaller and faster, but it makes it hard or impossible to restore Chroma.</li> <li><code>--yes</code> option can be set to <code>true</code> (skip confirmation prompt) or <code>false</code> (show confirmation prompt). The default is <code>false</code>.</li> </ul> <p>Example output:</p> <pre><code>chops wal config smallc --purge off\nChromaDB version: 0.6.2\n                           Current WAL config                            \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Config key                                \u2503 Config Change             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Automatically purge (automatically_purge) \u2502 True (old) -&gt; False (new) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to update the WAL config? [y/N]: y\nWAL config updated successfully!\n</code></pre>"},{"location":"running/maintenance/#full-text-search-fts-maintenance","title":"Full Text Search (FTS) Maintenance","text":""},{"location":"running/maintenance/#fts-rebuild","title":"FTS Rebuild","text":"<p>What it does: Rebuilds the Full Text Search (FTS) index for all collections.</p> <p>Why it's useful: This command is useful for rebuilding the Full Text Search (FTS) index for all collections.</p> <pre><code>chops fts rebuild /path/to/persist_dir\n</code></pre> <p>Additional options:</p> <ul> <li><code>--yes</code> (<code>-y</code>) - skip confirmation prompt (default: <code>False</code>, prompt will be shown)</li> <li><code>--tokenizer</code> (<code>-t</code>) - the tokenizer to use for the index.</li> </ul> <p>Example output:</p> <pre><code>chops fts rebuild --tokenizer unicode61 smallc\nChromaDB version: 0.6.2\n\nAre you sure you want to rebuild the FTS index in smallc? This action will drop the existing FTS index and create a new one. [y/N]: y\nRebuilt FTS. Will try to start your Chroma now.\nNOTE: Depending on the size of your documents in Chroma it may take a while for Chroma to start up again.\nChroma started successfully. FTS rebuilt.\n</code></pre>"},{"location":"running/maintenance/#hnsw-maintenance","title":"HNSW Maintenance","text":""},{"location":"running/maintenance/#hnsw-info","title":"HNSW Info","text":"<p>What it does: Gathers information about the HNSW index for a given collection.</p> <p>Why it's useful: This command is useful for gathering information about the HNSW index for a given collection.</p> <pre><code>chops hnsw info /path/to/persist_dir\n</code></pre> <p>Additional options:</p> <ul> <li><code>--collection</code> (<code>-c</code>) - the collection name</li> <li><code>--verbose</code> (<code>-v</code>) - If specified, the HNSW index will be loaded for more accurate fragmentation level reporting.</li> </ul> <p>Example output:</p> <pre><code>chops hnsw info smallc -c test\nChromaDB version: 0.6.2\n    HNSW details for collection test in default_database database    \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Metric              \u2503 Value                                       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Space               \u2502 cosine                                      \u2502\n\u2502 Dimensions          \u2502 384                                         \u2502\n\u2502 EF Construction     \u2502 200                                         \u2502\n\u2502 EF Search           \u2502 100                                         \u2502\n\u2502 M                   \u2502 64                                          \u2502\n\u2502 Number of threads   \u2502 16                                          \u2502\n\u2502 Resize factor       \u2502 1.2                                         \u2502\n\u2502 Batch size          \u2502 100                                         \u2502\n\u2502 Sync threshold      \u2502 1000                                        \u2502\n\u2502 Segment ID          \u2502 0137d64b-8d71-42f5-b0d9-28716647b068        \u2502\n\u2502 Path                \u2502 smallc/0137d64b-8d71-42f5-b0d9-28716647b068 \u2502\n\u2502 Has metadata        \u2502 True                                        \u2502\n\u2502 Number of elements  \u2502 20                                          \u2502\n\u2502 Collection ID       \u2502 97f5234e-d02a-43b8-9909-99447950c949        \u2502\n\u2502 Index size          \u2502 41.6KiB                                     \u2502\n\u2502 Fragmentation level \u2502 0.00% (estimated)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"running/maintenance/#hnsw-rebuild","title":"HNSW Rebuild","text":"<p>What it does: Rebuilds the HNSW index for a given collection and allows the modification of otherwise immutable (construction-only) parameters.</p> <p>Why it's useful: This command is useful for rebuilding the HNSW index for a given collection and allows the modification of otherwise immutable (construction-only) parameters.</p> <pre><code>chops hnsw rebuild /path/to/persist_dir\n</code></pre> <p>Example output:</p> <pre><code>chops hnsw rebuild smallc -c test --m 64 --construction-ef 200\nChromaDB version: 0.6.2\n    HNSW details for collection test in default_database database    \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Metric              \u2503 Value                                       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Space               \u2502 cosine                                      \u2502\n\u2502 Dimensions          \u2502 384                                         \u2502\n\u2502 EF Construction     \u2502 200                                         \u2502\n\u2502 EF Search           \u2502 100                                         \u2502\n\u2502 M                   \u2502 64                                          \u2502\n\u2502 Number of threads   \u2502 16                                          \u2502\n\u2502 Resize factor       \u2502 1.2                                         \u2502\n\u2502 Batch size          \u2502 100                                         \u2502\n\u2502 Sync threshold      \u2502 1000                                        \u2502\n\u2502 Segment ID          \u2502 0137d64b-8d71-42f5-b0d9-28716647b068        \u2502\n\u2502 Path                \u2502 smallc/0137d64b-8d71-42f5-b0d9-28716647b068 \u2502\n\u2502 Has metadata        \u2502 True                                        \u2502\n\u2502 Number of elements  \u2502 20                                          \u2502\n\u2502 Collection ID       \u2502 97f5234e-d02a-43b8-9909-99447950c949        \u2502\n\u2502 Index size          \u2502 47.6KiB                                     \u2502\n\u2502 Fragmentation level \u2502 0.00% (estimated)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    HNSW segment config changes     \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Config Key           \u2503 Old \u2503 New \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 hnsw:construction_ef \u2502 100 \u2502 200 \u2502\n\u2502 hnsw:M               \u2502 102 \u2502 64  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to rebuild this index? [y/N]: y\nBackup of old index created at smallc/0137d64b-8d71-42f5-b0d9-28716647b068_backup_20250208100514\n    HNSW details for collection test in default_database database    \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Metric              \u2503 Value                                       \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Space               \u2502 cosine                                      \u2502\n\u2502 Dimensions          \u2502 384                                         \u2502\n\u2502 EF Construction     \u2502 200                                         \u2502\n\u2502 EF Search           \u2502 100                                         \u2502\n\u2502 M                   \u2502 64                                          \u2502\n\u2502 Number of threads   \u2502 16                                          \u2502\n\u2502 Resize factor       \u2502 1.2                                         \u2502\n\u2502 Batch size          \u2502 100                                         \u2502\n\u2502 Sync threshold      \u2502 1000                                        \u2502\n\u2502 Segment ID          \u2502 0137d64b-8d71-42f5-b0d9-28716647b068        \u2502\n\u2502 Path                \u2502 smallc/0137d64b-8d71-42f5-b0d9-28716647b068 \u2502\n\u2502 Has metadata        \u2502 True                                        \u2502\n\u2502 Number of elements  \u2502 20                                          \u2502\n\u2502 Collection ID       \u2502 97f5234e-d02a-43b8-9909-99447950c949        \u2502\n\u2502 Index size          \u2502 41.6KiB                                     \u2502\n\u2502 Fragmentation level \u2502 0.00%                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"running/maintenance/#hnsw-configuration","title":"HNSW Configuration","text":"<p>What it does: Configures the HNSW index for your Chroma database.</p> <p>Why it's useful: This command is useful for configuring the HNSW index for your Chroma database.</p> <pre><code>chops hnsw config /path/to/persist_dir --collection &lt;collection_name&gt;\n</code></pre> <p>Options:</p> <ul> <li><code>--search-ef</code> (<code>-e</code>) - the search ef to use for the index.</li> <li><code>--num-threads</code> (<code>-t</code>) - the number of threads to use for the index.</li> <li><code>--resize-factor</code> (<code>-r</code>) - the resize factor to use for the index.</li> <li><code>--batch-size</code> (<code>-b</code>) - the batch size to use for the index.</li> <li><code>--sync-threshold</code> (<code>-s</code>) - the sync threshold to use for the index.</li> </ul> <p>Example output:</p> <pre><code>chops hnsw config smallc -c test --search-ef 100\nChromaDB version: 0.6.2\n HNSW segment config changes  \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Config Key     \u2503 Old \u2503 New \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 hnsw:search_ef \u2502 110 \u2502 100 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to apply these changes? [y/N]: y\nHNSW index configuration modified successfully\n</code></pre>"},{"location":"running/maintenance/#collection-maintenance","title":"Collection Maintenance","text":""},{"location":"running/maintenance/#collection-snapshot","title":"Collection Snapshot","text":"<p>What it does: Creates a snapshot of a collection. The snapshots are self-contained sqlite3 files.</p> <p>Why it's useful: The command is useful if you want to create a backup or a point-in-time copy of a collection in its entirety. The snapshot files are self-contained and use sqlite3 as a storage engine. You can use <code>sqlite3</code> commands to inspect the snapshot files.</p> <pre><code>chops collection snapshot /path/to/persist_dir --collection &lt;collection_name&gt; -o /path/to/snapshot.sqlite3\n</code></pre> <p>Additional options:</p> <ul> <li><code>--yes</code> (<code>-y</code>) - skip confirmation prompt (default: <code>False</code>, prompt will be shown)</li> <li><code>--collection</code> (<code>-c</code>) - the collection name</li> <li><code>--output</code> (<code>-o</code>) - the path to the output snapshot file</li> </ul> <p>Example output:</p> <pre><code>chops collection snapshot ./smallc --collection test -o snapshot.sqlite3\nChromaDB version: 0.6.2\n\nAre you sure you want to overwrite /Users/tazarov/experiments/chroma/chromadb-ops/snapshot.sqlite3 file? [y/N]: y\nBootstrapping snapshot database...\nSnapshot database bootstrapped in /Users/tazarov/experiments/chroma/chromadb-ops/snapshot.sqlite3\nCopying collection test to snapshot database...\n  Copying collection to snapshot   \n            database...            \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Table                   \u2503 Count \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Embeddings Queue        \u2502 20    \u2502\n\u2502 Max Seq ID              \u2502 1     \u2502\n\u2502 Embeddings              \u2502 20    \u2502\n\u2502 Embedding Metadata      \u2502 20    \u2502\n\u2502 Segments                \u2502 2     \u2502\n\u2502 Segment Metadata        \u2502 3     \u2502\n\u2502 Collections             \u2502 1     \u2502\n\u2502 Collection Metadata     \u2502 0     \u2502\n\u2502 HNSW Segment Data Files \u2502 5     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAre you sure you want to copy this collection to the snapshot database? [y/N]: y\nCollection test copied to snapshot database in /Users/tazarov/experiments/chroma/chromadb-ops/snapshot.sqlite3\n</code></pre>"},{"location":"running/performance-tips/","title":"Performance Tips","text":"<p>This section covers tips and tricks of how to improve your Chroma performance.</p>"},{"location":"running/performance-tips/#rebuild-hnsw-for-your-architecutre","title":"Rebuild HNSW for your architecutre","text":"<p>Single node chroma core package and server ship with a default HNSW build which is optimized for maximum compatibility. The default HNSW does not make use of available optimization for your CPU architecture such as SIMD/AVX.</p> <p>You can rebuild the HNSW index for the core package or the server as follows.</p> Core PackageServer <p>To rebuild the HNSW index locally you may need to install build tooling such as <code>gcc</code> depending on your operating system.</p> <pre><code>pip install --no-binary :all: chroma-hnswlib\n</code></pre> <p>In the following snippet, we clone the Chroma repository (you'll need git and docker installed), and then build a new docker image with the HNSW rebuild flag set to <code>true</code>.</p> <pre><code>git clone https://github.com/chroma-core/chroma.git &amp;&amp; cd chroma\ndocker build --build-arg REBUILD_HNSWLIB=true -t my-chroma-image:latest .\n</code></pre> Need help? <p>If you need help with the above steps, please reach out to us on Discord (look for <code>@taz</code>)</p>"},{"location":"running/performance-tips/#reducing-shortening-the-dimensionality-of-your-embeddings","title":"Reducing (shortening) the dimensionality of your embeddings","text":"<p>Some embeddings models (or APIs) offer the ability to reduce the dimensionality of the resulting embeddings. This is a great way to reduce the storage and memory requirements of your Chroma.</p> <p>Currently the following embedding functions support this feature:</p> <ul> <li>OpenAI with 3rd generation models (i.e. <code>text-embedding-3-small</code> and <code>text-embedding-3-large</code>)</li> </ul>"},{"location":"running/performance-tips/#openai-example","title":"OpenAI Example","text":"<p>For more information on shortening embeddings see the official OpenAI Blog post.</p> PythonJavascript <pre><code>from chromadb.utils.embedding_functions.openai_embedding_function import (\n    OpenAIEmbeddingFunction,\n)\nimport os\n\nef = OpenAIEmbeddingFunction(api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"text-embedding-3-small\", dimensions=64)\nembeddings = ef([\"hello world\"])\n</code></pre> <pre><code>import  {OpenAIEmbeddingFunction} from \"chromadb\"\n\nconst embedder = new OpenAIEmbeddingFunction({\n        openai_api_key: process.env.OPENAI_API_KEY,\n        openai_embedding_dimensions: 64,\n        openai_model: \"text-embedding-3-small\",\n    });\nconst embeddings = embedder.generate([\"hello world\"]);\n</code></pre>"},{"location":"running/road-to-prod/","title":"Road To Production","text":"<p>In this section we will cover considerations for operating Chroma ina production environment.</p> <p>To operate Chroma in production your deployment must follow your organization's best practices and guidelines around business continuity, security, and compliance. Here we will list the core concepts and offer some guidance on how to achieve them.</p> <p>Core system abilities:</p> <ul> <li>High Availability - The deployment should be able to handle failures while continuing to serve requests.</li> <li>Scalability - The deployment should be able to handle increased load by adding more resources (aka scale   horizontally).</li> <li>Privacy and Security - The deployment should protect data from unauthorized access and ensure data integrity.</li> <li>Observability - The deployment should provide metrics and logs to help operators understand the system's health.</li> <li>Backup and Restore - The deployment should have a backup and restore strategy to protect against data loss.</li> <li>Disaster Recovery - The deployment should have a disaster recovery plan to recover from catastrophic failures.</li> <li>Maintenance - The deployment should be easy to maintain and upgrade.</li> </ul> <p>While our guidance is most likely incomplete it can be taken as a compliment to your own organizational processes. For those deploying Chroma in a smaller enterprise without such processes, we advise common sense and caution.</p>"},{"location":"running/road-to-prod/#high-availability","title":"High Availability","text":""},{"location":"running/road-to-prod/#scalability","title":"Scalability","text":""},{"location":"running/road-to-prod/#privacy-and-security","title":"Privacy and Security","text":""},{"location":"running/road-to-prod/#data-security","title":"Data Security","text":""},{"location":"running/road-to-prod/#in-transit","title":"In Transit","text":"<p>The bare minimum for securing data in transit is to use HTTPS when performing Chroma API calls. This ensures that data is encrypted when it is sent over the network.</p> <p>There are several ways to achieve this:</p> <ul> <li>Use a reverse proxy like Envoy or Nginx to terminate SSL/TLS connections.</li> <li>Use a load balancer like AWS ELB or Google Cloud Load Balancer to terminate SSL/TLS connections (technically a Envoy   and Nginx are also LBs).</li> <li>Use a service mesh like Istio or Linkerd to manage SSL/TLS connections between services.</li> <li>Enable SSL/TLS in your Chroma server.</li> </ul> <p>Depending on your requirements you may choose one or more of these options.</p> <p>Reverse Proxy:</p> <p>Load Balancer:</p> <p>Service Mesh:</p> <p>Chroma Server:</p>"},{"location":"running/road-to-prod/#at-rest","title":"At Rest","text":""},{"location":"running/road-to-prod/#access-control","title":"Access Control","text":""},{"location":"running/road-to-prod/#authentication","title":"Authentication","text":""},{"location":"running/road-to-prod/#authorization","title":"Authorization","text":""},{"location":"running/road-to-prod/#observability","title":"Observability","text":""},{"location":"running/road-to-prod/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"running/road-to-prod/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"running/road-to-prod/#maintenance","title":"Maintenance","text":""},{"location":"running/running-chroma/","title":"Running Chroma","text":""},{"location":"running/running-chroma/#local-server","title":"Local Server","text":"<p>Article Link</p> <p>This article is also available on Medium Running ChromaDB \u2014 Part 1: Local Server.</p>"},{"location":"running/running-chroma/#chroma-cli","title":"Chroma CLI","text":"<p>The simplest way to run Chroma locally is via the Chroma <code>cli</code> which is part of the core Chroma package.</p> <p>Prerequisites:</p> <ul> <li>Python 3.8 to 3.11 - Download Python | Python.org</li> </ul> <pre><code>pip install chromadb\nchroma run --host localhost --port 8000 --path ./my_chroma_data\n</code></pre> <p><code>--host</code> The host to which to listen to, by default it is <code>[localhost](http://localhost:8000/docs)</code> , but if you want to expose it to your entire network then you can specify `0.0.0.0``</p> <p><code>--port</code> The port on which to listen to, by default this is <code>8000</code>.</p> <p><code>--path</code> The path where to persist your Chroma data locally.</p> <p>Target Path Install</p> <p>It is possible to install Chroma in a specific directory by running <code>pip install chromadb -t /path/to/dir</code>. To run Chroma CLI from the installation dir expor the Python Path <code>export PYTHONPATH=$PYTHONPATH:/path/to/dir</code>.</p>"},{"location":"running/running-chroma/#docker","title":"Docker","text":"<p>Running Chroma server locally can be achieved via a simple docker command as shown below.</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> </ul> <pre><code>docker run -d --rm --name chromadb -p 8000:8000 -v ./chroma:/chroma/chroma -e IS_PERSISTENT=TRUE -e ANONYMIZED_TELEMETRY=TRUE chromadb/chroma:0.6.3\n</code></pre> <p>Options:</p> <ul> <li><code>-p 8000:8000</code> specifies the port on which the Chroma server will be exposed.</li> <li><code>-v</code> specifies a local dir which is where Chroma will store its data so when the container is destroyed the data   remains. Note: If you are using <code>-e PERSIST_DIRECTORY</code> then you need to point the volume to that directory.</li> <li><code>-e</code> <code>IS_PERSISTENT=TRUE</code> let\u2019s Chroma know to persist data</li> <li><code>-e</code> <code>PERSIST_DIRECTORY=/path/in/container</code> specifies the path in the container where the data will be stored, by   default it is <code>/chroma/chroma</code></li> <li><code>-e ANONYMIZED_TELEMETRY=TRUE</code> allows you to turn on (<code>TRUE</code>) or off (<code>FALSE</code>) anonymous product telemetry which helps   the Chroma team in making informed decisions about Chroma OSS and commercial direction.</li> <li><code>chromadb/chroma:5.11</code> indicates the Chroma release version.</li> </ul>"},{"location":"running/running-chroma/#docker-compose-cloned-repo","title":"Docker Compose (Cloned Repo)","text":"<p>If you are feeling adventurous you can also use the Chroma <code>main</code> branch to run a local Chroma server with the latest changes:</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>Git - Git - Downloads (git-scm.com)</li> </ul> <pre><code>git clone https://github.com/chroma-core/chroma &amp;&amp; cd chroma\ndocker compose up -d --build\n</code></pre> <p>If you want to run a specific version of Chroma you can checkout the version tag you need:</p> <pre><code>git checkout release/0.6.3\n</code></pre>"},{"location":"running/running-chroma/#docker-compose-without-cloning-the-repo","title":"Docker Compose (Without Cloning the Repo)","text":"<p>If you do not wish or are able to clone the repo locally, Chroma server can also be run with docker compose by creating (or using a gist) a <code>docker-compose.yaml</code></p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>cURL (if you want to use the gist approach)</li> </ul> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\nservices:\n  chromadb:\n    image: chromadb/chroma:0.6.3\n    volumes:\n      - ./chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma # this is the default path, change it as needed\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n    ports:\n      - 8000:8000\n    networks:\n      - net\n</code></pre> <p>The above will create a container with the latest Chroma (<code>chromadb/chroma:0.6.3</code>), will expose it to port <code>8000</code> on the local machine and will persist data in <code>./chromadb</code> relative path from where the <code>docker-compose.yaml</code> has been ran.</p> <p>Versioning</p> <p>When running Chroma with docker compose try to pin the version to a specific release. This will ensure intentional upgrades and avoid potential issues (usually with clients).</p> <p>We have also created a small gist with the above file for convenience:</p> <pre><code>curl -s https://gist.githubusercontent.com/tazarov/4fd933274bbacb3b9f286b15c01e904b/raw/87268142d64d8ee0f7f98c27a62a5d089923a1df/docker-compose.yaml | docker-compose -f - up\n</code></pre>"},{"location":"running/running-chroma/#minikube-with-helm-chart","title":"Minikube With Helm Chart","text":"<p>Note: This deployment can just as well be done with <code>KinD</code> depending on your preference.</p> <p>A more advanced approach to running Chroma locally (but also on a remote cluster) is to deploy it using a Helm chart.</p> <p>Disclaimer: The chart used here is not a 1st party chart, but is contributed by a core contributor to Chroma.</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>Install minikube - minikube start | minikube (k8s.io)</li> <li>kubectl - Install Tools | Kubernetes</li> <li>Helm - Helm | Installing Helm</li> </ul> <p>Once you have all of the above running Chroma in a local <code>minikube</code> cluster quite simple</p> <p>Create a <code>minikube</code> cluster:</p> <pre><code>minikube start --addons=ingress -p chroma\nminikube profile chroma\n</code></pre> <p>Get and install the chart:</p> <pre><code>helm repo add chroma https://amikos-tech.github.io/chromadb-chart/\nhelm repo update\nhelm install chroma chroma/chromadb --set chromadb.apiVersion=\"0.6.3\"\n</code></pre> <p>By default the chart will enable authentication in Chroma. To get the token run the following:</p> <pre><code>kubectl --namespace default get secret chromadb-auth -o jsonpath=\"{.data.token}\" | base64 --decode\n# or use this to directly export variable\nexport CHROMA_TOKEN=$(kubectl --namespace default get secret chromadb-auth -o jsonpath=\"{.data.token}\" | base64 --decode)\n</code></pre> <p>The first step to connect and start using Chroma is to forward your port:</p> <pre><code>minikube service chroma-chromadb --url\n</code></pre> <p>The above should print something like this:</p> <pre><code>http://127.0.0.1:61892\n\u2757  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.\n</code></pre> <p>Note: Depending on your OS the message might be slightly different.</p> <p>Test it out (<code>pip install chromadb</code>):</p> <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(host=\"http://127.0.0.1:61892\",\n                             settings=Settings(\n                                 chroma_client_auth_provider=\"chromadb.auth.token.TokenAuthClientProvider\",\n                                 chroma_client_auth_credentials=\"&lt;your_chroma_token&gt;\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\n\nclient.get_version()  # this should work with or without authentication - it is a public endpoint\n\nclient.list_collections()  # this is a protected endpoint and requires authentication\n</code></pre> <p>For more information about the helm chart consult - https://github.com/amikos-tech/chromadb-chart</p>"},{"location":"running/systemd-service/","title":"Systemd service","text":"<p>You can run Chroma as a systemd service which wil allow you to automatically start Chroma on boot and restart it if it crashes.</p>"},{"location":"running/systemd-service/#docker-compose","title":"Docker Compose","text":"<p>The following is an examples systemd service for running Chroma using Docker Compose.</p> <p>Create a file <code>/etc/systemd/system/chroma.service</code> with the following content:</p> <p>Example assumptions</p> <p>The below example assumes Debian-based system with docker-ce installed.</p> <pre><code>[Unit]\nDescription = Chroma Service\nAfter = network.target docker.service\nRequires = docker.service\n\n[Service]\nType = forking\nUser = root\nGroup = root\nWorkingDirectory = /home/admin/chroma\nExecStart = /usr/bin/docker compose up -d\nExecStop = /usr/bin/docker compose down\nRemainAfterExit = true\n\n[Install]\nWantedBy = multi-user.target\n</code></pre> <p>Replace <code>WorkingDirectory</code> with the path to your docker compose is. You may also need to replace <code>/usr/bin/docker</code> with the path to your docker binary.</p> <p>Alternatively you can install directly from a gist:</p> <pre><code>wget https://gist.githubusercontent.com/tazarov/9c46966de0b32a4962dcc79dce8b2646/raw/7cf8c471f33fba8a51d6f808f9b1af6ca1b0923c/chroma-docker.service \\\n  -O /etc/systemd/system/chroma.service\n</code></pre> <p>Loading, enabling and starting the service:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable chroma\nsudo systemctl start chroma\n</code></pre> <p>Type=forking</p> <p>In the above example, we use <code>Type=forking</code> because Docker Compose runs in the background (<code>-d</code>). If you are using a different command that runs in the foreground, you may need to use <code>Type=simple</code> instead.</p>"},{"location":"running/systemd-service/#chroma-cli","title":"Chroma CLI","text":"<p>The following is an examples systemd service for running Chroma using the Chroma CLI.</p> <p>Create a file <code>/etc/systemd/system/chroma.service</code> with the following content:</p> <p>Example assumptions</p> <p>The below example assumes that Chroma is installed in Python <code>site-packages</code> package.</p> <pre><code>[Unit]\nDescription = Chroma Service\nAfter = network.target\n\n[Service]\nType = simple\nUser = root\nGroup = root\nWorkingDirectory = /chroma\nExecStart=/usr/local/bin/chroma run --host 127.0.0.1 --port 8000 --path /chroma/data --log-path /var/log/chroma.log\n\n[Install]\nWantedBy = multi-user.target\n</code></pre> <p>Replace the <code>WorkingDirectory</code>, <code>/chroma/data</code> and <code>/var/log/chroma.log</code> with the appropriate paths.</p> <p>Safe Config</p> <p>The above example service listens and <code>localhost</code> which may not work if you are looking to expose Chroma to outside world. Adjust the <code>--host</code> and <code>--port</code> flags as needed.</p> <p>Alternatively you can install from a gist:</p> <pre><code>wget https://gist.githubusercontent.com/tazarov/5e10ce892c06757d8188a8a34cd6d26d/raw/327a9d0b07afeb0b0cb77453aa9171fdd190984f/chroma-cli.service \\\n  -O /etc/systemd/system/chroma.service\n</code></pre> <p>Loading, enabling and starting the service:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable chroma\nsudo systemctl start chroma\n</code></pre> <p>Type=simple</p> <p>In the above example, we use <code>Type=simple</code> because the Chroma CLI runs in the foreground. If you are using a different command that runs in the background, you may need to use <code>Type=forking</code> instead.</p>"},{"location":"security/","title":"Security","text":"<p>Security is an important topic and this section is devoted to it.</p> <p>There are many ways to secure a service, such as Chroma and this section attempts to encompass the most common use cases.</p> <p>Way to secure Chroma include:</p> <ul> <li>In-transit encryption using SSL/TLS certificates</li> <li>Access control</li> <li>At-rest encryption</li> <li>Adding authentication and authorization</li> </ul>"},{"location":"security/#ssltls-certificates","title":"SSL/TLS Certificates","text":"<p>Securing your Chroma with a proxy is one of the most common ways to secure your Chroma. Ensuring that all traffic between your client and Chroma server is encrypted is a good practice.</p> <p>There are multiple ways to secure your Chroma instance using SSL/TLS certificates and here we'll explore a few.</p> <ul> <li>SSL/TLS certificate in Chroma server - configure and use SSL/TLS certificates directly in Chroma.</li> <li>Proxy with SSL/TLS termination - use a proxy to terminate SSL/TLS and forward traffic to Chroma.</li> <li>(Coming soon) Cloud Provider API Gateway with SSL/TLS termination - use a cloud provider's API Gateway to terminate SSL/TLS and   forward traffic to Chroma.</li> </ul>"},{"location":"security/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>Chroma offers built-in authentication and authorization mechanisms to secure your Chroma instance.</p> <ul> <li>Chroma-native Auth - Configure Chroma built-in authentication and authorization.</li> </ul>"},{"location":"security/auth/","title":"Chroma-native Auth","text":"<p>Chroma offers built in authentication and authorization mechanisms to secure your Chroma instance.</p> <p>Auth Disabled by Default</p> <p>By default, Chroma does not require authentication. You must enable it manually. If you are deploying Chroma in a public-facing  environment, it is highly recommended to enable authentication.</p> <p>Auth needs the company of SSL/TLS</p> <p>Authentication without encryption is insecure. If you are deploying Chroma in a public-facing environment, it is highly recommended that you add (SSL/TLS)[ssl-proxy.md].</p>"},{"location":"security/auth/#authentication","title":"Authentication","text":"<p>Chroma supports two types of authentication:</p> <ul> <li>Basic Auth - RFC 7617 compliant pre-emptive authentication with username and password credentials in Authorization header.</li> <li>Token Auth - Standard token-based auth with <code>Authorization</code> or <code>X-Chroma-Token</code> headers.</li> </ul> <p>For each authentication method there are configurations in both client and server.</p>"},{"location":"security/auth/#basic-authentication","title":"Basic Authentication","text":"<p>Server</p> <p>Generate a password file with bcrypt hashed password:</p> <pre><code>docker run --rm --entrypoint htpasswd httpd:2 -Bbn admin password123 &gt;&gt; server.htpasswd\n</code></pre> <p>Verify the password file:</p> <pre><code>docker run --rm -v ./server.htpasswd:/server.htpasswd --entrypoint htpasswd httpd:2 -vb /server.htpasswd admin password123\n</code></pre> Multiple users <p>Chroma supports multiple users in the htpasswd file. You can add multiple users by running the command multiple  times WITHOUT <code>-c</code> flag.</p> Frequently encountered Chroma errors <p>If you see the following error:</p> <pre><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n</code></pre> <p>It is likely that you have not used the <code>-B</code> (bcrypt) flag when creating the password file.</p> <p>Environment variables:</p> <pre><code>export CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=\"server.htpasswd\"\nexport CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.basic_authn.BasicAuthenticationServerProvider\"\n</code></pre> <p>Running the server:</p> CLIDockerDocker Compose <pre><code>export CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=\"server.htpasswd\"\nexport CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.basic_authn.BasicAuthenticationServerProvider\"\nchroma run --path /chroma-data\n</code></pre> <pre><code>docker run --rm -v ./server.htpasswd:/chroma/server.htpasswd \\\n -e CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=\"server.htpasswd\" \\\n -e CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.basic_authn.BasicAuthenticationServerProvider\" \\\n -p 8000:8000 \\\n chromadb/chroma:latest\n</code></pre> <p>Create a <code>docker-compose.yaml</code> with the following content:</p> <pre><code>networks:\n  net:\n    driver: bridge\nservices:\n  chromadb:\n    image: chromadb/chroma:latest\n    volumes:\n      - ./chromadb:/chroma/chroma\n      - ./server.htpasswd:/chroma/server.htpasswd\n    environment:\n      - IS_PERSISTENT=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma # this is the default path, change it as needed\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=server.htpasswd\n      - CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.basic_authn.BasicAuthenticationServerProvider\n    ports:\n      - 8000:8000\n    networks:\n      - net\n</code></pre> <p>Run the following command to start the Chroma server:</p> <pre><code>docker compose -f docker-compose.yaml up -d\n</code></pre> Is my config right? <p>If you have correctly configured the server you should see the following line in the server logs:</p> <pre><code>Starting component BasicAuthenticationServerProvider\n</code></pre> <p>Client</p> Python SyncPython AsyncJSGoJava <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n  settings=Settings(\n      chroma_client_auth_provider=\"chromadb.auth.basic_authn.BasicAuthClientProvider\",\n      chroma_client_auth_credentials=\"admin:admin\")\n)\n\n# if everything is correctly configured the below should list all collections\nclient.list_collections()\n</code></pre> <pre><code>import chromadb\nimport base64\n\nbase64_credentials = base64.b64encode(b\"admin:admin\").decode(\"utf-8\")\n\nclient = await chromadb.AsyncHttpClient(headers={\"Authorization\": f\"Basic {base64_credentials}\"})\n</code></pre> <pre><code>// const {ChromaClient} = require(\"chromadb\"); // CommonJS\nimport { ChromaClient } from \"chromadb\"; // ES Modules\nconst client = new ChromaClient({\n    url: \"http://localhost:8000\",\n    auth: {\n        provider: \"basic\",\n        credentials: \"admin:admin\",\n    }\n});\n</code></pre> <pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    chroma \"github.com/amikos-tech/chroma-go\"\n  \"github.com/amikos-tech/chroma-go/types\"\n)\n\nfunc main() {\n    client, err := chroma.NewClient(\n        chroma.WithBasePath(\"http://localhost:8000\"),\n        chroma.WithAuth(types.NewBasicAuthCredentialsProvider(\"admin\", \"admin\")),\n    )\n    if err != nil {\n        log.Fatalf(\"Error creating client: %s \\n\", err)\n    }\n    _, err = client.ListCollections(context.TODO())\n    if err != nil {\n        log.Fatalf(\"Error calling ListCollections: %s \\n\", err)\n    }\n}\n</code></pre> <p>The below example shows auth with just headers. A more robust authentication mechanism is being implemented.</p> <pre><code>package tech.amikos;\n\nimport tech.amikos.chromadb.*;\nimport tech.amikos.chromadb.Collection;\n\nimport java.util.*;\n\npublic class Main {\n    public static void main(String[] args) {\n        try {\n            Client client = new Client(System.getenv(\"http://localhost:8000\"));\n            client.setDefaultHeaders(new HashMap&lt;&gt;() {{\n                put(\"Authorization\", \"Basic \" + Base64.getEncoder().encodeToString(\"admin:admin\".getBytes()));\n            }});\n            // your code here\n        } catch (Exception e) {\n            System.out.println(e);\n        }\n    }\n}\n</code></pre> Testing with cURL <pre><code>curl -v http://localhost:8000/api/v1/collections -u user1:change_this_password\n</code></pre>"},{"location":"security/auth/#token-authentication","title":"Token Authentication","text":"<p>Server</p> <p>Environment variables:</p> <pre><code>export CHROMA_SERVER_AUTHN_CREDENTIALS=\"chr0ma-t0k3n\"\nexport CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.token_authn.TokenAuthenticationServerProvider\"\nexport CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=\"Authorization\" # or X-Chroma-Token\n</code></pre> <p>Auth Headers</p> <p>Chroma supports two token transport headers:</p> <ul> <li><code>Authorization</code> (default) - the clients are expected to pass <code>Authorization: Bearer &lt;token&gt;</code> header</li> <li><code>X-Chroma-Token</code> - the clients are expected to pass <code>X-Chroma-Token: &lt;token&gt;</code> header</li> </ul> <p>The header can be configured via <code>CHROMA_AUTH_TOKEN_TRANSPORT_HEADER</code> environment variable.</p> <p>Running the server:</p> CLIDockerDocker Compose <pre><code>export CHROMA_SERVER_AUTHN_CREDENTIALS=\"chr0ma-t0k3n\"\nexport CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.token_authn.TokenAuthenticationServerProvider\"\nexport CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=\"Authorization\"\nchroma run --path /chroma-data\n</code></pre> <pre><code>docker run --rm -e CHROMA_SERVER_AUTHN_CREDENTIALS=\"chr0ma-t0k3n\" \\\n -e CHROMA_SERVER_AUTHN_PROVIDER=\"chromadb.auth.token_authn.TokenAuthenticationServerProvider\" \\\n -e CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=\"Authorization\" \\\n -p 8000:8000 \\\n chromadb/chroma:latest\n</code></pre> <p>Create a <code>docker-compose.yaml</code> with the following content:</p> <pre><code>networks:\n  net:\n    driver: bridge\nservices:\n  chromadb:\n    image: chromadb/chroma:latest\n    volumes:\n      - ./chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma # this is the default path, change it as needed\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS=\"chr0ma-t0k3n\"\n      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=\"Authorization\"\n      - CHROMA_SERVER_AUTHN_PROVIDER=chromadb.auth.token_authn.TokenAuthenticationServerProvider\n    ports:\n      - 8000:8000\n    networks:\n      - net\n</code></pre> <p>Run the following command to start the Chroma server:</p> <pre><code>docker compose -f docker-compose.yaml up -d\n</code></pre> Is my config right? <p>If you have correctly configured the server you should see the following line in the server logs:</p> <pre><code>Starting component TokenAuthenticationServerProvider\n</code></pre> <p>Client</p> Python SyncPython AsyncJSGoJava <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n  settings=Settings(\n      chroma_client_auth_provider=\"chromadb.auth.token_authn.TokenAuthClientProvider\",\n      chroma_client_auth_credentials=\"chr0ma-t0k3n\",\n      chroma_auth_token_transport_header=\"Authorization\"\n  )\n)\n\n# if everything is correctly configured the below should list all collections\nclient.list_collections()\n</code></pre> <pre><code>import chromadb\n# for Authorization header\nclient = await chromadb.AsyncHttpClient(headers={\"Authorization\": \"Bearer chr0ma-t0k3n\"})\n# for X-Chroma-Token header\nclient = await chromadb.AsyncHttpClient(headers={\"X-Chroma-Token\": \"chr0ma-t0k3n\"})\n\n# if everything is correctly configured the below should list all collections\nawait client.list_collections()\n</code></pre> <pre><code>// const {ChromaClient} = require(\"chromadb\"); // CommonJS\nimport { ChromaClient } from \"chromadb\"; // ES Modules\nconst client = new ChromaClient({\n    url: \"http://localhost:8000\",\n    auth: {\n        provider: \"token\",\n        credentials: \"chr0ma-t0k3n\",\n    }\n});\n</code></pre> <pre><code>package main\n\nimport (\n    \"context\"\n    \"log\"\n    chroma \"github.com/amikos-tech/chroma-go\"\n    \"github.com/amikos-tech/chroma-go/types\"\n)\n\nfunc main() {\n    client, err := chroma.NewClient(\n        chroma.WithBasePath(\"http://localhost:8000\"), \n        chroma.WithAuth(types.NewTokenAuthCredentialsProvider(\"chr0ma-t0k3n\", types.AuthorizationTokenHeader)),\n    )\n    if err != nil {\n        log.Fatalf(\"Error creating client: %s \\n\", err)\n    }\n    _, err = client.ListCollections(context.TODO())\n    if err != nil {\n        log.Fatalf(\"Error calling ListCollections: %s \\n\", err)\n    }\n}\n</code></pre> <p>The example below shows authorization with just headers. A more robust auth mechanism is under implementation.</p> <pre><code>package tech.amikos;\n\nimport tech.amikos.chromadb.*;\nimport tech.amikos.chromadb.Collection;\n\nimport java.util.*;\n\npublic class Main {\n    public static void main(String[] args) {\n        try {\n            Client client = new Client(System.getenv(\"http://localhost:8000\"));\n            client.setDefaultHeaders(new HashMap&lt;&gt;() {{\n                put(\"Authorization\", \"Bearer chr0ma-t0k3n\");\n            }});\n            // your code here\n        } catch (Exception e) {\n            System.out.println(e);\n        }\n    }\n}\n</code></pre> Testing with cURL <pre><code>curl -v http://localhost:8000/api/v1/collections -H \"Authorization: Bearer chr0ma-t0k3n\"\n</code></pre>"},{"location":"security/auth/#authorization","title":"Authorization","text":"<p>Coming soon!</p>"},{"location":"security/chroma-ssl-cert/","title":"SSL/TLS Certificates in Chroma","text":"<p>Chroma uses uvicorn as an ASGI server, which can be configured to use SSL/TLS certificates.</p> <p>CLI not supported</p> <p>Using certificates with Chroma CLI is not yet supported.</p> Performance Impact <p>Using certificates within Chroma will have a performance impact as <code>uvicorn</code> will need to hnadle  the encryption and decryption of the data. If performance is of concern,  consider using a reverse proxy like <code>nginx</code> or <code>envoy</code> to handle the SSL/TLS termination.</p>"},{"location":"security/chroma-ssl-cert/#self-signed-certificates","title":"Self-Signed Certificates","text":""},{"location":"security/chroma-ssl-cert/#creating-a-self-signed-certificate","title":"Creating a self-signed certificate","text":"<p>Important</p> <p>The <code>SAN</code> (Subject Alternative Name) is required for the certificate to work as modern security standards require    the certificate to match the domain name.</p> <p>You will also need to create a <code>openssl.cnf</code> file in the same directory with the following content:</p> <pre><code>```ini\n[req]\ndistinguished_name = req_distinguished_name\nx509_extensions = usr_cert\n\n[req_distinguished_name]\nCN = $ENV::CHROMA_DOMAIN\n\n[usr_cert]\nsubjectAltName = DNS:$ENV::CHROMA_DOMAIN\n```\n</code></pre> Certificate Domain - CHROMA_DOMAIN <p>You can set the <code>CHROMA_DOMAIN</code> environment variable to the domain you want to use for the certificate. </p> OpenSSLDocker <p>To run the following you will need to have <code>openssl</code> installed on your system.</p> <pre><code>export CHROMA_DOMAIN=${CHROMA_DOMAIN:-\"localhost\"}\nopenssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 \\\n  -keyout certs/serverkey.pem \\\n  -subj '/O=Chroma/C=US' \\\n  -out certs/servercert.pem \\\n  -config openssl.cnf\n</code></pre> <p>This will create a self-signed certificate and key in the <code>certs</code> directory.</p> <p>If you are using Docker, you can use the following command to generate the certificates:</p> <pre><code>docker run --rm -v $(pwd)/certs:/certs \\\n  -v $(pwd)/openssl.cnf:/etc/ssl/openssl.cnf \\\n  -e CHROMA_DOMAIN=localhost \\\n  openquantumsafe/openssl3 \\\n  openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 \\\n  -keyout /certs/serverkey.pem \\\n  -subj '/O=Chroma/C=US' \\\n  -out /certs/servercert.pem \\\n  -config /etc/ssl/openssl.cnf\n</code></pre> Security Warning <p>Self-signed certificates are not recommended for production use. They are only suitable for testing and development purposes. Additionally in the above example the keyfile is not password protected, which is also not recommended for production use.</p>"},{"location":"security/chroma-ssl-cert/#configuring-and-running-chroma","title":"Configuring and running Chroma","text":"<p>You can run Chroma with the SSL/TLS certificate generate above or any other certificate you have.</p> DockerDocker Compose <p>To run Chroma with the self-signed certificate, you can use the following command:</p> <pre><code>docker run --rm -it -p 8000:8000 \\\n  -v $(pwd)/certs:/chroma/certs \\\n  chromadb/chroma:0.5.0 \\\n  --workers 1 \\\n  --host 0.0.0.0 \\\n  --port 8000 \\\n  --proxy-headers \\\n  --log-config chromadb/log_config.yml \\\n  --timeout-keep-alive 30 \\\n  --ssl-keyfile /chroma/certs/serverkey.pem \\\n  --ssl-certfile /chroma/certs/servercert.pem\n</code></pre> <p>To run Chroma with the self-signed certificate using Docker Compose, you can use the following <code>docker-compose.yml</code> file:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: chromadb/chroma:0.6.3\n    volumes:\n      # Be aware that indexed data are located in \"/chroma/chroma/\"\n      # Default configuration for persist_directory in chromadb/config.py\n      # Read more about deployments: https://docs.trychroma.com/deployment\n      - chroma-data:/chroma/chroma\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30 --ssl-keyfile /chroma/certs/serverkey.pem --ssl-certfile /chroma/certs/servercert.pem\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTHN_PROVIDER=${CHROMA_SERVER_AUTHN_PROVIDER}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=${CHROMA_SERVER_AUTHN_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS=${CHROMA_SERVER_AUTHN_CREDENTIALS}\n      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n    restart: unless-stopped\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n\nvolumes:\n  chroma-data:\n    driver: local\n</code></pre>"},{"location":"security/chroma-ssl-cert/#using-a-certificate-authority","title":"Using a Certificate Authority","text":"<p>Examples below will demonstrate how to use <code>certbot</code> to generate a certificate with a given certificate authority.</p>"},{"location":"security/chroma-ssl-cert/#lets-encrypt","title":"Let's Encrypt","text":"<p>Coming soon!</p>"},{"location":"security/chroma-ssl-cert/#aws-certificate-manager","title":"AWS Certificate Manager","text":"<p>Coming soon!</p>"},{"location":"security/ssl-proxies/","title":"SSL/TLS Proxy","text":"<p>In this section we'll explore how to secure Chroma with a TLS-terminated HTTPS proxy. Below we'll give two examples of how to do this using Envoy and Nginx. The certificates are self-signed and generated using OpenSSL, but in the future we'll also provide examples of how to achieve this with Let's Encrypt and certbot.</p>"},{"location":"security/ssl-proxies/#getting-the-cert","title":"Getting The cert","text":"<p>To manually generate a certificate follow the steps here.</p>"},{"location":"security/ssl-proxies/#envoy","title":"Envoy","text":"<p>The following envoy configuration will create a listener on port 443 that will forward all requests to the <code>chromadb</code>.</p> <pre><code>static_resources:\n  listeners:\n    - name: listener_0\n      address:\n        socket_address:\n          address: 0.0.0.0\n          port_value: 443\n      filter_chains:\n        - filters:\n            - name: envoy.filters.network.http_connection_manager\n              typed_config:\n                \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n                stat_prefix: ingress_http\n                route_config:\n                  name: chroma_route\n                  virtual_hosts:\n                    - name: local_chromadb\n                      domains: [ \"*\" ]\n                      routes:\n                        - match:\n                            prefix: \"/\"\n                          route:\n                            cluster: chromadb_service\n                            prefix_rewrite: \"/\"\n                http_filters:\n                  - name: envoy.filters.http.router\n                    typed_config:\n                      \"@type\": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router\n          transport_socket:\n            name: envoy.transport_sockets.tls\n            typed_config:\n              \"@type\": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext\n              common_tls_context:\n                tls_certificates:\n                  - certificate_chain:\n                      filename: \"/etc/envoy/certs/servercert.pem\"\n                    private_key:\n                      filename: \"/etc/envoy/certs/serverkey.pem\"\n  clusters:\n    - name: chromadb_service\n      connect_timeout: 0.25s\n      type: LOGICAL_DNS\n      lb_policy: ROUND_ROBIN\n      load_assignment:\n        cluster_name: chromadb_service\n        endpoints:\n          - lb_endpoints:\n              - endpoint:\n                  address:\n                    socket_address:\n                      address: chromadb\n                      port_value: 8000\n</code></pre> <p>Finally the docker compose to tie things up where we have added a <code>cert-gen</code> step to automatically generate the certificates, prior to starting the <code>envoy</code> and <code>chromadb</code> services.</p> <pre><code>version: '3'\nnetworks:\n  net:\n    driver: bridge\nservices:\n  cert-gen:\n    image: openquantumsafe/openssl3\n    volumes:\n      - ./certs:/certs\n      - ./openssl.cnf:/etc/ssl/openssl.cnf\n    command: |\n      sh -c \"[ -f /certs/servercert.pem ] || \\\n      openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -keyout /certs/serverkey.pem -out /certs/servercert.pem -subj '/O=Chroma/C=US' -config /etc/ssl/openssl.cnf\"\n    environment:\n      - CHROMA_DOMAIN=${CHROMA_DOMAIN:-localhost}\n  envoy:\n    image: bitnami/envoy\n    volumes:\n      - ./envoy.yaml:/opt/bitnami/envoy/conf/envoy.yaml\n      - ./certs:/etc/envoy/certs\n      - ./wait-for-certs.sh:/usr/local/bin/wait-for-certs.sh\n    ports:\n      - \"443:443\"\n    networks:\n      - net\n    depends_on:\n      cert-gen:\n        condition: service_completed_successfully\n      chromadb:\n        condition: service_healthy\n    entrypoint: |\n      sh -c \"/usr/local/bin/wait-for-certs.sh &amp;&amp; \\\n      /opt/bitnami/envoy/bin/envoy -c /opt/bitnami/envoy/conf/envoy.yaml\"\n  chromadb:\n    image: chromadb/chroma:0.6.3\n    volumes:\n      - ./chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n    networks:\n      - net\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n</code></pre>"},{"location":"security/ssl-proxies/#nginx","title":"Nginx","text":"<p>Use the following Nginx config (<code>nginx.conf</code>) as a starting point and build from there:</p> <pre><code>server {\n    listen 443 ssl;\n    server_name localhost;\n\n    ssl_certificate /etc/nginx/certs/servercert.pem;\n    ssl_certificate_key /etc/nginx/certs/serverkey.pem;\n\n    location / {\n        proxy_pass http://chromadb:8000;\n        proxy_set_header Host $host;\n        proxy_http_version 1.1;  # Use HTTP/1.1\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre> <p>Create a <code>docker-compose.yml</code> file with the following content:</p> <p>Config Files</p> <p>For the following <code>docker-compose.yaml</code> to operate successfully <code>openssl.cnf</code> and <code>nginx.conf</code> files need to be present in the same directory.</p> <pre><code>version: '3'\nnetworks:\n  net:\n    driver: bridge\nservices:\n  cert-gen:\n    image: openquantumsafe/openssl3\n    volumes:\n      - ./certs:/certs\n      - ./openssl.cnf:/etc/ssl/openssl.cnf\n    command: |\n      sh -c \"[ -f /certs/servercert.pem ] || \\\n      openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -keyout /certs/serverkey.pem -out /certs/servercert.pem -subj '/O=Chroma/C=US' -config /etc/ssl/openssl.cnf\"\n    environment:\n      - CHROMA_DOMAIN=${CHROMA_DOMAIN:-localhost}\n  chromadb:\n    image: chromadb/chroma:0.6.3\n    volumes:\n      - ./chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n  nginx:\n    image: nginx:latest\n    depends_on:\n      - cert-gen\n      - chromadb\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n      - ./certs:/etc/nginx/certs\n    networks:\n      - net\n    depends_on:\n      chromadb:\n        condition: service_healthy\n</code></pre>"},{"location":"strategies/backup/","title":"ChromaDB Backups","text":"<p>Depending on your use case there are a few different ways to back up your ChromaDB data.</p> <ul> <li>API export - this approach is relatively simple, slow for large datasets and may result in a backup that is missing   some updates, should your data change frequently.</li> <li>Disk snapshot - this approach is fast, but is highly dependent on the underlying storage. Should your cloud provider   and underlying volume support snapshots, this is a good option.</li> <li>Filesystem backup - this approach is also fast, but requires stopping your Chroma container to avoid data corruption.   This is a good option if you can afford to stop your Chroma container for a few minutes.</li> </ul> <p>Other Options</p> <p>Have another option in mind, feel free to add it to the above list.</p>"},{"location":"strategies/backup/#api-export","title":"API Export","text":""},{"location":"strategies/backup/#with-chroma-datapipes","title":"With Chroma Datapipes","text":"<p>One way to export via the API is to use Tooling like Chroma Data Pipes. Chroma Data Pipes is a command-line tool that provides a simple way import/export/transform ChromaDB data.</p> <p>Exporting from local filesystem:</p> <pre><code>cdp export \"file:///absolute/path/to/chroma-data/my-collection-name\" &gt; my_chroma_data.jsonl\n</code></pre> <p>Exporting from remote server:</p> <pre><code>cdp export \"http://remote-chroma-server:8000/my-collection-name\" &gt; my_chroma_data.jsonl\n</code></pre> <p>Get Help</p> <p>Read more about Chroma Data Pipes here</p>"},{"location":"strategies/backup/#disk-snapshot","title":"Disk Snapshot","text":"<p>TBD</p>"},{"location":"strategies/backup/#filesystem-backup","title":"Filesystem Backup","text":""},{"location":"strategies/backup/#from-docker-container","title":"From Docker Container","text":"<p>Sometimes you have been running Chroma in a Docker container without a host mount, intentionally or unintentionally. So all your data is now stored in the container's filesystem. Here's how you can back up your data:</p> <ol> <li>Stop the container:</li> </ol> <pre><code>docker stop &lt;chroma-container-id/name&gt;\n</code></pre> <ol> <li>Create a backup of the container's filesystem:</li> </ol> <pre><code>docker cp &lt;chroma-container-id/name&gt;:/chroma/chroma /path/to/backup\n</code></pre> <p><code>/path/to/backup</code> is the directory where you want to store the backup on your host machine.</p>"},{"location":"strategies/batching/","title":"Batching","text":"<p>It is often that you may need to ingest a large number of documents into Chroma. The problem you may face is related to the underlying SQLite version of the machine running Chroma which imposes a maximum number of statements and parameters which Chroma translates into a batchable record size, exposed via the <code>max_batch_size</code> parameter of the <code>ChromaClient</code> class.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")\nprint(\"Number of documents that can be inserted at once: \",client.max_batch_size)\n</code></pre>"},{"location":"strategies/batching/#creating-batches","title":"Creating Batches","text":"<p>Due to consistency and data integrity reasons, Chroma does not offer, yet, out-of-the-box batching support. The below code snippet shows how to create batches of documents and ingest them into Chroma.</p> <pre><code>import chromadb\nfrom chromadb.utils.batch_utils import create_batches\nimport uuid\n\nclient = chromadb.PersistentClient(path=\"test-large-batch\")\nlarge_batch = [(f\"{uuid.uuid4()}\", f\"document {i}\", [0.1] * 1536) for i in range(100000)]\nids, documents, embeddings = zip(*large_batch)\nbatches = create_batches(api=client,ids=list(ids), documents=list(documents), embeddings=list(embeddings))\ncollection = client.get_or_create_collection(\"test\")\nfor batch in batches:\n    print(f\"Adding batch of size {len(batch[0])}\")\n    collection.add(ids=batch[0],\n                   documents=batch[3],\n                   embeddings=batch[1],\n                   metadatas=batch[2])\n</code></pre>"},{"location":"strategies/cors/","title":"CORS Configuration for Browser-Based Access","text":"<p>Chroma JS package allows you to use Chroma in your browser-based SPA application. This is great, but that means that you'll need to configure Chroma to work with your browser to avoid CORS issues.</p>"},{"location":"strategies/cors/#setting-up-chroma-for-browser-based-access","title":"Setting up Chroma for Browser-Based Access","text":"<p>To allow browsers to directly access your Chroma instance you'll need to configure the <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code>. The <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> environment variable controls the hosts which are allowed to access your Chroma instance.</p> <p>Note</p> <p>The <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> environment variable is a list of strings. Each string is a URL that is allowed to access your Chroma instance. If you want to allow all hosts to access your Chroma instance, you can set <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> to <code>[\"*\"]</code>. This is not recommended for production environments.</p> <p>The below examples assume that your web app is running on <code>http://localhost:3000</code>. You can find an example of NextJS and Langchain here.</p> <p>Using Chroma run:</p> <pre><code>export CHROMA_SERVER_CORS_ALLOW_ORIGINS='[\"http://localhost:3000\"]'\nchroma run --path /path/to/chroma-data\n</code></pre> <p>Or with docker:</p> <pre><code>docker run -e CHROMA_SERVER_CORS_ALLOW_ORIGINS='[\"http://localhost:3000\"]' -v /path/to/chroma-data:/chroma/chroma -p 8000:8000 chromadb/chroma\n</code></pre> <p>Or in your <code>docker-compose.yml</code>:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: chromadb/chroma:0.5.0\n    volumes:\n      # Be aware that indexed data are located in \"/chroma/chroma/\"\n      # Default configuration for persist_directory in chromadb/config.py\n      # Read more about deployments: https://docs.trychroma.com/deployment\n      - chroma-data:/chroma/chroma\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=${CHROMA_SERVER_AUTHN_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS=${CHROMA_SERVER_AUTHN_CREDENTIALS}\n      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=[\"http://localhost:3000\"]\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n\nvolumes:\n  chroma-data:\n    driver: local\n</code></pre> <p>Run <code>docker compose up</code> to start your Chroma instance.</p>"},{"location":"strategies/keyword-search/","title":"Keyword Search","text":"<p>Chroma uses SQLite for storing metadata and documents. Additionally documents are indexed using SQLite FTS5 for fast text search.</p> PythonJS/TS <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.PersistentClient(path=\"test\", settings=Settings(allow_reset=True))\n\nclient.reset()\ncol = client.get_or_create_collection(\"test\")\n\ncol.upsert(ids=[\"1\", \"2\", \"3\"], documents=[\"He is a technology freak and he loves AI topics\", \"AI technology are advancing at a fast pace\", \"Innovation in LLMs is a hot topic\"],metadatas=[{\"author\": \"John Doe\"}, {\"author\": \"Jane Doe\"}, {\"author\": \"John Doe\"}])\ncol.query(query_texts=[\"technology\"], where_document={\"$or\":[{\"$contains\":\"technology\"}, {\"$contains\":\"freak\"}]})\n</code></pre> <p>The above should return:</p> <pre><code>{'ids': [['2', '1']],\n'distances': [[1.052205477809135, 1.3074231535113972]],\n'metadatas': [[{'author': 'Jane Doe'}, {'author': 'John Doe'}]],\n'embeddings': None,\n'documents': [['AI technology are advancing at a fast pace',\n  'He is a technology freak and he loves AI topics']],\n'uris': None,\n'data': None}\n</code></pre> <pre><code>const { ChromaClient, OpenAIEmbeddingFunction } = require(\"chromadb\");\n\n(async () =&gt; {\n    const client = new ChromaClient({\n        url: \"http://localhost:8000\",\n    });\n\n    const collection = client.getOrCreateCollection(\"test\");\n\n    await collection.upsert({\n        ids: [\"1\", \"2\", \"3\"],\n        documents: [\"He is a technology freak and he loves AI topics\", \"AI technology are advancing at a fast pace\", \"Innovation in LLMs is a hot topic\"],\n        metadatas: [{ author: \"John Doe\" }, { author: \"Jane Doe\" }, { author: \"John Doe\" }],\n    });\n\n    const results = await collection.query({\n        queryTexts: [\"technology\"],\n        whereDocument: {\n            \"$or\": [\n                { \"$contains\": \"technology\" },\n                { \"$contains\": \"freak\" }\n            ]\n        }\n    });\n})();\n</code></pre>"},{"location":"strategies/memory-management/","title":"Memory Management","text":"<p>This section provided additional info and strategies how to manage memory in Chroma.</p>"},{"location":"strategies/memory-management/#lru-cache-strategy","title":"LRU Cache Strategy","text":"<p>Out of the box Chroma offers an LRU cache strategy which unloads segments (collections) that are not used while trying to abide to the configured memory usage limits.</p> <p>To enable the LRU cache the following two settings parameters or environment variables need to be set:</p> PythonEnvironment Variables <pre><code>from chromadb.config import Settings\n\nsettings = Settings(\n    chroma_segment_cache_policy=\"LRU\",\n    chroma_memory_limit_bytes=10000000000  # ~10GB\n)\n</code></pre> <pre><code>export CHROMA_SEGMENT_CACHE_POLICY=LRU\nexport CHROMA_MEMORY_LIMIT_BYTES=10000000000  # ~10GB\n</code></pre>"},{"location":"strategies/memory-management/#manualcustom-collection-unloading","title":"Manual/Custom Collection Unloading","text":"<p>Local Clients</p> <p>The below code snippets assume you are working with a <code>PersistentClient</code> or an <code>EphemeralClient</code> instance.</p> <p>At the time of writing (Chroma v0.6.3), Chroma does not allow you to manually unloading of collections from memory.</p> <p>Here we provide a simple utility function to help users unload collections from memory.</p> <p>Internal APIs</p> <p>The below code relies on internal APIs and may change in future versions of Chroma.  The function relies on Chroma internal APIs which may change. The below snippet has been tested with Chroma <code>0.4.24+</code>.</p> <pre><code>import gc\nimport os\n\nimport chromadb\nimport psutil\nfrom chromadb.types import SegmentScope\n\n\ndef bytes_to_gb(bytes_value):\n    return bytes_value / (1024 ** 3)\n\n\ndef get_process_info():\n    pid = os.getpid()\n    p = psutil.Process(pid)\n    with p.oneshot():\n        mem_info = p.memory_info()\n        # disk_io = p.io_counters()\n    return {\n        \"memory_usage\": bytes_to_gb(mem_info.rss),\n    }\n\n\ndef unload_index(collection_name: str, chroma_client: chromadb.PersistentClient):\n    \"\"\"\n    Unloads binary hnsw index from memory and removes both segments (binary and metadata) from the segment cache.\n    \"\"\"\n    collection = chroma_client.get_collection(collection_name)\n    collection_id = collection.id\n    segment_manager = chroma_client._server._manager\n    for scope in [SegmentScope.VECTOR, SegmentScope.METADATA]:\n        if scope in segment_manager.segment_cache:\n            cache = segment_manager.segment_cache[scope].cache\n            if collection_id in cache:\n                segment_manager.callback_cache_evict(cache[collection_id])\n    gc.collect()\n</code></pre> <p>Example Contributed</p> <p>The above example was enhanced and contributed by <code>Amir</code> (amdeilami) from our Discord comminity. We appreciate and encourage his work and contributions to the Chroma community.</p> Usage Example <pre><code>import chromadb\n\n\nclient = chromadb.PersistentClient(path=\"testds-1M/chroma-data\")\ncol=client.get_collection(\"test\")\nprint(col.count())\ncol.get(limit=1,include=[\"embeddings\"]) # force load the collection into memory\n\nunload_index(\"test\", client)\n</code></pre>"},{"location":"strategies/multi-category-filters/","title":"Multi-Category/Tag Filters","text":"<p>Sometimes you may want to filter documents in Chroma based on multiple categories or tags e.g. <code>games</code> and <code>movies</code>. Unfortunately, Chroma does not yet support complex data-types like lists or sets so that one can use a single metadata field to store and filter by. It is also not possible to use fuzzy search <code>LIKE</code> queries on metadata fields.</p> <p>To solve this problem without introducing a complex logic on the client side, we suggest the following approach.</p> <p>When adding document to a collection add each category it belongs to as a boolean metadata field:</p> <p>No Empty Categories/Tags</p> <p>Only add categories an item belongs to with flags set to <code>True</code>.  Do not add categories an item does not belong to and set the flag to <code>False</code>.</p> <pre><code>collection.add(\n    ids=[f\"{uuid.uuid4()}\"],\n    documents=[\"This is a document\"],\n    metadatas=[{\"games\": True, \"movies\": True}],\n)\n</code></pre> <p>When querying documents, you can filter by multiple categories by using the <code>where</code> parameter:</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    where={\"games\": True},\n)\n# or a more complex query\nresults = collection.query(\n    query_texts=[\"This is a query document\"],\n    where={\"$or\": [{\"games\": True}, {\"movies\": True}]},\n)\n</code></pre>"},{"location":"strategies/privacy/","title":"Privacy Strategies","text":""},{"location":"strategies/privacy/#overview","title":"Overview","text":"<p>TBD</p>"},{"location":"strategies/privacy/#encryption","title":"Encryption","text":""},{"location":"strategies/privacy/#document-encryption","title":"Document Encryption","text":""},{"location":"strategies/privacy/#client-side-document-encryption","title":"Client-side Document Encryption","text":"<p>See the notebook on client-side document encryption.</p>"},{"location":"strategies/rebuilding/","title":"Rebuilding Chroma DB","text":""},{"location":"strategies/rebuilding/#rebuilding-a-collection","title":"Rebuilding a Collection","text":"<p>Here are several reasons you might want to rebuild a collection:</p> <ul> <li>Your metadata or binary index is corrupted or even deleted</li> <li>Optimize performance of HNSW index after a large number of updates</li> </ul> <p>WAL Consistency and Backups</p> <p>Before you proceed, make sure to backup your data. Secondly make sure that your WAL contains all the data to allow  the proper rebuilding of the collection. For instance, after v0.4.22 you should not have run optimizations or WAL  cleanup.</p> <p>IMPORTANT</p> <p>Only do this on a stopped Chroma instance.</p> <p>Find the UUID of the target binary index directory to remove. Typically, the binary index directory is located in the persistent directory and is named after the collection vector segment (in <code>segments</code> table). You can find the UUID by running the following SQL query:</p> <pre><code>sqlite3 /path/to/db/chroma.sqlite3 \"select s.id, c.name from segments s join collections c on  s.collection=c.id where s.scope='VECTOR';\"\n</code></pre> <p>The above should print UUID dir and collection names.</p> <p>Once you remove/rename the UUID dir, restart Chroma and query your collection like so:</p> <pre><code>import chromadb\nclient = chromadb.HttpClient() # Adjust as per your client\nres = client.get_collection(\"my_collection\").get(limit=1,include=['embeddings'])\n</code></pre> <p>Chroma will recreate your collection from the WAL.</p> <p>Rebuilding the collection</p> <p>Depending on how large your collection is, this process can take a while.</p>"},{"location":"strategies/time-based-queries/","title":"Time-based Queries","text":""},{"location":"strategies/time-based-queries/#filtering-documents-by-timestamps","title":"Filtering Documents By Timestamps","text":"<p>In the example below, we create a collection with 100 documents, each with a random timestamp in the last two weeks. We then query the collection for documents that were created in the last week.</p> <p>The example demonstrates how Chroma metadata can be leveraged to filter documents based on how recently they were added or updated.</p> <pre><code>import uuid\nimport chromadb\n\nimport datetime\nimport random\n\nnow = datetime.datetime.now()\ntwo_weeks_ago = now - datetime.timedelta(days=14)\n\ndates = [\n    two_weeks_ago + datetime.timedelta(days=random.randint(0, 14))\n    for _ in range(100)\n]\ndates = [int(date.timestamp()) for date in dates]\n\n# convert epoch seconds to iso format\n\ndef iso_date(epoch_seconds): return datetime.datetime.fromtimestamp(\n    epoch_seconds).isoformat()\n\nclient = chromadb.EphemeralClient()\n\ncol = client.get_or_create_collection(\"test\")\n\ncol.add(ids=[f\"{uuid.uuid4()}\" for _ in range(100)], documents=[\n    f\"document {i}\" for i in range(100)], metadatas=[{\"date\": date} for date in dates])\n\nres = col.get(where={\"date\": {\"$gt\": (now - datetime.timedelta(days=7)).timestamp()}})\n\nfor i in res['metadatas']:\n    print(iso_date(i['date']))\n</code></pre> <p>Ref: https://gist.github.com/tazarov/3c9301d22ab863dca0b6fb1e5e3511b1</p>"},{"location":"strategies/multi-tenancy/","title":"Multi-Tenancy Strategies","text":""},{"location":"strategies/multi-tenancy/#introduction","title":"Introduction","text":"<p>Some deployment settings of Chroma may require multi-tenancy support. This document outlines the strategies for multi-tenancy approaches in Chroma.</p>"},{"location":"strategies/multi-tenancy/#approaches","title":"Approaches","text":"<ul> <li>Naive approach - This is a simple approach puts the onus of enforcing multi-tenancy on the   application. It is the simplest approach to implement, but is not very well suited for production environments.</li> <li>Multi-User Basic Auth - This article provides a stepping stone to more advanced   multi-tenancy where the Chroma   authentication allows for multiple users to access the same Chroma instance with their own credentials.</li> <li>Authorization Model with OpenFGA - Implement an advanced authorization model   with OpenFGA.</li> <li>Implementing OpenFGA Authorization Model In Chroma - Learn how to   implement OpenFGA authorization model in Chroma with full code example.</li> </ul>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/","title":"Implementing OpenFGA Authorization Model In Chroma","text":"<p>Source Code</p> <p>The source code for this article can be found here.</p>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#preparation","title":"Preparation","text":"<p>To make things useful we also introduce an initial tuple set with permissions which will allows us to test the authorization model.</p> <p>We define three users:</p> <ul> <li><code>admin</code> part of <code>chroma</code> team as <code>owner</code></li> <li><code>user1</code> part of <code>chroma</code> team as <code>reader</code></li> <li><code>admin-ext</code> part of <code>external</code> team as <code>owner</code></li> </ul> <p>We will give enough permissions to these three users and their respective teams so that they can perform collection creation, deletion, add records, remove records, get records and query records in the context of their role within the team - <code>owner</code> has access to all API actions while <code>reader</code> can only read, list get, query.</p> <p>Abbreviate Example</p> <p>We have removed some of the data from the above example for brevity. The full tuple set can be found under data/data/initial-data.json</p> <pre><code>[\n  {\n    \"object\": \"team:chroma\",\n    \"relation\": \"owner\",\n    \"user\": \"user:admin\"\n  },\n  {\n    \"object\": \"team:chroma\",\n    \"relation\": \"reader\",\n    \"user\": \"user:user1\"\n  },\n  {\n    \"object\": \"team:external\",\n    \"relation\": \"owner\",\n    \"user\": \"user:admin-ext\"\n  },\n  {\n    \"object\": \"server:localhost\",\n    \"relation\": \"can_get_tenant\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"tenant:default_tenant-default_database\",\n    \"relation\": \"can_get_database\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_create_collection\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_list_collections\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_get_or_create_collection\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_count_collections\",\n    \"user\": \"team:chroma#owner\"\n  }\n]\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#testing-the-model","title":"Testing the model","text":"<p>Let\u2019s spin up a quick docker compose to test our setup. In the repo we have provided <code>openfga/docker-compose.openfga-standalone.yaml</code></p> <pre><code>docker compose -f openfga/docker-compose.openfga-standalone.yaml up\n</code></pre> <p>For this next part ensure you have FGA CLI installed.</p> <p>Once the containers are up and running let\u2019s create a store and import the model:</p> <pre><code>export FGA_API_URL=http://localhost:8082 # our OpenFGA binds to 8082 on localhost\nfga store create --model data/models/model-article-p4.fga --name chromadb-auth\n</code></pre> <p>You should see a response like this:</p> <pre><code>{\n  \"store\": {\n    \"created_at\": \"2024-04-09T18:37:26.367747Z\",\n    \"id\": \"01HV3VB347NPY3NMX6VQ5N2E23\",\n    \"name\": \"chromadb-auth\",\n    \"updated_at\": \"2024-04-09T18:37:26.367747Z\"\n  },\n  \"model\": {\n    \"authorization_model_id\": \"01HV3VB34JAXWF0F3C00DFBZV4\"\n  }\n}\n</code></pre> <p>Let\u2019s import our initial tuple set. Before that make sure to export <code>FGA_STORE_ID</code> and <code>FGA_MODEL_ID</code> as per the output of the previous command:</p> <pre><code>export FGA_STORE_ID=01HV3VB347NPY3NMX6VQ5N2E23\nexport FGA_MODEL_ID=01HV3VB34JAXWF0F3C00DFBZV4\nfga tuple write --file data/data/initial-data.json\n</code></pre> <p>Let\u2019s test our imported model and tuples:</p> <pre><code>fga query check user:admin can_get_preflight server:localhost\n</code></pre> <p>If everything is working you should see this:</p> <pre><code>{\n  \"allowed\": true,\n  \"resolution\": \"\"\n}\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#implementing-authorization-plumbing-in-chroma","title":"Implementing Authorization Plumbing in Chroma","text":"<p>First we will start with making a few small changes to the authorization plugin we\u2019ve made. Why you ask? We need to introduce teams (aka groups). For that we\u2019ll resort to standard Apache <code>groupfile</code> as follows:</p> <pre><code>chroma: admin, user1\nexternal: admin-ext\n</code></pre> <p>The <code>groupfile</code> will be mounted to our Chroma container and read by the multi-user basic auth plugin. The changes to the authentication plugin are as follows:</p> <pre><code># imports as before\n\n@register_provider(\"multi_user_htpasswd_file\")\nclass MultiUserHtpasswdFileServerAuthCredentialsProvider(ServerAuthCredentialsProvider):\n    _creds: Dict[str, SecretStr]  # contains user:password-hash\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        try:\n            self.bc = importlib.import_module(\"bcrypt\")\n        except ImportError:\n            raise ValueError(aa\n                \"The bcrypt python package is not installed. \"\n                \"Please install it with `pip install bcrypt`\"\n            )\n        system.settings.require(\"chroma_server_auth_credentials_file\")\n        _file = str(system.settings.chroma_server_auth_credentials_file)\n        ...  # as before\n        _basepath = path.dirname(_file)\n        self._user_group_map = dict()\n        if path.exists(path.join(_basepath, \"groupfile\")):\n            _groups = dict()\n            with open(path.join(_basepath, \"groupfile\"), \"r\") as f:\n                for line in f:\n                    _raw_group = [v for v in line.strip().split(\":\")]\n                    if len(_raw_group) &lt; 2:\n                        raise ValueError(\n                            \"Invalid Htpasswd group file found in \"\n                            f\"[{path.join(_basepath, 'groupfile')}]. \"\n                            \"Must be &lt;groupname&gt;:&lt;username1&gt;,&lt;username2&gt;,...,&lt;usernameN&gt;.\"\n                        )\n                    _groups[_raw_group[0]] = [u.strip() for u in _raw_group[1].split(\",\")]\n                    for _group, _users in _groups.items():\n                        for _user in _users:\n                            if _user not in self._user_group_map:\n                                self._user_group_map[_user] = _group\n\n    @trace_method(  # type: ignore\n        \"MultiUserHtpasswdFileServerAuthCredentialsProvider.validate_credentials\",\n        OpenTelemetryGranularity.ALL,\n    )\n    @override\n    def validate_credentials(self, credentials: AbstractCredentials[T]) -&gt; bool:\n        ...  # as before\n\n    @override\n    def get_user_identity(\n            self, credentials: AbstractCredentials[T]\n    ) -&gt; Optional[SimpleUserIdentity]:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n        if _creds[\"username\"].get_secret_value() in self._user_group_map.keys():\n            return SimpleUserIdentity(\n                _creds[\"username\"].get_secret_value(),\n                attributes={\n                    \"team\": self._user_group_map[_creds[\"username\"].get_secret_value()]\n                },\n            )\n        return SimpleUserIdentity(_creds[\"username\"].get_secret_value(), attributes={\"team\": \"public\"})\n</code></pre> <p>Full code</p> <p>The code can be found under <code>chroma_auth/authn/basic/__**init__**.py</code></p> <p>We read the group file and for each user create a key in <code>self._user_group_map</code> to specify the group or team of that user. The information is returned as user identity attributes that is further used by the authz plugin.</p> <p>Now let\u2019s turn our attention to the authorization plugin. First let\u2019s start with that we\u2019re trying to achieve with it:</p> <ul> <li>Handle OpenFGA configuration from the import of the model as per the snippet above. This will help us to wire all   necessary parts of the code with correct authorization model configuration.</li> <li>Map all existing Chroma authorization actions to our authorization model</li> <li>Adapt any shortcomings or quirks in Chroma authorization to the way OpenFGA works</li> <li>Implement the Enforcement Point (EP) logic</li> <li>Implement OpenFGA Permissions API wrapper - this is a utility class that will help us update and keep updating the   OpenFGA tuples throughout collections\u2019 lifecycle.</li> </ul> <p>We\u2019ve split the implementation in two files:</p> <ul> <li><code>chroma_auth/authz/openfga/__init__.py</code> - Storing our OpenFGA authorization configuration reader and our authorization   plugin that adapts to Chroma authz model and enforces authorization decisions</li> <li><code>chroma_auth/authz/openfga/openfga_permissions.py</code> - Holds our OpenFGA permissions update logic.</li> <li><code>chroma_auth/instr/**__init__**.py</code> - holds our adapted FastAPI server from Chroma <code>0.4.24</code>. While the authz plugin   system in Chroma makes it easy to write the enforcement of authorization decisions, the update of permissions does   require us to into this rabbit hole. Don\u2019t worry the actual changes are minimal</li> </ul> <p>Let\u2019s cover things in a little more detail.</p> <p>Reading the configuration.</p> <pre><code>@register_provider(\"openfga_config_provider\")\nclass OpenFGAAuthorizationConfigurationProvider(\n    ServerAuthorizationConfigurationProvider[ClientConfiguration]\n):\n    _config_file: str\n    _config: ClientConfiguration\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        self._settings = system.settings\n        if \"FGA_API_URL\" not in os.environ:\n            raise ValueError(\"FGA_API_URL not set\")\n        self._config = self._try_load_from_file()\n\n        # TODO in the future we can also add credentials (preshared) or OIDC\n\n    def _try_load_from_file(self) -&gt; ClientConfiguration:\n        store_id = None\n        model_id = None\n        if \"FGA_STORE_ID\" in os.environ and \"FGA_MODEL_ID\" in os.environ:\n            return ClientConfiguration(\n                api_url=os.environ.get(\"FGA_API_URL\"),\n                store_id=os.environ[\"FGA_STORE_ID\"],\n                authorization_model_id=os.environ[\"FGA_MODEL_ID\"],\n            )\n        if \"FGA_CONFIG_FILE\" not in os.environ and not store_id and not model_id:\n            raise ValueError(\"FGA_CONFIG_FILE or FGA_STORE_ID/FGA_MODEL_ID env vars not set\")\n        with open(os.environ[\"FGA_CONFIG_FILE\"], \"r\") as f:\n            config = json.load(f)\n            return ClientConfiguration(\n                api_url=os.environ.get(\"FGA_API_URL\"),\n                store_id=config[\"store\"][\"id\"],\n                authorization_model_id=config[\"model\"][\"authorization_model_id\"],\n            )\n\n    @override\n    def get_configuration(self) -&gt; ClientConfiguration:\n        return self._config\n</code></pre> <p>This is a pretty simple and straightforward implementation that will either take env variables for the FGA Server URL, Store and Model or it will only take the server ULR + json configuration (the same as above).</p> <p>Next let\u2019s have a look at our <code>OpenFGAAuthorizationProvider</code> implementation. We\u2019ll start with the constructor where we adapt existing Chroma authorization actions to our model:</p> <pre><code>def __init__(self, system: System) -&gt; None:\n    # more code here, but we're skipping for brevity\n    self._authz_to_model_action_map = {\n        AuthzResourceActions.CREATE_DATABASE.value: \"can_create_database\",\n        AuthzResourceActions.GET_DATABASE.value: \"can_get_database\",\n        AuthzResourceActions.CREATE_TENANT.value: \"can_create_tenant\",\n        AuthzResourceActions.GET_TENANT.value: \"can_get_tenant\",\n        AuthzResourceActions.LIST_COLLECTIONS.value: \"can_list_collections\",\n        AuthzResourceActions.COUNT_COLLECTIONS.value: \"can_count_collections\",\n        AuthzResourceActions.GET_COLLECTION.value: \"can_get_collection\",\n        AuthzResourceActions.CREATE_COLLECTION.value: \"can_create_collection\",\n        AuthzResourceActions.GET_OR_CREATE_COLLECTION.value: \"can_get_or_create_collection\",\n        AuthzResourceActions.DELETE_COLLECTION.value: \"can_delete_collection\",\n        AuthzResourceActions.UPDATE_COLLECTION.value: \"can_update_collection\",\n        AuthzResourceActions.ADD.value: \"can_add_records\",\n        AuthzResourceActions.DELETE.value: \"can_delete_records\",\n        AuthzResourceActions.GET.value: \"can_get_records\",\n        AuthzResourceActions.QUERY.value: \"can_query_records\",\n        AuthzResourceActions.COUNT.value: \"can_count_records\",\n        AuthzResourceActions.UPDATE.value: \"can_update_records\",\n        AuthzResourceActions.UPSERT.value: \"can_upsert_records\",\n        AuthzResourceActions.RESET.value: \"can_reset\",\n    }\n\n    self._authz_to_model_object_map = {\n        AuthzResourceTypes.DB.value: \"database\",\n        AuthzResourceTypes.TENANT.value: \"tenant\",\n        AuthzResourceTypes.COLLECTION.value: \"collection\",\n    }\n</code></pre> <p>The above is located in <code>chroma_auth/authz/openfga/__init__.py</code></p> <p>The above is fairly straightforward mapping between <code>AuthzResourceActions</code> part of Chroma\u2019s auth framework and the relations (aka actions) we\u2019ve defined in our model above. Next we map also the <code>AuthzResourceTypes</code> to OpenFGA objects. This seem pretty simple right? Wrong, things are not so perfect and nothing exhibits this more than our next portion that takes the action and resource and returns object and relation to be checked:</p> <pre><code>def resolve_resource_action(self, resource: AuthzResource, action: AuthzAction) -&gt; tuple:\n    attrs = \"\"\n    tenant = None,\n    database = None\n    if \"tenant\" in resource.attributes:\n        attrs += f\"{resource.attributes['tenant']}\"\n        tenant = resource.attributes['tenant']\n    if \"database\" in resource.attributes:\n        attrs += f\"-{resource.attributes['database']}\"\n        database = resource.attributes['database']\n    if action.id == AuthzResourceActions.GET_TENANT.value or action.id == AuthzResourceActions.CREATE_TENANT.value:\n        return \"server:localhost\", self._authz_to_model_action_map[action.id]\n    if action.id == AuthzResourceActions.GET_DATABASE.value or action.id == AuthzResourceActions.CREATE_DATABASE.value:\n        return f\"tenant:{attrs}\", self._authz_to_model_action_map[action.id]\n    if action.id == AuthzResourceActions.CREATE_COLLECTION.value:\n        try:\n            cole_exists = self._api.get_collection(\n                resource.id, tenant=tenant, database=database\n            )\n            return f\"collection:{attrs}-{cole_exists.name}\", self._authz_to_model_action_map[\n                AuthzResourceActions.GET_COLLECTION.value]\n        except Exception as e:\n            return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}\", self._authz_to_model_action_map[\n                action.id]\n    if resource.id == \"*\":\n        return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}\", self._authz_to_model_action_map[action.id]\n    else:\n        return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}-{resource.id}\",\n        self._authz_to_model_action_map[action.id]\n</code></pre> <p>Full code</p> <p>The above is located in <code>chroma_auth/authz/openfga/__init__.py</code></p> <p>The <code>resolve_resource_action</code> function demonstrates the idiosyncrasies of Chroma\u2019s auth. I have only myself to blame. The key takeaway is that there is room for improvement.</p> <p>The actual authorization enforcement is then dead simple:</p> <pre><code>def authorize(self, context: AuthorizationContext) -&gt; bool:\n    with OpenFgaClient(self._authz_config_provider.get_configuration()) as fga_client:\n        try:\n            obj, act = self.resolve_resource_action(resource=context.resource, action=context.action)\n            resp = fga_client.check(body=ClientCheckRequest(\n                user=f\"user:{context.user.id}\",\n                relation=act,\n                object=obj,\n            ))\n            # openfga_sdk.models.check_response.CheckResponse\n            return resp.allowed\n        except Exception as e:\n            logger.error(f\"Error while authorizing: {str(e)}\")\n            return False\n</code></pre> <p>At the end we\u2019ll look at the our permissions API wrapper. While a full-blown solution will implement all possible object lifecycle hooks, we\u2019re content with collections. Therefore we\u2019ll add lifecycle callbacks for creating and deleting collection (we\u2019re not considering, sharing of the collection with other users and change of ownership). So how does our create collection hook might look like you ask?</p> <pre><code>def create_collection_permissions(self, collection: Collection, request: Request) -&gt; None:\n    if not hasattr(request.state, \"user_identity\"):\n        return\n    identity = request.state.user_identity  # AuthzUser\n    tenant = request.query_params.get(\"tenant\")\n    database = request.query_params.get(\"database\")\n    _object = f\"collection:{tenant}-{database}-{collection.id}\"\n    _object_for_get_collection = f\"collection:{tenant}-{database}-{collection.name}\"  # this is a bug in the Chroma Authz that feeds in the name of the collection instead of ID\n    _user = f\"team:{identity.get_user_attributes()['team']}#owner\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else f\"user:{identity.get_user_id()}\"\n    _user_writer = f\"team:{identity.get_user_attributes()['team']}#writer\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    _user_reader = f\"team:{identity.get_user_attributes()['team']}#reader\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    with OpenFgaClient(self._fga_configuration) as fga_client:\n        fga_client.write_tuples(\n            body=[\n                ClientTuple(_user, \"can_add_records\", _object),\n                ClientTuple(_user, \"can_delete_records\", _object),\n                ClientTuple(_user, \"can_update_records\", _object),\n                ClientTuple(_user, \"can_get_records\", _object),\n                ClientTuple(_user, \"can_upsert_records\", _object),\n                ClientTuple(_user, \"can_count_records\", _object),\n                ClientTuple(_user, \"can_query_records\", _object),\n                ClientTuple(_user, \"can_get_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_delete_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_update_collection\", _object),\n            ]\n        )\n        if _user_writer:\n            fga_client.write_tuples(\n                body=[\n                    ClientTuple(_user_writer, \"can_add_records\", _object),\n                    ClientTuple(_user_writer, \"can_delete_records\", _object),\n                    ClientTuple(_user_writer, \"can_update_records\", _object),\n                    ClientTuple(_user_writer, \"can_get_records\", _object),\n                    ClientTuple(_user_writer, \"can_upsert_records\", _object),\n                    ClientTuple(_user_writer, \"can_count_records\", _object),\n                    ClientTuple(_user_writer, \"can_query_records\", _object),\n                    ClientTuple(_user_writer, \"can_get_collection\", _object_for_get_collection),\n                    ClientTuple(_user_writer, \"can_delete_collection\", _object_for_get_collection),\n                    ClientTuple(_user_writer, \"can_update_collection\", _object),\n                ]\n            )\n        if _user_reader:\n            fga_client.write_tuples(\n                body=[\n                    ClientTuple(_user_reader, \"can_get_records\", _object),\n                    ClientTuple(_user_reader, \"can_query_records\", _object),\n                    ClientTuple(_user_reader, \"can_count_records\", _object),\n                    ClientTuple(_user_reader, \"can_get_collection\", _object_for_get_collection),\n                ]\n            )\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/authz/openfga/openfga_permissions.py</code></p> <p>Looks pretty straight, but hold on I hear a thought creeping in your mind. \u201cWhy are you adding roles manually?\u201d</p> <p>You are right, it lacks that DRY-je-ne-sais-quoi, and I\u2019m happy to keep it simple an explicit. A more mature implementation can read the model figure out what type we\u2019re adding permissions for and then for each relation add the requisite users, but premature optimization is difficult to put in an article that won\u2019t turn into a book.</p> <p>With the above code we make the assumption that the collection doesn\u2019t exist ergo its permissions tuples don\u2019t exist. ( OpenFGA will fail to add tuples that already exist and there is not way around it other than deleting them first). Remember permission tuple lifecycle is your responsibility when adding authz to your application.</p> <p>The delete is oddly similar (that\u2019s why we\u2019ve skipped the bulk of it):</p> <pre><code>def delete_collection_permissions(self, collection: Collection, request: Request) -&gt; None:\n    if not hasattr(request.state, \"user_identity\"):\n        return\n    identity = request.state.user_identity\n\n    _object = f\"collection:{collection.tenant}-{collection.database}-{collection.id}\"\n    _object_for_get_collection = f\"collection:{collection.tenant}-{collection.database}-{collection.name}\"  # this is a bug in the Chroma Authz that feeds in the name of the collection instead of ID\n    _user = f\"team:{identity.get_user_attributes()['team']}#owner\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else f\"user:{identity.get_user_id()}\"\n    _user_writer = f\"team:{identity.get_user_attributes()['team']}#writer\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    _user_reader = f\"team:{identity.get_user_attributes()['team']}#reader\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    with OpenFgaClient(self._fga_configuration) as fga_client:\n        fga_client.delete_tuples(\n            body=[\n                ClientTuple(_user, \"can_add_records\", _object),\n                ClientTuple(_user, \"can_delete_records\", _object),\n                ClientTuple(_user, \"can_update_records\", _object),\n                ClientTuple(_user, \"can_get_records\", _object),\n                ClientTuple(_user, \"can_upsert_records\", _object),\n                ClientTuple(_user, \"can_count_records\", _object),\n                ClientTuple(_user, \"can_query_records\", _object),\n                ClientTuple(_user, \"can_get_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_delete_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_update_collection\", _object),\n            ]\n        )\n    # more code in the repo\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/authz/openfga/openfga_permissions.py</code></p> <p>Let\u2019s turn our attention at the last piece of code - the necessary evil of updating the FastAPI in Chroma to add our Permissions API hooks. We start simple by injecting our component using Chroma\u2019s DI (dependency injection).</p> <pre><code>from chroma_auth.authz.openfga.openfga_permissions import OpenFGAPermissionsAPI\n\nself._permissionsApi: OpenFGAPermissionsAPI = self._system.instance(OpenFGAPermissionsAPI)\n</code></pre> <p>The we add a hook for collection creation:</p> <pre><code>def create_collection(\n        self,\n        request: Request,\n        collection: CreateCollection,\n        tenant: str = DEFAULT_TENANT,\n        database: str = DEFAULT_DATABASE,\n) -&gt; Collection:\n    existing = None\n    try:\n        existing = self._api.get_collection(collection.name, tenant=tenant, database=database)\n    except ValueError as e:\n        if \"does not exist\" not in str(e):\n            raise e\n    collection = self._api.create_collection(\n        name=collection.name,\n        metadata=collection.metadata,\n        get_or_create=collection.get_or_create,\n        tenant=tenant,\n        database=database,\n    )\n    if not existing:\n        self._permissionsApi.create_collection_permissions(collection=collection, request=request)\n    return collection\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/instr/__init__.py</code></p> <p>And one for collection removal:</p> <pre><code>def delete_collection(\n        self,\n        request: Request,\n        collection_name: str,\n        tenant: str = DEFAULT_TENANT,\n        database: str = DEFAULT_DATABASE,\n) -&gt; None:\n    collection = self._api.get_collection(collection_name, tenant=tenant, database=database)\n    resp = self._api.delete_collection(\n        collection_name, tenant=tenant, database=database\n    )\n\n    self._permissionsApi.delete_collection_permissions(collection=collection, request=request)\n    return resp\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/instr/__init__.py</code></p> <p>The key thing to observe about the above snippets is that we invoke permissions API when we\u2019re sure things have been persisted in the DB. I know, I know, atomicity here is also important, but that is for another article. Just keep in mind that it is easier to fix broken permission than broken data.</p> <p>I promise this was the last bit of python code you\u2019ll see in this article.</p>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#the-infra","title":"The Infra","text":"<p>Infrastructure!!! Finally, a sigh of relieve.</p> <p>Let\u2019s draw a diagrams:</p> <p></p> <p>Link</p> <p>We have our Chroma server, that relies on OpenFGA which persists data in PostgreSQL. \u201cOk, but \u2026\u201d, I can see you scratch your head, \u201c\u2026 how do I bring this magnificent architecture to live?\u201d. I thought you\u2019d never ask. We\u2019ll rely on our trusty docker compose skills with the following sequence in mind:</p> <p></p> <p>\u201cWhere is the <code>docker-compose.yaml</code>!\u201d. Voil\u00e0, my impatient friends:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    depends_on:\n      openfga:\n        condition: service_healthy\n      import:\n        condition: service_completed_successfully\n    image: chroma-server\n    build:\n      dockerfile: Dockerfile\n    volumes:\n      - ./chroma-data:/chroma/chroma\n      - ./server.htpasswd:/chroma/server.htpasswd\n      - ./groupfile:/chroma/groupfile\n      - ./data/:/data\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n      - CHROMA_SERVER_AUTHZ_PROVIDER=${CHROMA_SERVER_AUTHZ_PROVIDER}\n      - CHROMA_SERVER_AUTHZ_CONFIG_PROVIDER=${CHROMA_SERVER_AUTHZ_CONFIG_PROVIDER}\n      - FGA_API_URL=http://openfga:8080\n      - FGA_CONFIG_FILE=/data/store.json # we expect that the import job will create this file\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n  postgres:\n    image: postgres:14\n    container_name: postgres\n    networks:\n      - net\n    ports:\n      - \"5432:5432\"\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=password\n    healthcheck:\n      test: [ \"CMD-SHELL\", \"pg_isready -U postgres\" ]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - postgres_data_openfga:/var/lib/postgresql/data\n\n  migrate:\n    depends_on:\n      postgres:\n        condition: service_healthy\n    image: openfga/openfga:latest\n    container_name: migrate\n    command: migrate\n    environment:\n      - OPENFGA_DATASTORE_ENGINE=postgres\n      - OPENFGA_DATASTORE_URI=postgres://postgres:password@postgres:5432/postgres?sslmode=disable\n    networks:\n      - net\n  openfga:\n    depends_on:\n      migrate:\n        condition: service_completed_successfully\n    image: openfga/openfga:latest\n    container_name: openfga\n    environment:\n      - OPENFGA_DATASTORE_ENGINE=postgres\n      - OPENFGA_DATASTORE_URI=postgres://postgres:password@postgres:5432/postgres?sslmode=disable\n      - OPENFGA_LOG_FORMAT=json\n    command: run\n    networks:\n      - net\n    ports:\n      # Needed for the http server\n      - \"8082:8080\"\n      # Needed for the grpc server (if used)\n      - \"8083:8081\"\n      # Needed for the playground (Do not enable in prod!)\n      - \"3003:3000\"\n    healthcheck:\n      test: [ \"CMD\", \"/usr/local/bin/grpc_health_probe\", \"-addr=openfga:8081\" ]\n      interval: 5s\n      timeout: 30s\n      retries: 3\n  import:\n    depends_on:\n      openfga:\n        condition: service_healthy\n    image: fga-cli\n    build:\n      context: .\n      dockerfile: Dockerfile-fgacli\n    container_name: import\n    volumes:\n      - ./data/:/data\n    command: |\n      /bin/sh -c \"/data/create_store_and_import.sh\"\n    environment:\n      - FGA_SERVER_URL=http://openfga:8080\n    networks:\n      - net\nvolumes:\n  postgres_data_openfga:\n    driver: local\n</code></pre> <p>Don\u2019t forget to create an <code>.env</code> file:</p> <pre><code>CHROMA_SERVER_AUTH_PROVIDER = \"chromadb.auth.basic.BasicAuthServerProvider\"\nCHROMA_SERVER_AUTH_CREDENTIALS_FILE = \"server.htpasswd\"\nCHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER = \"chroma_auth.authn.basic.MultiUserHtpasswdFileServerAuthCredentialsProvider\"\nCHROMA_SERVER_AUTHZ_PROVIDER = \"chroma_auth.authz.openfga.OpenFGAAuthorizationProvider\"\nCHROMA_SERVER_AUTHZ_CONFIG_PROVIDER = \"chroma_auth.authz.openfga.OpenFGAAuthorizationConfigurationProvider\"\n</code></pre> <p>Update your <code>server.htpasswd</code> to include the new user:</p> <pre><code>admin:$2\ny$05$vkBK4b1Vk5O98jNHgr.uduTJsTOfM395sKEKe48EkJCVPH / MBIeHK\nuser1:$2\ny$05$UQ0kC2x3T2XgeN4WU12BdekUwCJmLjJNhMaMtFNolYdj83OqiEpVu\nadmin - ext:$2\ny$05$9.\nL13wKQTHeXz9IH2UO2RurWEK. / Z24qapzyi6ywQGJds2DaC36C2\n</code></pre> <p>And the <code>groupfile</code> from before. And don\u2019t forget to take a look at the import script under - <code>data/create_store_and_import.sh</code></p> <p>Run the following command at the root of the repo and let things fail and burn down (or in the event this works - awe you, disclaimer - it worked on my machine):</p> <pre><code>docker\ncompose\nup - -build\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#tests-who-needs-test-when-you-have-stable-infra","title":"Tests, who needs test when you have stable infra!","text":"<p>Authorization is serious stuff, which is why we\u2019ve created a bare minimum set of tests to prove we\u2019re not totally wrong about it!</p> <p>Real Serious Note</p> <p>Serious Note: Take these things seriously and write a copious amounts of tests before rolling out things to prod. Don\u2019t become OWASP Top10 \u201cHero\u201d. Broken access controls is a thing that WILL keep you up at night.</p> <p>We\u2019ll focus on three areas:</p> <ul> <li>Testing admin (owner) access</li> <li>Testing team access for owner and reader roles</li> <li>Testing cross team permissions</li> </ul> <p>Admin Access</p> <p>Simple check to ensure that whoever created the collection (aka the owner) is allowed all actions.</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\n\ncol = client.get_or_create_collection(f\"test_collection-{str(uuid.uuid4())}\")\ncol.add(ids=[\"1\"], documents=[\"test doc\"])\n\ncol.get()\ncol.update(ids=[\"1\"], documents=[\"test doc 2\"])\ncol.count()\ncol.upsert(ids=[\"1\"], documents=[\"test doc 3\"])\ncol.delete(ids=[\"1\"])\n\nclient.delete_collection(col.name)\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p> <p>Team Access</p> <p>Team access tests whether roles and permissions associated with those roles are correctly enforced.</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\n\ncol_name = f\"test_collection-{str(uuid.uuid4())}\"\ncol = client.get_or_create_collection(col_name)\nprint(f\"Creating collection {col.id}\")\ncol.add(ids=[\"1\"], documents=[\"test doc\"])\n\nclient.get_collection(col_name)\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"user1:password123\"))\n\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\nclient.count_collections()\nprint(\"Getting collection \" + col_name)\ncol = client.get_collection(col_name)\ncol.get()\ncol.count()\n\ntry:\n    client.delete_collection(col_name)\nexcept Exception as e:\n    print(e)  #expect unauthorized error\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\n\nclient.delete_collection(col_name)\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p> <p>Cross-team access</p> <p>In the cross team access scenario we\u2019ll create a collection with one team owner (<code>admin</code>) and will try to access it (aka delete it) with another team\u2019s owner in a very mano-a-mano (owner-to-owner way). It is important to observe that all these collections are created within the same database (<code>default_database</code>)</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\ncol_name = f\"test_collection-{str(uuid.uuid4())}\"\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\n\nclient.get_or_create_collection(col_name)\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin-ext:password123\"))\n\nclient.get_or_create_collection(\"external-collection\")\n\ntry:\n    client.delete_collection(col_name)\nexcept Exception as e:\n    print(\"Expected error for admin-ext: \", str(e))  #expect unauthorized error\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.delete_collection(col_name)\ntry:\n    client.delete_collection(\"external-collection\")\nexcept Exception as e:\n    print(\"Expected error for admin: \", str(e))  #expect unauthorized error\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/","title":"Chroma Authorization Model with OpenFGA","text":"<p>Source Code</p> <p>The source code for this article can be found here.</p> <p>This article will not provide any code that you can use immediately but will set the stage for our next article, which will introduce the actual Chroma-OpenFGA integration.</p> <p>With that in mind, let\u2019s get started.</p> <p>Who is this article for? The intended audience is DevSecOps, but engineers and architects could also use this to learn about Chroma and the authorization models.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#authorization-model","title":"Authorization Model","text":"<p>Authorization models are an excellent way to abstract the way you wish your users to access your application form the actual implementation.</p> <p>There are many ways to do authz, ranging from commercial Auth0 FGA to OSS options like Ory Keto/Kratos, CASBIN, Permify, and Kubescape, but for this article, we\u2019ve decided to use OpenFGA (which technically is Auth0\u2019s open-source framework for FGA).</p> <p>Why OpenFGA, I hear you ask? Here are a few reasons:</p> <ul> <li>Apache-2 licensed</li> <li>CNCF Incubating project</li> <li>Zanzibar alignment in that it is a ReBAC (Relation-based access control) system</li> <li>DSL for modeling and testing permissions (as well as JSON-base version for those with masochistic tendencies)</li> </ul> <p>OpenFGA has done a great job explaining the steps to building an Authorization model, which you can read here. We will go over those while keeping our goal of creating an authorization model for Chroma.</p> <p>It is worth noting that the resulting authorization model that we will create here will be suitable for many GenAI applications, such as general-purpose RAG systems. Still, it is not a one-size-fits-all solution to all problems. For instance, if you want to implement authz in Chroma within your organization, OpenFGA might not be the right tool for the job, and you should consult with your IT/Security department for guidance on integrating with existing systems.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#the-goal","title":"The Goal","text":"<p>Our goal is to achieve the following:</p> <ul> <li>Allow fine-grained access to the following resources - collection, database, tenant, and Chroma server.</li> <li>AlGrouping of users for improved permission management.</li> <li>Individual user access to resources</li> <li>Roles - owner, writer, reader</li> </ul> <p>Document-Level Access</p> <p>Although granting access to individual documents in a collection can be beneficial in some contexts, we have left that part out of our goals to keep things as simple and short as possible. If you are interested in this topic, reach out, and we will help you.</p> <p>This article will not cover user management, commonly called Identity Access Management (IAM). We\u2019ll cover that in a subsequent article.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#modeling-fundamentals","title":"Modeling Fundamentals","text":"<p>Let\u2019s start with the fundamentals:</p> <p><code>Why could user U perform an action A on an object O?</code></p> <p>We will attempt to answer the question in the context of Chroma by following OpenFGA approach to refining the model. The steps are:</p> <ol> <li>Pick the most important features.</li> <li>List of object types</li> <li>List of relations for the types</li> <li>Test the model</li> <li>Iterate</li> </ol> <p>Given that OpenFGA is Zanzibar inspired, the basic primitive for it is a tuple of the following format:</p> <pre><code>(User,Relation,Object)\n</code></pre> <p>With the above we can express any relation between a user (or a team or even another object) the action the user performs (captured by object relations) and the object (aka API resource).</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#pick-the-features","title":"Pick the features","text":"<p>In the context of Chroma, the features are the actions the user can perform on Chroma API (as of this writing v0.4.24).</p> <p>Let\u2019s explore what are the actions that users can perform:</p> <ul> <li>Create a tenant</li> <li>Get a tenant</li> <li>Create a database for a tenant</li> <li>Get a database for a tenant</li> <li>Create a collection in a database</li> <li>Delete a collection from a database</li> <li>Update collection name and metadata</li> <li>List collections in a database</li> <li>Count collections in a database</li> <li>Add records to a collection</li> <li>Delete records from a collection</li> <li>Update records in a collection</li> <li>Upsert records in a collection</li> <li>Count records in a collection</li> <li>Get records from a collection</li> <li>Query records in a collection</li> <li>Get pre-flight-checks</li> </ul> <p>Open Endpoints</p> <p>Note we will omit get <code>hearbeat</code> and get <code>version</code>actions as this is generally a good idea to be open so that orchestrators (docker/k8s) can get the health status of chroma.</p> <p>To make it easy to reason about relations in our authorization model we will rephrase the above to the following format:</p> <pre><code>A user {user} can perform action {action} to/on/in {object types} ... IF {conditions}\n</code></pre> <ul> <li>A user can perform action create tenant on Chroma server if they are owner of the server</li> <li>A user can perform action get tenant on Chroma server if they are a reader or writer or owner of the server</li> <li>A user can perform action create database on a tenant if they are an owner of the tenant</li> <li>A user can perform action get database on a tenant if they are reader, writer or owner of the tenant</li> <li>A user can perform action create collection on a database if they are a writer or an owner of the database</li> <li>A user can perform action delete collection on a database if they are a writer or an owner of the database</li> <li>A user can perform action update collection name or metadata on a database if they are a writer or an owner of the   database</li> <li>A user can perform action list collections in a database if they are a writer or an owner of the database</li> <li>A user can perform action count collections in a database if they are a writer or an owner of the database</li> <li>A user can perform action add records on a collection if they are writer or owner of the collection</li> <li>A user can perform action delete records on a collection if they are writer or owner of the collection</li> <li>A user can perform action update records on a collection if they are writer or owner of the collection</li> <li>A user can perform action upsert records on a collection if they are writer or owner of the collection</li> <li>A user can perform action get records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action count records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action query records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action get pre-flight-checks on a Chroma server if they are writer or owner or reader of the server</li> </ul> <p>We don\u2019t have to get it all right in the first iteration, but the above is a good starting point that can be adapted further.</p> <p>The above statements alone are already a great introspection as to what we can do within Chroma and who is supposed to be able to do what. Please note that your mileage may vary, as per your authz requirements, but in our experience the variations are generally around the who.</p> <p>As an astute reader you have already noted that we\u2019re generally outlined some RBAC stuff in the form of owner, writer and reader.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#list-the-objects","title":"List the objects!!!","text":"<p>Now that we know what our users can do, let\u2019s figure solidify our understanding of on what our users will be performing these actions, aka the object types.</p> <p>Let\u2019s call them out:</p> <ul> <li>User - this is basic and pretty obvious object type that we want to model our users after</li> <li>Chroma server - this is our top level object in the access relations</li> <li>Tenant - for most Chroma developers this will equate to a team or a group</li> <li>Database</li> <li>Collection</li> </ul> <p>We can also examine all of the <code>of the &lt;object&gt;</code> in the above statements to ensure we haven\u2019t missed any objects. So far seems we\u2019re all good.</p> <p>Now that we have our objects let\u2019s create a first iteration of our authorization model using OpenFGA DSL:</p> <pre><code>model\n  schema 1.1\n\ntype server\ntype user\ntype tenant\ntype database\ntype collection\n</code></pre> <p>OpenFGA CLI</p> <p>You will need to install openfga CLI - https://openfga.dev/docs/getting-started/install-sdk. Also check the VSCode extension for OpenFGA.</p> <p>Let\u2019s validate our work:</p> <pre><code>fga model validate --file model-article-p1.fga\n</code></pre> <p>You should see the following output:</p> <pre><code>{\n  \"is_valid\":true\n}\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#relations","title":"Relations","text":"<p>Now that we have the actions and the objects, let us figure out the relationships we want to build into our model.</p> <p>To come up with our relations we can follow these two rules:</p> <ul> <li>Any noun of the type <code>{noun} of a/an/the {type}</code> expression (e.g. <code>of the collection</code>)</li> <li>Any verb or action described with <code>can {action} on/in {type}</code></li> </ul> <p>So now let\u2019s work on our model to expand it with relationships:</p> <pre><code>model\n  schema 1.1\n\ntype user\n\ntype server\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define can_get_preflight: reader or owner or writer\n    define can_create_tenant: owner or writer\n\ntype tenant\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [server]\n    define can_create_database: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_get_database: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n\ntype database\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [tenant]\n    define can_create_collection: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_delete_collection: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_list_collections: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_get_collection: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_get_or_create_collection: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_count_collections: owner or writer or owner from belongsTo or writer from belongsTo\n\ntype collection\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [database]\n    define can_add_records: writer or reader or owner from belongsTo or writer from belongsTo\n    define can_delete_records: writer or owner from belongsTo or writer from belongsTo\n    define can_update_records: writer or owner from belongsTo or writer from belongsTo\n    define can_get_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n    define can_upsert_records: writer or owner from belongsTo or writer from belongsTo\n    define can_count_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n    define can_query_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n</code></pre> <p>Let\u2019s validated:</p> <pre><code>fga model validate --file model-article-p2.fga\n</code></pre> <p>This seems mostly accurate and should do ok as Authorization model. But let us see if we can make it better. If we are to implement the above we will end up with lots of permissions in OpenFGA, not that it can\u2019t handle them, but as we go into the implementation details it will become cumbersome to update and maintain all these permissions. So let\u2019s look for opportunity to simplify things a little.</p> <p>Can we make the model a little simpler and the first question we ask is do we really need owner, reader, writer on every object or can we make a decision about our model and simplify this. As it turns out we can. The way that most multi-user systems work is that they tend to gravitate to grouping things as a way to reduce the need to maintain a large number of permissions. In our case we can group our users into <code>team</code> and in each team we\u2019ll have owner, writer, reader</p> <p>Let\u2019s see the results:</p> <pre><code>model\n  schema 1.1\n\ntype user\n\ntype team\n  relations\n    define owner: [user]\n    define writer: [user]\n    define reader: [user]\n\ntype server\n  relations\n    define can_get_preflight: [user, team#owner, team#writer, team#reader]\n    define can_create_tenant: [user, team#owner, team#writer]\n    define can_get_tenant: [user, team#owner, team#writer, team#reader]\n\ntype tenant\n  relations\n    define can_create_database: [user, team#owner, team#writer]\n    define can_get_database: [user, team#owner, team#writer, team#reader]\n\ntype database\n  relations\n    define can_create_collection: [user, team#owner, team#writer]\n    define can_list_collections: [user, team#owner, team#writer, team#reader]\n    define can_get_or_create_collection: [user, team#owner, team#writer]\n    define can_count_collections: [user, team#owner, team#writer, team#reader]\n\ntype collection\n  relations\n    define can_delete_collection: [user, team#owner, team#writer]\n    define can_get_collection: [user, team#owner, team#writer, team#reader]\n    define can_update_collection: [user, team#owner, team#writer]\n    define can_add_records: [user, team#owner, team#writer]\n    define can_delete_records: [user, team#owner, team#writer]\n    define can_update_records: [user, team#owner, team#writer]\n    define can_get_records: [user, team#owner, team#writer, team#reader]\n    define can_upsert_records: [user, team#owner, team#writer]\n    define can_count_records: [user, team#owner, team#writer, team#reader]\n    define can_query_records: [user, team#owner, team#writer, team#reader]\n</code></pre> <p>That is arguably more readable.</p> <p>As you will observe we have also added <code>[user]</code> in the permissions of each object, why is that you may ask. The reason is that we want to build a fine-grained authorization, which means while a collection can be belong to a team, we can also grant individual permissions to users. This gives us a great way to play around with permissions at the cost of a more complex implementation of how permissions are managed, but we will get to that in the next post.</p> <p>We have also removed the <code>belongsTo</code> relationship as we no longer need it. Reason: OpenFGA does not allow access of relations more than a single layer into the hierarchy thus a collection cannot use the owner of its team for permissions (there are other ways to implement that outside of the scope of this article).</p> <p>Let\u2019s recap what is our model capable of doing:</p> <ul> <li>Fine-grained access control to objects is possible via relations</li> <li>Users can be grouped into teams (a single user per team is also acceptable for cases where you need a user to be the   sole owner of a collection or a database)</li> <li>Access to resources can be granted to individual users via object relations</li> <li>Define roles within a team (this can be extended to allow roles per resource, but is outside of the scope of this   article)</li> </ul> <p>In short we have achieved the goals we have initially set, with a relatively simple and understandable model. However, does our model work? Let\u2019s find out in the next section.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#testing-the-model","title":"Testing the model","text":"<p>Luckily OpenFGA folks have provided a great developer experience by making it easy to write and run tests. This is a massive W and time-saver.</p> <ul> <li>An individual user can be given access to specific resources via relations</li> <li>Users can be part of any of the team roles</li> <li>An object can access by a team</li> </ul> <pre><code>name: Chroma Authorization Model Tests # optional\n\nmodel_file: ./model-article-p4.fga # you can specify an external .fga file, or include it inline\n\n# tuple_file: ./tuples.yaml # you can specify an external file, or include it inline\ntuples:\n  - user: user:jane\n    relation: owner\n    object: team:chroma\n  - user: user:john\n    relation: writer\n    object: team:chroma\n  - user: user:jill\n    relation: reader\n    object: team:chroma\n  - user: user:sam\n    relation: can_create_tenant\n    object: server:server1\n  - user: user:sam\n    relation: can_get_tenant\n    object: server:server1\n  - user: user:sam\n    relation: can_get_preflight\n    object: server:server1\n  - user: user:michelle\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_get_tenant\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_get_tenant\n    object: server:server1\n  - user: team:chroma#reader\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#reader\n    relation: can_get_tenant\n    object: server:server1\n\ntests:\n  - name: Users should have team roles\n    check:\n      - user: user:jane\n        object: team:chroma\n        assertions:\n          owner: true\n          writer: false\n          reader: false\n      - user: user:john\n        object: team:chroma\n        assertions:\n          writer: true\n          owner: false\n          reader: false\n      - user: user:jill\n        object: team:chroma\n        assertions:\n          writer: false\n          owner: false\n          reader: true\n      - user: user:unknown\n        object: team:chroma\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n      - user: user:jane\n        object: team:unknown\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n      - user: user:unknown\n        object: team:unknown\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n  - name: Users should have direct access to server\n    check:\n      - user: user:sam\n        object: server:server1\n        assertions:\n          can_get_preflight: true\n          can_create_tenant: true\n          can_get_tenant: true\n      - user: user:michelle\n        object: server:server1\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: true\n          can_get_tenant: false\n      - user: user:unknown\n        object: server:server1\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: false\n          can_get_tenant: false\n      - user: user:jill\n        object: server:serverX\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: false\n          can_get_tenant: false\n  - name: Users of a team should have access to server\n    check:\n      - user: user:jane\n        object: server:server1\n        assertions:\n          can_create_tenant: true\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:john\n        object: server:server1\n        assertions:\n          can_create_tenant: true\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:jill\n        object: server:server1\n        assertions:\n          can_create_tenant: false\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:unknown\n        object: server:server1\n        assertions:\n          can_create_tenant: false\n          can_get_tenant: false\n          can_get_preflight: false\n</code></pre> <p>Let\u2019s run the tests:</p> <pre><code>fga model test --tests test.model-article-p4.fga.yaml\n</code></pre> <p>This will result in the following output:</p> <pre><code># Test Summary #\nTests 3/3 passing\nChecks 42/42 passing\n</code></pre> <p>That is all folks. We try to keep things as concise as possible and this article has already our levels of comfort in that area. The bottom line is that authorization is no joke and it should take as long of a time as needed.</p> <p>Writing out all tests will not be concise (maybe we\u2019ll add that to the repo).</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#conclusion","title":"Conclusion","text":"<p>In this article we\u2019ve have built an authorization model for Chroma from scratch using OpenFGA. Admittedly it is a simple model, it still gives is a lot of flexibility to control access to Chroma resources.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#resources","title":"Resources","text":"<ul> <li>https://github.com/amikos-tech/chromadb-auth - the companion repo for this article (files are stored   under <code>openfga/basic/</code>)</li> <li>https://openfga.dev/docs - Read it, understand it, code it!</li> <li>https://marketplace.visualstudio.com/items?itemName=openfga.openfga-vscode - It makes your life easier</li> </ul>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/","title":"Multi-User Basic Auth","text":""},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#why-multi-user-auth","title":"Why Multi-user Auth?","text":"<p>Multi-user authentication can be crucial for several reasons. Let's delve into this topic.</p> <p>Security\u2014The primary concern is the security of your deployments. You need to control who can access your data and ensure they are authorized to do so. You may wonder, since Chroma offers basic and token-based authentication, why is multi-user authentication necessary?</p> <p>You should never share your Chroma access credentials with your users or any app that depends on Chroma. The answer to this concern is a categorical NO.</p> <p>Another reason to consider multi-user authentication is to differentiate access to your data. However, the solution presented here doesn't provide this. It's a stepping stone towards our upcoming article on multi-tenancy and securing Chroma data.</p> <p>Last but not least is auditing. While we acknowledge this is not for everybody, there is ~~an~~ increasing pressure to provide visibility into your app via auditable events.</p> <p>Multi-user experiences - Not all GenAI apps are intended to be private or individual. This is another reason to consider and implement multi-user authentication and authorization.</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#dive-right-in","title":"Dive right in.","text":"<p>Let's get straight to the point and build a multi-user authorization with basic authentication. Here's our goal:</p> <ul> <li>Develop a server-side authorization provider that can read multiple users from a <code>.htpasswd</code> file</li> <li>Generate a multi-user <code>.htpasswd</code> file with several test users</li> <li>Package our plugin with the Chroma base image and execute it using Docker Compose</li> </ul> <p>Auth CIP</p> <p>Chroma has detailed info about how its authentication and authorization are implemented. Should you want to learn more go read the CIP (Chroma Improvement Proposal doc).</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#the-plugin","title":"The Plugin","text":"<pre><code>import importlib\nimport logging\nfrom typing import Dict, cast, TypeVar, Optional\n\nfrom chromadb.auth import (\n    ServerAuthCredentialsProvider,\n    AbstractCredentials,\n    SimpleUserIdentity,\n)\nfrom chromadb.auth.registry import register_provider\nfrom chromadb.config import System\nfrom chromadb.telemetry.opentelemetry import (\n    OpenTelemetryGranularity,\n    trace_method,\n    add_attributes_to_current_span,\n)\nfrom pydantic import SecretStr\nfrom overrides import override\n\nT = TypeVar(\"T\")\n\nlogger = logging.getLogger(__name__)\n\n\n@register_provider(\"multi_user_htpasswd_file\")\nclass MultiUserHtpasswdFileServerAuthCredentialsProvider(ServerAuthCredentialsProvider):\n    _creds: Dict[str, SecretStr]  # contains user:password-hash\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        try:\n            self.bc = importlib.import_module(\"bcrypt\")\n        except ImportError:\n            raise ValueError(\n                \"The bcrypt python package is not installed. \"\n                \"Please install it with `pip install bcrypt`\"\n            )\n        system.settings.require(\"chroma_server_auth_credentials_file\")\n        _file = str(system.settings.chroma_server_auth_credentials_file)\n        self._creds = dict()\n        with open(_file, \"r\") as f:\n            for line in f:\n                _raw_creds = [v for v in line.strip().split(\":\")]\n                if len(_raw_creds) != 2:\n                    raise ValueError(\n                        \"Invalid Htpasswd credentials found in \"\n                        f\"[{str(system.settings.chroma_server_auth_credentials_file)}]. \"\n                        \"Must be &lt;username&gt;:&lt;bcrypt passwd&gt;.\"\n                    )\n                self._creds[_raw_creds[0]] = SecretStr(_raw_creds[1])\n\n    @trace_method(  # type: ignore\n        \"MultiUserHtpasswdFileServerAuthCredentialsProvider.validate_credentials\",\n        OpenTelemetryGranularity.ALL,\n    )\n    @override\n    def validate_credentials(self, credentials: AbstractCredentials[T]) -&gt; bool:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n\n        if len(_creds) != 2 or \"username\" not in _creds or \"password\" not in _creds:\n            logger.error(\n                \"Returned credentials did match expected format: \"\n                \"dict[username:SecretStr, password: SecretStr]\"\n            )\n            add_attributes_to_current_span(\n                {\n                    \"auth_succeeded\": False,\n                    \"auth_error\": \"Returned credentials did match expected format: \"\n                                  \"dict[username:SecretStr, password: SecretStr]\",\n                }\n            )\n            return False  # early exit on wrong format\n        _user_pwd_hash = (\n            self._creds[_creds[\"username\"].get_secret_value()]\n            if _creds[\"username\"].get_secret_value() in self._creds\n            else None\n        )\n        validation_response = _user_pwd_hash is not None and self.bc.checkpw(\n            _creds[\"password\"].get_secret_value().encode(\"utf-8\"),\n            _user_pwd_hash.get_secret_value().encode(\"utf-8\"),\n        )\n        add_attributes_to_current_span(\n            {\n                \"auth_succeeded\": validation_response,\n                \"auth_error\": f\"Failed to validate credentials for user {_creds['username'].get_secret_value()}\"\n                if not validation_response\n                else \"\",\n            }\n        )\n        return validation_response\n\n    @override\n    def get_user_identity(\n            self, credentials: AbstractCredentials[T]\n    ) -&gt; Optional[SimpleUserIdentity]:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n        return SimpleUserIdentity(_creds[\"username\"].get_secret_value())\n</code></pre> <p>In less than 80 lines of code, we have our plugin. Let's delve into and explain some of the key points of the code above:</p> <ul> <li><code>__init__</code> - Here, we dynamically import bcrypt, which we'll use to check user credentials. We also read the   configured credentials file - <code>server.htpasswd</code> line by line, to retrieve each user (we assume each line contains a   new user with its bcrypt hash).</li> <li><code>validate_credentials</code> - This is where the magic happens. We initially perform some lightweight validations on the   credentials parsed by Chroma and passed to the plugin. Then, we attempt to retrieve the user and its hash from   the <code>_creds</code> dictionary. The final step is to verify the hash. We've also added some attributes to monitor our   authentication process in our observability layer (we have an upcoming article about this).</li> <li><code>get_user_identity</code> - Constructs a simple user identity, which the authorization plugin uses to verify permissions.   Although not needed for now, each authentication plugin must implement this, as user identities are crucial for   authorization.</li> </ul> <p>We'll store our plugin in <code>__init__.py</code> within the following directory structure - <code>chroma_auth/authn/basic/__init__.py</code> (refer to the repository for details).</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#password-file","title":"Password file","text":"<p>Now that we have our plugin let\u2019s create a password file with a few users:</p> <p>Initial user:</p> <pre><code>echo \"password123\" | htpasswd -iBc server.htpasswd admin\n</code></pre> <p>The above will create (<code>-c</code> flag) a new server.htpasswd file with initial user <code>admin</code> and the password will be read from stdin (<code>-i</code> flag) and saved as bcrypt hash (<code>-B</code> flag)</p> <p>Let\u2019s add another user:</p> <pre><code>echo \"password123\" | htpasswd -iB server.htpasswd user1\n</code></pre> <p>Now our <code>server.htpasswd</code> file will look like this:</p> <pre><code>admin:$2y$05$vkBK4b1Vk5O98jNHgr.uduTJsTOfM395sKEKe48EkJCVPH/MBIeHK\nuser1:$2y$05$UQ0kC2x3T2XgeN4WU12BdekUwCJmLjJNhMaMtFNolYdj83OqiEpVu\n</code></pre> <p>Moving on to docker setup.</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#docker-compose-setup","title":"Docker compose setup","text":"<p>Let\u2019s create a <code>Dockerfile</code> to bundle our plugin with the official Chroma image:</p> <pre><code>ARG CHROMA_VERSION=0.4.24\nFROM ghcr.io/chroma-core/chroma:${CHROMA_VERSION} as base\n\nCOPY chroma_auth/ /chroma/chroma_auth\n</code></pre> <p>This will pick up the official docker image for Chroma and will add our plugin directory structure so that we can use it.</p> <p>Now let\u2019s create an <code>.env</code> file to load our plugin:</p> <pre><code>CHROMA_SERVER_AUTH_PROVIDER=\"chromadb.auth.basic.BasicAuthServerProvider\"\nCHROMA_SERVER_AUTH_CREDENTIALS_FILE=\"server.htpasswd\"\nCHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=\"chroma_auth.authn.basic.MultiUserHtpasswdFileServerAuthCredentialsProvider\"\n</code></pre> <p>And finally our <code>docker-compose.yaml</code>:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: chroma-server\n    build:\n      dockerfile: Dockerfile\n    volumes:\n      - ./chroma-data:/chroma/chroma\n      - ./server.htpasswd:/chroma/server.htpasswd\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n</code></pre>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#the-test","title":"The test","text":"<p>Let\u2019s run our docker compose setup:</p> <pre><code>docker compose --env-file ./.env up --build\n</code></pre> <p>You should see the following log message if the plugin was successfully loaded:</p> <pre><code>server-1  | DEBUG:    [01-04-2024 14:10:13] Starting component MultiUserHtpasswdFileServerAuthCredentialsProvider\nserver-1  | DEBUG:    [01-04-2024 14:10:13] Starting component BasicAuthServerProvider\nserver-1  | DEBUG:    [01-04-2024 14:10:13] Starting component FastAPIChromaAuthMiddleware\n</code></pre> <p>Once our container is up and running, let\u2019s see if our multi-user auth works:</p> <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.get_or_create_collection(\"test_collection\")  # this is a protected endpoint and requires authentication\nclient.list_collections()  # this is a protected endpoint and requires authentication\n</code></pre> <p>The above code should return the list of collections, a single collection <code>test_collection</code> that we created.</p> <pre><code>(chromadb-multi-user-basic-auth-py3.11) [chromadb-multi-user-basic-auth]python                                                                                                                                                                                                            19:51:38  \u2601  main \u2602 \u26a1 \u271a\nPython 3.11.7 (main, Dec 30 2023, 14:03:09) [Clang 15.0.0 (clang-1500.1.0.2.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import chromadb\n&gt;&gt;&gt; from chromadb.config import Settings\n&gt;&gt;&gt; \n&gt;&gt;&gt; client = chromadb.HttpClient(\n...     settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"admin:password123\"))\n&gt;&gt;&gt; client.heartbeat()  # this should work with or without authentication - it is a public endpoint\n1711990302270211007\n&gt;&gt;&gt; \n&gt;&gt;&gt; client.list_collections()  # this is a protected endpoint and requires authentication\n[]\n</code></pre> <p>Great, now let\u2019s test for our other user:</p> <pre><code>client = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"user1:password123\"))\n</code></pre> <p>Works just as well (logs omitted for brevity).</p> <p>To ensure that our plugin works as expected let\u2019s also test with an user that is not in our <code>server.htpasswd</code> file:</p> <pre><code>client = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"invalid_user:password123\"))\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/__init__.py\", line 197, in HttpClient\n    return ClientCreator(tenant=tenant, database=database, settings=settings)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 144, in __init__\n    self._validate_tenant_database(tenant=tenant, database=database)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 445, in _validate_tenant_database\n    raise e\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 438, in _validate_tenant_database\n    self._admin_client.get_tenant(name=tenant)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 486, in get_tenant\n    return self._server.get_tenant(name=name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py\", line 127, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/fastapi.py\", line 200, in get_tenant\n    raise_chroma_error(resp)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/fastapi.py\", line 649, in raise_chroma_error\n    raise chroma_error\nchromadb.errors.AuthorizationError: Unauthorized\n</code></pre> <p>As expected, we get auth error when trying to connect to Chroma (the client initialization validates the tenant and DB which are both protected endpoints which raises the exception above).</p>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/","title":"Naive Multi-tenancy Strategies","text":"<p>Single-note Chroma</p> <p>The below strategies are applicable to single-node Chroma only. The strategies require your app to act as both PEP (Policy Enforcement Point)  and PDP (Policy Decision Point) for authorization. This is a naive approach to multi-tenancy and is probably not suited for production environments, however it is a good and simple way to get started with multi-tenancy in Chroma.</p> <p>Authorization</p> <p>We are in the process of creating a list of articles on how to implement proper authorization in Chroma,  leveraging the an external service and Chroma's auth plugins. The first article of the series is available in  Medium  and will also be made available here soon.</p>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#introduction","title":"Introduction","text":"<p>There are several multi-tenancy strategies available to users of Chroma. The actual strategy will depend on the needs of the user and the application. The strategies below apply to multi-user environments, but do no factor in partly-shared resources like groups or teams.</p> <ul> <li>User-Per-Doc: In this scenario, the app maintains multiple collections and each collection document is associated   with a single user.</li> <li>User-Per-Collection: In this scenario, the app maintains multiple collections and each collection is   associated with a single user.</li> <li>User-Per-Database: In this scenario, the app maintains multiple databases with a single tenant and each database   is   associated with a single user.</li> <li>User-Per-Tenant: In this scenario, the app maintains multiple tenants and each tenant is associated with a single   user.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-doc","title":"User-Per-Doc","text":"<p>The goal of this strategy is to grant user permissions to access individual documents.</p> <p></p> <p>To implement this strategy you need to add some sort of user identification to each document that belongs to a user. For this example we will assume it is <code>user_id</code>.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient()\ncollection = client.get_or_create_collection(\"my-collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    metadatas=[{\"user_id\": \"user1\"}, {\"user_id\": \"user2\"}],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>At query time you will have to provide the <code>user_id</code> as a filter to your query like so:</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    where=[{\"user_id\": \"user1\"}],\n)\n</code></pre> <p>To successfully implement this strategy your code needs to consistently add and filter on the <code>user_id</code> metadata to ensure separation of data.</p> <p>Drawbacks:</p> <ul> <li>Error-prone: Messing up the filtering can lead to data being leaked across users.</li> <li>Scalability: As the number of users and documents grow, doing filtering on metadata can become slow.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-collection","title":"User-Per-Collection","text":"<p>The goal of this strategy is to grant a user access to all documents in a collection.</p> <p></p> <p>To implement this strategy you need to create a collection for each user. For this example we will assume it is <code>user_id</code>.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient()\nuser_id = \"user1\"\ncollection = client.get_or_create_collection(f\"user-collection:{user_id}\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>At query time you will have to provide the <code>user_id</code> as a filter to your query like so:</p> <pre><code>user_id = \"user1\"\nuser_collection = client.get_collection(f\"user-collection:{user_id}\")\nresults = user_collection.query(\n    query_texts=[\"This is a query document\"],\n)\n</code></pre> <p>To successfully implement this strategy your code needs to consistently create and query the correct collection for the user.</p> <p>Drawbacks:</p> <ul> <li>Error-prone: Messing up the collection name can lead to data being leaked across users.</li> <li>Shared document search: If you want to maintain some documents shared then you will have to create a separate   collection for those documents and allow users to query the shared collection as well.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-database","title":"User-Per-Database","text":"<p>The goal of this strategy is to associate a user with a single database thus granting them access to all collections and documents within the database.</p> <p></p> <pre><code>import chromadb\nfrom chromadb import DEFAULT_TENANT\nfrom chromadb import Settings\n\nadminClient = chromadb.AdminClient(Settings(\n    is_persistent=True,\n    persist_directory=\"multitenant\",\n))\n\n\n# For Remote Chroma server:\n# \n# adminClient= chromadb.AdminClient(Settings(\n#   chroma_api_impl=\"chromadb.api.fastapi.FastAPI\",\n#   chroma_server_host=\"localhost\",\n#   chroma_server_http_port=\"8000\",\n# ))\n\ndef get_or_create_db_for_user(user_id):\n    database = f\"db:{user_id}\"\n    try:\n        adminClient.get_database(database)\n    except Exception as e:\n        adminClient.create_database(database, DEFAULT_TENANT)\n    return DEFAULT_TENANT, database\n\n\nuser_id = \"user_John\"\n\ntenant, database = get_or_create_db_for_user(user_id)\n# replace with chromadb.HttpClient for remote Chroma server\nclient = chromadb.PersistentClient(path=\"multitenant\", tenant=tenant, database=database)\ncollection = client.get_or_create_collection(\"user_collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>In the above code we do the following:</p> <ul> <li>We create or get a database for each user in the <code>DEFAULT_TENANT</code> using the <code>chromadb.AdminClient</code>.</li> <li>We then create a <code>PersistentClient</code> for each user with the <code>tenant</code> and <code>database</code> we got from the <code>AdminClient</code>.</li> <li>We then create or get collection and add data to it.</li> </ul> <p>Drawbacks:</p> <ul> <li>This strategy requires consistent management of tenants and databases and their use in the client application.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-tenant","title":"User-Per-Tenant","text":"<p>The goal of this strategy is to associate a user with a single tenant thus granting them access to all databases, collections, and documents within the tenant.</p> <p></p> <pre><code>import chromadb\nfrom chromadb import DEFAULT_DATABASE\nfrom chromadb import Settings\n\nadminClient = chromadb.AdminClient(Settings(\n    chroma_api_impl=\"chromadb.api.segment.SegmentAPI\",\n    is_persistent=True,\n    persist_directory=\"multitenant\",\n))\n\n\n# For Remote Chroma server:\n# \n# adminClient= chromadb.AdminClient(Settings(\n#   chroma_api_impl=\"chromadb.api.fastapi.FastAPI\",\n#   chroma_server_host=\"localhost\",\n#   chroma_server_http_port=\"8000\",\n# ))\n\ndef get_or_create_tenant_for_user(user_id):\n    tenant_id = f\"tenant_user:{user_id}\"\n    try:\n        adminClient.get_tenant(tenant_id)\n    except Exception as e:\n        adminClient.create_tenant(tenant_id)\n        adminClient.create_database(DEFAULT_DATABASE, tenant_id)\n    return tenant_id, DEFAULT_DATABASE\n\n\nuser_id = \"user1\"\n\ntenant, database = get_or_create_tenant_for_user(user_id)\n# replace with chromadb.HttpClient for remote Chroma server\nclient = chromadb.PersistentClient(path=\"multitenant\", tenant=tenant, database=database)\ncollection = client.get_or_create_collection(\"user_collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>In the above code we do the following:</p> <ul> <li>We create or get a tenant for each user with <code>DEFAULT_DATABASE</code> using the <code>chromadb.AdminClient</code>.</li> <li>We then create a <code>PersistentClient</code> for each user with the <code>tenant</code> and <code>database</code> we got from the <code>AdminClient</code>.</li> <li>We then create or get collection and add data to it.</li> </ul> <p>Drawbacks:</p> <ul> <li>This strategy requires consistent management of tenants and databases and their use in the client application.</li> </ul>"}]}