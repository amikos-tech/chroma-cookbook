{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ChromaDB Cookbook","text":"<p>This is a collection of small guides and recipes to help you get started with ChromaDB.</p> <p>Latest ChromaDB version: 0.4.24</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>We suggest you first head to the Concepts section to get familiar with ChromaDB concepts, such as Documents, Metadata, Embeddings, etc.</p> <p>Once you're comfortable with the concepts, you can jump to the Installation section to install ChromaDB.</p> <p>Core Topics:</p> <ul> <li>Filters - Learn to filter data in ChromaDB using metadata and document filters</li> <li>Resource Requirements - Understand the resource requirements for running ChromaDB</li> <li>\u2728Multi-Tenancy - Learn how to implement multi-tenancy in ChromaDB</li> </ul>"},{"location":"#running-chromadb","title":"Running ChromaDB","text":"<ul> <li>CLI - Running ChromaDB via the CLI</li> <li>Docker - Running ChromaDB in Docker</li> <li>Docker Compose - Running ChromaDB in Docker Compose</li> <li>Kubernetes - Running ChromaDB in Kubernetes (Minikube)</li> </ul>"},{"location":"#integrations","title":"Integrations","text":"<ul> <li>\u2728LangChain - Integrating ChromaDB with LangChain</li> <li>\u2728LlamaIndex - Integrating ChromaDB with LlamaIndex</li> <li>\u2728Ollama - Integrating ChromaDB with Ollama</li> </ul>"},{"location":"#the-ecosystem","title":"The Ecosystem","text":""},{"location":"#clients","title":"Clients","text":"<p>Below is a list of available clients for ChromaDB.</p> <ul> <li>Python Client (Official Chroma client)</li> <li>JavaScript Client (Official Chroma client)</li> <li>Ruby Client (Community maintained)</li> <li>Java Client (Community maintained)</li> <li>Go Client (Community maintained)</li> <li>C# Client (Microsoft maintained)</li> <li>Rust Client (Community maintained)</li> <li>Elixir Client (Community maintained)</li> <li>Dart Client (Community maintained)</li> <li>PHP Client (Community maintained)</li> <li>PHP (Laravel) Client (Community maintained)</li> </ul>"},{"location":"#user-interfaces","title":"User Interfaces","text":"<ul> <li>VectorAdmin (MintPlex Labs) - An open-source web-based admin   interface for vector databases, including ChromaDB</li> <li>ChromaDB UI (Community maintained) - A web-based UI for ChromaDB</li> </ul>"},{"location":"#cli-tooling","title":"CLI Tooling","text":"<ul> <li>Chroma CLI (Community maintained) - Early Alpha</li> <li>Chroma Data Pipes (Community maintained) - A CLI tool for   importing and exporting data from ChromaDB</li> <li>Chroma Ops (Community maintained) - A maintenance CLI tool for ChromaDB</li> </ul>"},{"location":"#strategies","title":"Strategies","text":"<ul> <li>Backup - Backing up ChromaDB data</li> <li>Batch Imports - Importing data in batches</li> <li>Multi-Tenancy - Running multiple ChromaDB instances</li> <li>Keyword Search - Searching for keywords in ChromaDB</li> <li>Memory Management - Managing memory in ChromaDB</li> <li>Time-based Queries - Querying data based on timestamps</li> <li>\u2728'<code>Coming Soon</code> Testing with Chroma - learn how to test your GenAI apps that include Chroma.</li> <li>\u2728'<code>Coming Soon</code> Monitoring Chroma - learn how to monitor your Chroma instance.</li> <li>\u2728'<code>Coming Soon</code> Building Chroma clients - learn how to build clients for Chroma.</li> <li>\u2728'<code>Coming Soon</code> Creating the perfect Embedding Function (wrapper) - learn the best practices for creating your own   embedding function.</li> <li>\u2728 Multi-User Basic Auth Plugin - learn how to build a multi-user   basic authentication plugin for Chroma.</li> <li>\u2728 CORS Configuration For JS Browser apps - learn how to configure CORS for Chroma.</li> </ul>"},{"location":"#get-help","title":"Get Help","text":"<p>Missing something? Let us know by opening an issue, reach out on Discord (look for <code>@taz</code>).</p>"},{"location":"contributing/getting-started/","title":"Getting Started with Contributing to Chroma","text":""},{"location":"contributing/getting-started/#overview","title":"Overview","text":"<p>Here are some steps to follow:</p> <ul> <li>Fork the repository (if you are part of an organization to which you cannot grant permissions it might be advisable to fork under your own user account to allow other community members to contribute by granting them permissions, something that is a bit more difficult at organizational level)</li> <li>Clone your forked repo locally (git clone ...) under a dir with an apt name for the change you want to make e.g. <code>my_awesome_feature</code></li> <li>Create a branch for your change (git checkout -b my_awesome_feature)</li> <li>Make your changes</li> <li>Test (see Testing)</li> <li>Lint (see Linting)</li> <li>Commit your changes (git commit -am 'Added some feature')</li> <li>Push to the branch (git push origin my_awesome_feature)</li> <li>Create a new Pull Request (PR) from your forked repository to the main Chroma repository</li> </ul>"},{"location":"contributing/getting-started/#testing","title":"Testing","text":"<p>It is generally good to test your changes before submitting a PR.</p> <p>To run the full test suite:</p> <pre><code>pip install -r requirements_dev.txt\npytest\n</code></pre> <p>To run a specific test:</p> <pre><code>pytest chromadb/tests/test_api.py::test_get_collection\n</code></pre> <p>If you want to see the output of print statements in the tests, you can run:</p> <pre><code>pytest -s\n</code></pre> <p>If you want your pytest to stop on first failure, you can run:</p> <pre><code>pytest -x\n</code></pre>"},{"location":"contributing/getting-started/#integration-tests","title":"Integration Tests","text":"<p>You can only run the integration tests by running:</p> <pre><code>sh bin/bin/integration-test\n</code></pre> <p>The above will create a docker container and will run the integration tests against it. This will also include JS client.</p>"},{"location":"contributing/getting-started/#linting","title":"Linting","text":""},{"location":"contributing/useful-shortcuts/","title":"Useful Shortcuts for Contributors","text":""},{"location":"contributing/useful-shortcuts/#git","title":"Git","text":""},{"location":"contributing/useful-shortcuts/#aliases","title":"Aliases","text":""},{"location":"contributing/useful-shortcuts/#create-venv-and-install-dependencies","title":"Create venv and install dependencies","text":"<p>Add the following to your <code>.bashrc</code>, <code>.zshrc</code> or <code>.profile</code>:</p> <pre><code>alias chroma-init='python -m virtualenv venv &amp;&amp; source venv/bin/activate &amp;&amp; pip install -r requirements.txt &amp;&amp; pip install -r requirements_dev.txt'\n</code></pre>"},{"location":"core/api/","title":"Chroma API","text":"<p>In this article we will cover the Chroma API in an indepth details.</p>"},{"location":"core/api/#accessing-the-api","title":"Accessing the API","text":"<p>If you are running a Chroma server you can access its API at - <code>http://&lt;chroma_server_host&gt;:&lt;chroma_server_port&gt;/docs</code> ( e.g. <code>http://localhost:8000/docs</code>).</p>"},{"location":"core/api/#api-endpoints","title":"API Endpoints","text":"<p>TBD</p>"},{"location":"core/api/#generating-clients","title":"Generating Clients","text":"<p>While Chroma ecosystem has client implementations for many languages, it may be the case you want to roll out your own. Below we explain some of the options available to you:</p>"},{"location":"core/api/#using-openapi-generator","title":"Using OpenAPI Generator","text":"<p>The fastest way to build a client is to use the OpenAPI Generator the API spec.</p>"},{"location":"core/api/#manually-creating-a-client","title":"Manually Creating a Client","text":"<p>If you more control over things, you can create your own client by using the API spec as guideline.</p> <p>For your convenience we provide some data structures in various languages to help you get started. The important structures are:</p> <ul> <li>Client</li> <li>Collection</li> <li>Embedding</li> <li>Document</li> <li>ID</li> <li>Metadata</li> <li>QueryRequest/QueryResponse</li> <li>Include</li> <li>Where Filter</li> <li>WhereDocument Filter</li> </ul>"},{"location":"core/api/#python","title":"Python","text":""},{"location":"core/api/#typescript","title":"Typescript","text":""},{"location":"core/api/#golang","title":"Golang","text":""},{"location":"core/api/#java","title":"Java","text":""},{"location":"core/api/#rust","title":"Rust","text":""},{"location":"core/api/#elixir","title":"Elixir","text":""},{"location":"core/clients/","title":"Chroma Clients","text":""},{"location":"core/clients/#persistent-client","title":"Persistent Client","text":"<p>To create your a local persistent client use the <code>PersistentClient</code> class. This client will store all data locally in a directory on your machine at the path you specify.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")\n</code></pre> <p><code>path</code> parameter must be a local path on the machine where Chroma is running. If the path does not exist, it will be created. The path can be relative or absolute. If the path is not specified, the default is <code>chroma/</code> in the current working directory.</p>"},{"location":"core/clients/#uses-of-persistent-client","title":"Uses of Persistent Client","text":"<p>The persistent client is useful for:</p> <ul> <li>Local development: You can use the persistent client to develop locally and test out ChromaDB.</li> <li>Embedded applications: You can use the persistent client to embed ChromaDB in your application. For example, if   you are building a web application, you can use the persistent client to store data locally on the server.</li> </ul>"},{"location":"core/clients/#http-client","title":"HTTP Client","text":"<p>Chroma also provides HTTP Client, suitable for use in a client-server mode. This client can be used to connect to a remote ChromaDB server.</p> <pre><code>import chromadb\n\nclient = chromadb.HttpClient(host=\"localhost\", port=\"8000\")\n</code></pre> <p>HTTP client takes two optional parameters:</p> <ul> <li><code>host</code>: The host of the remote server. If not specified, the default is <code>localhost</code>.</li> <li><code>port</code>: The port of the remote server. If not specified, the default is <code>8000</code>.</li> <li><code>ssl</code>: If <code>True</code>, the client will use HTTPS. If not specified, the default is <code>False</code>.</li> </ul>"},{"location":"core/clients/#uses-of-http-client","title":"Uses of HTTP Client","text":"<p>The HTTP client is ideal for when you want to scale your application or move off of local machine storage. It is important to note that there are trade-offs associated with using HTTP client:</p> <ul> <li>Network latency - The time it takes to send a request to the server and receive a response.</li> <li>Serialization and deserialization overhead - The time it takes to convert data to a format that can be sent over the   network and then convert it back to its original format.</li> <li>Security - The data is sent over the network, so it is important to ensure that the connection is secure (we recommend   using both HTTPS and authentication).</li> <li>Availability - The server must be available for the client to connect to it.</li> <li>Bandwidth usage - The amount of data sent over the network.</li> <li>Data privacy and compliance - Storing data on a remote server may require compliance with data protection laws and   regulations.</li> <li>Difficulty in debugging - Debugging network issues can be more difficult than debugging local issues. The same applies   to server-side issues.</li> </ul>"},{"location":"core/clients/#host-parameter-special-cases","title":"Host parameter special cases","text":"<p>The <code>host</code> parameter supports a more advanced syntax than just the hostname. You can specify the whole endpoint ULR ( without the API paths), e.g. <code>https://chromadb.example.com:8000/my_server/path/</code>. This is useful when you want to use a reverse proxy or load balancer in front of your ChromaDB server.</p>"},{"location":"core/clients/#ephemeral-client","title":"Ephemeral Client","text":"<p>Ephemeral client is a client that does not store any data on disk. It is useful for fast prototyping and testing. To get started with an ephemeral client, use the <code>EphemeralClient</code> class.</p> <pre><code>import chromadb\n\nclient = chromadb.EphemeralClient()\n</code></pre>"},{"location":"core/clients/#environmental-variable-configured-client","title":"Environmental Variable Configured Client","text":"<p>You can also configure the client using environmental variables. This is useful when you want to configure any of the client configurations listed above via environmental variables.</p> <pre><code>import chromadb\n\nclient = chromadb.Client()\n</code></pre> <p>Short list of env variables that can be used to configure the client:</p> <p>Note: For complete list of available settings check (<code>chromadb.config.Settings</code>).</p> Env Variable Description Default chroma_api_impl The API implementation to use. There are two options: <code>chromadb.api.segment.SegmentAPI</code> (persistent client)  <code>chromadb.api.fastapi.FastAPI</code> (Http client) <code>chromadb.api.segment.SegmentAPI</code> chroma_server_host The host of the remote server. This is required for HttpClient only. <code>None</code>/<code>null</code> chroma_server_http_port The port of the remote server. This is required for HttpClient only. <code>8000</code> chroma_server_headers The headers to be sent to the server. This is required for HttpClient only. <code>None</code>/<code>null</code>"},{"location":"core/collections/","title":"Collections","text":"<p>Collections are the grouping mechanism for embeddings, documents, and metadata.</p>"},{"location":"core/collections/#collection-basics","title":"Collection Basics","text":""},{"location":"core/collections/#collection-properties","title":"Collection Properties","text":"<p>Each collection is characterized by the following properties:</p> <ul> <li><code>name</code>: The name of the collection. The name can be changed as long as it is unique within the database (   use <code>collection.modify(new_name=\"new_name\")</code> to change the name of the collection</li> <li><code>metadata</code>: A dictionary of metadata associated with the collection. The metadata is a dictionary of key-value pairs.   Keys can be strings, values can be strings, integers, floats, or booleans. Metadata can be changed   using <code>collection.modify(new_metadata={\"key\": \"value\"})</code> (Note: Metadata is always overwritten when modified)</li> <li><code>embedding_function</code>: The embedding function used to embed documents in the collection.</li> </ul> <p>Defaults:</p> <ul> <li>Embedding Function - by default if <code>embedding_function</code> parameter is not provided at <code>get()</code> or <code>create_collection()</code>   or <code>get_or_create_collection()</code> time, Chroma uses <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> which   uses the <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> to embed documents. The default embedding   function uses Onnx Runtime   with <code>all-MiniLM-L6-v2</code> model.</li> <li>distance metric - by default Chroma use L2 (Euclidean Distance Squared) distance metric for newly created collection.   You can change it at creation   time using <code>hnsw:space</code> metadata key. Possible values are <code>l2</code>, <code>cosine</code>, and 'ip' (inner product)</li> <li>Batch size, defined by <code>hnsw:batch_size</code> metadata key. Default is 100. The batch size defines the size of the   in-memory bruteforce index. Once the threshold is reached, vectors are added to the HNSW index and the bruteforce   index is cleared. Greater values may improve ingest performance. When updating also consider changing sync threshold</li> <li>Sync threshold, defined by <code>hnsw:sync_threshold</code> metadata key. Default 1000. The sync threshold defines the limit at   which the HNSW index is synced to disk. This limit only applies to newly added vectors.</li> </ul> <p>Keep in Mind</p> <p>Collection distance metric cannot be changed after the collection is created.  To change the distance metric see #cloning-a-collection</p> <p>Name Restrictions</p> <p>Collection names in Chroma must adhere to the following restrictions:</p> <p>(1) contains 3-63 characters (2) starts and ends with an alphanumeric character (3) otherwise contains only alphanumeric characters, underscores or hyphens (-) (4) contains no two consecutive periods (..) (5) is not a valid IPv4 address</p>"},{"location":"core/collections/#creating-a-collection","title":"Creating a collection","text":"<p>Official Docs</p> <p>For more information on the <code>create_collection</code> or <code>get_or_create_collection</code> methods, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to create. Parameter is required N/A String <code>metadata</code> Metadata associated with the collection. This is an optional parameter <code>None</code> Dictionary <code>embedding_function</code> Embedding function to use for the collection. This is an optional parameter <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> EmbeddingFunction <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.create_collection(\"test\")\n</code></pre> <p>Alternatively you can use the <code>get_or_create_collection</code> method to create a collection if it doesn't exist already.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\", metadata={\"key\": \"value\"})\n</code></pre> <p>Metadata with <code>get_or_create_collection()</code></p> <p>If the collection exists and metadata is provided in the method it will attempt to overwrite the existing metadata.</p>"},{"location":"core/collections/#deleting-a-collection","title":"Deleting a collection","text":"<p>Official Docs</p> <p>For more information on the <code>delete_collection</code> method, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to delete. Parameter is required N/A String <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\nclient.delete_collection(\"test\")\n</code></pre>"},{"location":"core/collections/#listing-all-collections","title":"Listing all collections","text":"<p>Official Docs</p> <p>For more information on the <code>list_collections</code> method, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>offset</code> The starting offset for listing collections. This is an optional parameter <code>None</code> Positive Integer <code>limit</code> The number of collections to return. If the remaining collections from <code>offset</code> are fewer than this number then returned collection will also be fewer. This is an optional parameter <code>None</code> Positive Integer <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncollections = client.list_collections()\n</code></pre>"},{"location":"core/collections/#getting-a-collection","title":"Getting a collection","text":"<p>Official Docs</p> <p>For more information on the <code>get_collection</code> method, see the official ChromaDB documentation.</p> <p>Parameters:</p> Name Description Default Value Type <code>name</code> Name of the collection to get. Parameter is required N/A String <code>embedding_function</code> Embedding function to use for the collection. This is an optional parameter <code>chromadb.utils.embedding_functions.DefaultEmbeddingFunction</code> EmbeddingFunction <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_collection(\"test\")\n</code></pre>"},{"location":"core/collections/#modifying-a-collection","title":"Modifying a collection","text":"<p>Official Docs</p> <p>For more information on the <code>modify</code> method, see the official ChromaDB documentation.</p> <p>Modify method on collection</p> <p>As the reader will observe <code>modify</code> method is called on the collection and node on the client as the rest of the collection lifecycle methods.</p> <p>Metadata Overwrite</p> <p>Metadata is always overwritten when modified. If you want to add a new key-value pair to the metadata, you must first get the existing metadata and then add the new key-value pair to it.</p> <p>Parameters:</p> Name Description Default Value Type <code>new_name</code> The new name of the collection. Parameter is required N/A String <code>metadata</code> Metadata associated with the collection. This is an optional parameter <code>None</code> Dictionary <p>Both collection properties (<code>name</code> and <code>metadata</code>) can be modified, separately ot together.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_collection(\"test\")\ncol.modify(name=\"test2\", metadata={\"key\": \"value\"})\n</code></pre>"},{"location":"core/collections/#counting-collections","title":"Counting Collections","text":"<p>Official Docs</p> <p>N/A</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection\n\nclient.count_collections()\n</code></pre>"},{"location":"core/collections/#iterating-over-a-collection","title":"Iterating over a Collection","text":"<pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")  # or HttpClient()\n\ncollection = client.get_or_create_collection(\"local_collection\")\ncollection.add(\n    ids=[f\"i\" for i in range(1000)],\n    documents=[f\"document {i}\" for i in range(1000)],\n    metadatas=[{\"doc_id\": i} for i in range(1000)])\nexisting_count = collection.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = collection.get(\n        include=[\"metadatas\", \"documents\", \"embeddings\"],\n        limit=batch_size,\n        offset=i)\n    print(batch)  # do something with the batch\n</code></pre>"},{"location":"core/collections/#collection-utilities","title":"Collection Utilities","text":""},{"location":"core/collections/#copying-local-collection-to-remote","title":"Copying Local Collection to Remote","text":"<p>The following example demonstrates how to copy a local collection to a remote ChromaDB server. (it also works in reverse)</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")\nremote_client = chromadb.HttpClient()\n\ncollection = client.get_or_create_collection(\"local_collection\")\ncollection.add(\n    ids=[\"1\", \"2\"],\n    documents=[\"hello world\", \"hello ChromaDB\"],\n    metadatas=[{\"a\": 1}, {\"b\": 2}])\nremote_collection = remote_client.get_or_create_collection(\"remote_collection\",\n                                                           metadata=collection.metadata)\nexisting_count = collection.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = collection.get(\n        include=[\"metadatas\", \"documents\", \"embeddings\"],\n        limit=batch_size,\n        offset=i)\n    remote_collection.add(\n        ids=batch[\"ids\"],\n        documents=batch[\"documents\"],\n        metadatas=batch[\"metadatas\"],\n        embeddings=batch[\"embeddings\"])\n</code></pre> <p>Using ChromaDB Data Pipes</p> <p>There is a more efficient way to copy data between local and remote collections using ChromaDB Data Pipes package.</p> <pre><code>pip install chromadb-data-pipes\ncdp export \"file://path/to_local_data/local_collection\" | \\\ncdp import \"http://remote_chromadb:port/remote_collection\" --create\n</code></pre>"},{"location":"core/collections/#cloning-a-collection","title":"Cloning a collection","text":"<p>Here are some reasons why you might want to clone a collection:</p> <ul> <li>Change distance function (via metadata - <code>hnsw:space</code>)</li> <li>Change HNSW hyper parameters (<code>hnsw:M</code>, <code>hnsw:construction_ef</code>, <code>hnsw:search_ef</code>)</li> </ul> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection with L2 (default)\n\ncol.add(ids=[f\"{i}\" for i in range(1000)], documents=[f\"document {i}\" for i in range(1000)])\nnewCol = client.get_or_create_collection(\"test1\", metadata={\n    \"hnsw:space\": \"cosine\"})  # let's change the distance function to cosine\n\nexisting_count = col.count()\nbatch_size = 10\nfor i in range(0, existing_count, batch_size):\n    batch = col.get(include=[\"metadatas\", \"documents\", \"embeddings\"], limit=batch_size, offset=i)\n    newCol.add(ids=batch[\"ids\"], documents=batch[\"documents\"], metadatas=batch[\"metadatas\"],\n               embeddings=batch[\"embeddings\"])\n\nprint(newCol.count())\nprint(newCol.get(offset=0, limit=10))  # get first 10 documents\n</code></pre>"},{"location":"core/collections/#cloning-a-subset-of-a-collection-with-query","title":"Cloning a subset of a collection with query","text":"<p>The below example demonstrates how to select a slice of an existing collection by using <code>where</code> and <code>where_document</code> query and creating a new collection with the selected slice.</p> <p>Race Condition</p> <p>The below example is not atomic and if data is changed between the initial selection query (<code>select_ids = col.get(...)</code> and the subsequent insertion query (<code>batch = col.get(...)</code>) the new collection may not contain the expected data.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")  # or HttpClient()\ncol = client.get_or_create_collection(\"test\")  # create a new collection with L2 (default)\n\ncol.add(ids=[f\"{i}\" for i in range(1000)], documents=[f\"document {i}\" for i in range(1000)])\nnewCol = client.get_or_create_collection(\"test1\", metadata={\n    \"hnsw:space\": \"cosine\", \"hnsw:M\": 32})  # let's change the distance function to cosine and M to 32\nquery_where = {\"metadata_key\": \"value\"}\nquery_where_document = {\"$contains\": \"document\"}\nselect_ids = col.get(where_document=query_where_document, where=query_where, include=[])  # get only IDs\nbatch_size = 10\nfor i in range(0, len(select_ids[\"ids\"]), batch_size):\n    batch = col.get(include=[\"metadatas\", \"documents\", \"embeddings\"], limit=batch_size, offset=i, where=query_where,\n                    where_document=query_where_document)\n    newCol.add(ids=batch[\"ids\"], documents=batch[\"documents\"], metadatas=batch[\"metadatas\"],\n               embeddings=batch[\"embeddings\"])\n\nprint(newCol.count())\nprint(newCol.get(offset=0, limit=10))  # get first 10 documents\n</code></pre>"},{"location":"core/collections/#updating-documentrecord-metadata","title":"Updating Document/Record Metadata","text":"<p>In this example we loop through all documents of a collection and strip all metadata fields of leading and trailing whitespace. Change the <code>update_metadata</code> function to suit your needs.</p> <pre><code>from chromadb import Settings\nimport chromadb\n\nclient = chromadb.PersistentClient(path=\"test\", settings=Settings(allow_reset=True))\nclient.reset()  # reset the database so we can run this script multiple times\ncol = client.get_or_create_collection(\"test\")\ncount = col.count()\n\n\ndef update_metadata(metadata: dict):\n    return {k: v.strip() for k, v in metadata.items()}\n\n\nfor i in range(0, count, 10):\n    batch = col.get(include=[\"metadatas\"], limit=10, offset=i)\n    col.update(ids=batch[\"ids\"], metadatas=[update_metadata(metadata) for metadata in batch[\"metadatas\"]])\n</code></pre>"},{"location":"core/concepts/","title":"Chroma Core Concepts","text":""},{"location":"core/concepts/#tenancy-and-db-hierarchies","title":"Tenancy and DB Hierarchies","text":"<p>The following picture illustrates the tenancy and DB hierarchy in Chroma:</p> <p></p> <p>Storage</p> <p>In Chroma single-node, all data about tenancy, databases, collections and documents is stored in a single SQLite database.</p>"},{"location":"core/concepts/#tenants","title":"Tenants","text":"<p>A tenant is a logical grouping for a set of databases. A tenant is designed to model a single organization or user. A tenant can have multiple databases.</p>"},{"location":"core/concepts/#databases","title":"Databases","text":"<p>A database is a logical grouping for a set of collections. A database is designed to model a single application or project. A database can have multiple collections.</p>"},{"location":"core/concepts/#collections","title":"Collections","text":"<p>Collections are the grouping mechanism for embeddings, documents, and metadata.</p>"},{"location":"core/concepts/#documents","title":"Documents","text":"<p>Chunks of text</p> <p>Documents in ChromaDB lingo are chunks of text that fits within the embedding model's context window.  Unlike other frameworks that use the term \"document\" to mean a file,  ChromaDB uses the term \"document\" to mean a chunk of text.</p> <p>Documents are raw chunks of text that are associated with an embedding. Documents are stored in the database and can be queried for.</p>"},{"location":"core/concepts/#metadata","title":"Metadata","text":"<p>Metadata is a dictionary of key-value pairs that can be associated with an embedding. Metadata is stored in the database and can be queried for.</p> <p>Metadata values can be of the following types:</p> <ul> <li>strings</li> <li>integers</li> <li>floats (float32)</li> <li>booleans</li> </ul>"},{"location":"core/concepts/#embedding-function","title":"Embedding Function","text":"<p>Also referred to as embedding model, embedding functions in ChromaDB are wrappers that expose a consistent interface for generating embedding vectors from documents or text queries.</p> <p>For a list of supported embedding functions see Chroma's official documentation.</p>"},{"location":"core/concepts/#distance-function","title":"Distance Function","text":"<p>Distance functions help in calculating the difference (distance) between two embedding vectors. ChromaDB supports the following distance functions:</p> <ul> <li>Cosine - Useful for text similarity</li> <li>Euclidean (L2) - Useful for text similarity, more sensitive to noise than <code>cosine</code></li> <li>Inner Product (IP) - Recommender systems</li> </ul>"},{"location":"core/concepts/#embedding-vector","title":"Embedding Vector","text":"<p>A representation of a document in the embedding space in te form of a vector, list of 32-bit floats (or ints).</p>"},{"location":"core/concepts/#embedding-model","title":"Embedding Model","text":""},{"location":"core/concepts/#document-and-metadata-index","title":"Document and Metadata Index","text":"<p>The document and metadata index is stored in SQLite database.</p>"},{"location":"core/concepts/#vector-index-hnsw-index","title":"Vector Index (HNSW Index)","text":"<p>Under the hood (ca. v0.4.22) Chroma uses its own fork HNSW lib for indexing and searching vectors.</p> <p>In a single-node mode, Chroma will create a single HNSW index for each collection. The index is stored in a subdir of your persistent dir, named after the collection id (UUID-based).</p> <p>The HNSW lib uses fast ANN algo to search the vectors in the index.</p>"},{"location":"core/document-ids/","title":"Document IDs","text":"<p>Chroma is unopinionated about document IDs and delegates those decisions to the user. This frees users to build semantics around their IDs.</p>"},{"location":"core/document-ids/#note-on-compound-ids","title":"Note on Compound IDs","text":"<p>While you can choose to use IDs that are composed of multiple sub-IDs (e.g. <code>user_id</code> + <code>document_id</code>), it is important to highlight that Chroma does not support querying by partial ID.</p>"},{"location":"core/document-ids/#common-practices","title":"Common Practices","text":""},{"location":"core/document-ids/#uuids","title":"UUIDs","text":"<p>UUIDs are a common choice for document IDs. They are unique, and can be generated in a distributed fashion. They are also opaque, which means that they do not contain any information about the document itself. This can be a good thing, as it allows you to change the document without changing the ID.</p> <pre><code>import uuid\nimport chromadb\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\n\ncollection.add(ids=[uuid.uuid4() for _ in range(len(documents))], documents=my_documents)\n</code></pre>"},{"location":"core/document-ids/#hashes","title":"Hashes","text":"<p>Hashes are another common choice for document IDs. They are unique, and can be generated in a distributed fashion. They are also opaque, which means that they do not contain any information about the document itself. This can be a good thing, as it allows you to change the document without changing the ID.</p> <pre><code>import hashlib\nimport os\nimport chromadb\n\ndef generate_sha256_hash():\n    # Generate a random number\n    random_data = os.urandom(16)\n    # Create a SHA256 hash object\n    sha256_hash = hashlib.sha256()\n    # Update the hash object with the random data\n    sha256_hash.update(random_data)\n    # Return the hexadecimal representation of the hash\n    return sha256_hash.hexdigest()\n\n\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\n\ncollection.add(ids=[generate_sha256_hash() for _ in range(len(documents))], documents=my_documents)\n</code></pre> <p>It is also possible to use the document as basis for the hash, the downside of that is that when the document changes and you have a semantic around the text as relating to the hash, you may need to update the hash.</p> <pre><code>import hashlib\nimport chromadb\n\ndef generate_sha256_hash_from_text(text):\n    # Create a SHA256 hash object\n    sha256_hash = hashlib.sha256()\n    # Update the hash object with the text encoded to bytes\n    sha256_hash.update(text.encode('utf-8'))\n    # Return the hexadecimal representation of the hash\n    return sha256_hash.hexdigest()\nmy_documents = [\n    \"Hello, world!\",\n    \"Hello, Chroma!\"\n]\n\nclient = chromadb.Client()\n\ncollection.add(ids=[generate_sha256_hash_from_text(documents[i]) for i in range(len(documents))], documents=my_documents)\n</code></pre>"},{"location":"core/document-ids/#semantic-strategies","title":"Semantic Strategies","text":"<p>In this section we'll explore a few different use cases for building semantics around document IDs.</p> <ul> <li>URL Slugs - if your docs are web pages with permalinks (e.g. blog posts), you can use the URL slug as the document ID.</li> <li>File Paths - if your docs are files on disk, you can use the file path as the document ID.</li> </ul>"},{"location":"core/filters/","title":"Filters","text":"<p>Chroma provides two types of filters:</p> <ul> <li>Metadata - filter documents based on metadata using <code>where</code> clause in either <code>Collection.query()</code> or <code>Collection.get()</code></li> <li>Document - filter documents based on document content using <code>where_document</code> in <code>Collection.query()</code> or `Collection.get().</li> </ul> <p>Those familiar with MongoDB queries will find Chroma's filters very similar.</p>"},{"location":"core/filters/#metadata-filters","title":"Metadata Filters","text":""},{"location":"core/filters/#equality","title":"Equality","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": \"is_equal_to_this\"}\n)\n</code></pre> <p>Alternative syntax:</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$eq\": \"is_equal_to_this\"}}\n)\n</code></pre>"},{"location":"core/filters/#inequality","title":"Inequality","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$ne\": \"is_not_equal_to_this\"}}\n)\n</code></pre>"},{"location":"core/filters/#greater-than","title":"Greater Than","text":"<p>Greater Than</p> <p>The <code>$gt</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$gt\": 5}}\n)\n</code></pre>"},{"location":"core/filters/#greater-than-or-equal","title":"Greater Than or Equal","text":"<p>Greater Than or Equal</p> <p>The <code>$gte</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$gte\": 5.1}}\n)\n</code></pre>"},{"location":"core/filters/#less-than","title":"Less Than","text":"<p>Less Than</p> <p>The <code>$lt</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$lt\": 5}}\n)\n</code></pre>"},{"location":"core/filters/#less-than-or-equal","title":"Less Than or Equal","text":"<p>Less Than or Equal</p> <p>The <code>$lte</code> operator is only supported for numerical values - int or float values.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$lte\": 5.1}}\n)\n</code></pre>"},{"location":"core/filters/#in","title":"In","text":"<p>In works on all data types - string, int, float, and bool.</p> <p>In</p> <p>The <code>$in</code> operator is only supported for list of values of the same type.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$in\": [\"value1\", \"value2\"]}}\n)\n</code></pre>"},{"location":"core/filters/#not-in","title":"Not In","text":"<p>Not In works on all data types - string, int, float, and bool.</p> <p>Not In</p> <p>The <code>$nin</code> operator is only supported for list of values of the same type.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"metadata_field\": {\"$nin\": [\"value1\", \"value2\"]}}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-and","title":"Logical Operator: And","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$and\": [{\"metadata_field1\": \"value1\"}, {\"metadata_field2\": \"value2\"}]}\n)\n</code></pre> <p>Logical Operators can be nested.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$and\": [{\"metadata_field1\": \"value1\"}, {\"$or\": [{\"metadata_field2\": \"value2\"}, {\"metadata_field3\": \"value3\"}]}]}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-or","title":"Logical Operator: Or","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where={\"$or\": [{\"metadata_field1\": \"value1\"}, {\"metadata_field2\": \"value2\"}]}\n)\n</code></pre>"},{"location":"core/filters/#document-filters","title":"Document Filters","text":""},{"location":"core/filters/#contains","title":"Contains","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$contains\": \"search_string\"}\n)\n</code></pre>"},{"location":"core/filters/#not-contains","title":"Not Contains","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$not_contains\": \"search_string\"}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-and_1","title":"Logical Operator: And","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$and\": [{\"$contains\": \"search_string1\"}, {\"$contains\": \"search_string2\"}]}\n)\n</code></pre> <p>Logical Operators can be nested.</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$and\": [{\"$contains\": \"search_string1\"}, {\"$or\": [{\"$not_contains\": \"search_string2\"}, {\"$not_contains\": \"search_string3\"}]}]}\n)\n</code></pre>"},{"location":"core/filters/#logical-operator-or_1","title":"Logical Operator: Or","text":"<pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    n_results=2,\n    where_document={\"$or\": [{\"$not_contains\": \"search_string1\"}, {\"$not_contains\": \"search_string2\"}]}\n)\n</code></pre>"},{"location":"core/install/","title":"Installation","text":""},{"location":"core/install/#core-chromadb","title":"Core ChromaDB","text":"<p>To install the latest version of chromadb, run:</p> <pre><code>pip install chromadb\n</code></pre> <p>To install a specific version of chromadb, run:</p> <pre><code>pip install chromadb==&lt;x.y.z&gt;\n</code></pre> <p>Releases</p> <p>You can find Chroma releases in PyPI here.</p>"},{"location":"core/install/#chromadb-python-client","title":"ChromaDB Python Client","text":"<p>To install the latest version of the ChromaDB Python client, run:</p> <pre><code>pip install chromadb-client\n</code></pre> <p>Releases</p> <p>You can find Chroma releases in PyPI here.</p>"},{"location":"core/resources/","title":"Resource Requirements","text":"<p>Chroma makes use of the following compute resources:</p> <ul> <li>RAM - Chroma stores the vector HNSW index in-memory. This allows it to perform blazing fast semantic searches.</li> <li>Disk - Chroma persists all data to disk. This includes the vector HNSW index, metadata index, system DB, and the   write-ahead log (WAL).</li> <li>CPU - Chroma uses CPU for indexing and searching vectors.</li> </ul> <p>Here are some formulas and heuristics to help you estimate the resources you need to run Chroma.</p>"},{"location":"core/resources/#ram","title":"RAM","text":"<p>Once you select your embedding model, use the following formula for calculating RAM storage requirements for the vector HNSW index:</p> <p><code>number of vectors</code> * <code>dimensionality of vectors</code> * <code>4 bytes</code> = <code>RAM required</code></p> <ul> <li><code>number of vectors</code> - This is the number of vectors you plan to index. These are the documents in your Chroma   collection (or chunks if you use LlamaIndex or LangChain terminology).</li> <li><code>dimensionality of vectors</code> - This is the dimensionality of the vectors output by your embedding model. For example,   if you use the <code>sentence-transformers/paraphrase-MiniLM-L6-v2</code> model, the dimensionality of the vectors is 384.</li> <li><code>4 bytes</code> - This is the size of each component of a vector. Chroma relies on HNSW lib implementation that uses 32bit   floats.</li> </ul>"},{"location":"core/resources/#disk","title":"Disk","text":"<p>Disk storage requirements mainly depend on what metadata you store and the number of vectors you index. The heuristics is at least 2-4x the RAM required for the vector HNSW index.</p> <p>WAL Cleanup</p> <p>Chroma does not currently clean the WAL so your sqlite3 metadata file will grow over time. In the meantime feel free to use available tooling to periodically clean your WAL - see chromadb-ops for more information.</p>"},{"location":"core/resources/#cpu","title":"CPU","text":"<p>There are no hard requirements for the CPU, but it is recommended to use as much CPU as you can spare as it directly relates to index and search speeds.</p>"},{"location":"core/system_constraints/","title":"Chroma System Constraints","text":"<p>This section contains common constraints of Chroma.</p> <ul> <li>Chroma is thread-safe</li> <li>Chroma is not process-safe</li> <li>Multiple Chroma Clients (Ephemeral, Persistent, Http) can be created from one or more threads within the same process</li> <li>A collection's name is unique within a Tenant and DB</li> <li>A collection's dimensions cannot change after creation =&gt; you cannot change the embedding function after creation</li> <li>Chroma operates in two modes - standalone (PersistentClient, EphemeralClient) and client/server (HttpClient with   ChromaServer)</li> <li>The distance function cannot be changed after collection creation.</li> </ul>"},{"location":"core/system_constraints/#operational-modes","title":"Operational Modes","text":"<p>Chroma can be operated in two modes:</p> <ul> <li>Standalone - This allows embedding Chroma in your python application without the need to communicate with external   processes.</li> <li>Client/Server - This allows embedding Chroma in your python application as a thin-client with minimal dependencies and   communicating with it via REST API. This is useful when you want to use Chroma from multiple processes or even   multiple machines.</li> </ul> <p>Depending on the mode you choose, you will need to consider the following component responsibilities:</p> <ul> <li>Standalone:<ul> <li>Clients (Persistent, Ephemeral) - Responsible for persistence, embedding, querying</li> </ul> </li> <li>Client/Server:<ul> <li>Clients (HttpClient) - Responsible for embedding, communication with Chroma server via REST API</li> <li>Server - Responsible for persistence and querying</li> </ul> </li> </ul> <p></p>"},{"location":"core/tenants-and-databases/","title":"Tenants and Databases","text":"<p>Tenants and Databases are two grouping abstractions that provides means to organize and manage data in Chroma.</p>"},{"location":"core/tenants-and-databases/#tenants","title":"Tenants","text":"<p>A tenant is a logical grouping of databases.</p>"},{"location":"core/tenants-and-databases/#databases","title":"Databases","text":"<p>A database is a logical grouping of collections.</p>"},{"location":"core/advanced/wal-pruning/","title":"Write-ahead Log (WAL) Pruning","text":"<p>As of this writing (v0.4.22) Chroma stores its WAL forever. This means that the WAL will grow indefinitely. This is obviously not ideal. Here we provide a small script + a few steps how to prune your WAL and keep it at a reasonable size. Pruning the WAL is particularly important if you have many writes to Chroma (e.g. documents are added, updated or deleted frequently).</p>"},{"location":"core/advanced/wal-pruning/#tooling","title":"Tooling","text":"<p>We have worked on a tooling to provide users with a way to prune their WAL - chroma-ops.</p> <p>To prune your WAL you can run the following command:</p> <pre><code>pip install chroma-ops\nchops cleanup-wal /path/to/persist_dir\n</code></pre> <p>\u26a0\ufe0f IMPORTANT: It is always a good thing to backup your data before you prune the WAL.</p>"},{"location":"core/advanced/wal-pruning/#manual","title":"Manual","text":"<p>Steps:</p> <p>Stop Chroma</p> <p>It is vitally important that you stop Chroma before you prune the WAL.  If you don't stop Chroma you risk corrupting</p> <ul> <li>\u26a0\ufe0f Stop Chroma</li> <li>\ud83d\udcbe Create a backup of your <code>chroma.sqlite3</code> file in your persistent dir</li> <li>\ud83d\udc40 Check your current <code>chroma.sqlite3</code> size (e.g. <code>ls -lh /path/to/persist/dir/chroma.sqlite3</code>)</li> <li>\ud83d\udda5\ufe0f Run the script below</li> <li>\ud83d\udd2d Check your current <code>chroma.sqlite3</code> size again to verify that the WAL has been pruned</li> <li>\ud83d\ude80 Start Chroma</li> </ul> <p>Script (store it in a file like <code>compact-wal.sql</code>)</p> wal_clean.py<pre><code>#!/usr/bin/env python3\n# Call the script: python wal_clean.py ./chroma-test-compact\nimport os\nimport sqlite3\nfrom typing import cast, Optional, Dict\nimport argparse\nimport pickle\n\n\nclass PersistentData:\n    \"\"\"Stores the data and metadata needed for a PersistentLocalHnswSegment\"\"\"\n\n    dimensionality: Optional[int]\n    total_elements_added: int\n    max_seq_id: int\n\n    id_to_label: Dict[str, int]\n    label_to_id: Dict[int, str]\n    id_to_seq_id: Dict[str, int]\n\n\ndef load_from_file(filename: str) -&gt; \"PersistentData\":\n    \"\"\"Load persistent data from a file\"\"\"\n    with open(filename, \"rb\") as f:\n        ret = cast(PersistentData, pickle.load(f))\n        return ret\n\n\ndef clean_wal(chroma_persist_dir: str):\n    if not os.path.exists(chroma_persist_dir):\n        raise Exception(f\"Persist {chroma_persist_dir} dir does not exist\")\n    if not os.path.exists(f'{chroma_persist_dir}/chroma.sqlite3'):\n        raise Exception(\n            f\"SQL file not found int persist dir {chroma_persist_dir}/chroma.sqlite3\")\n    # Connect to SQLite database\n    conn = sqlite3.connect(f'{chroma_persist_dir}/chroma.sqlite3')\n\n    # Create a cursor object\n    cursor = conn.cursor()\n\n    # SQL query\n    query = \"SELECT id,topic FROM segments where scope='VECTOR'\"  # Replace with your query\n\n    # Execute the query\n    cursor.execute(query)\n\n    # Fetch the results (if needed)\n    results = cursor.fetchall()\n    wal_cleanup_queries = []\n    for row in results:\n        # print(row)\n        metadata = load_from_file(\n            f'{chroma_persist_dir}/{row[0]}/index_metadata.pickle')\n        wal_cleanup_queries.append(\n            f\"DELETE FROM embeddings_queue WHERE seq_id &lt; {metadata.max_seq_id} AND topic='{row[1]}';\")\n\n    cursor.executescript('\\n'.join(wal_cleanup_queries))\n    # Close the cursor and connection\n    cursor.close()\n    conn.close()\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('persist_dir', type=str)\n    arg = parser.parse_args()\n    print(arg.persist_dir)\n    clean_wal(arg.persist_dir)\n</code></pre> <p>Run the script</p> <pre><code># Let's create a backup\ntar -czvf /path/to/persist/dir/chroma.sqlite3.backup.tar.gz /path/to/persist/dir/chroma.sqlite3\nlsof /path/to/persist/dir/chroma.sqlite3 # make sure that no process is using the file\npython wal_clean.py /path/to/persist/dir/\n# start chroma\n</code></pre>"},{"location":"core/advanced/wal/","title":"Write-ahead Log (WAL)","text":"<p>Chroma uses WAL to ensure data durability, even if things go wrong (e.g. server crashes). To achieve the latter Chroma uses what is known in the DB-industry as WAL or Write-Ahead Log. The purpose of the WAL is to ensure that each user request (aka transaction) is safely stored before acknowledging back to the user. Subsequently, in fact immediately after writing to the WAL, the data is also written to the index. This enables Chroma to serve as real-time search engine, where the data is available for querying immediately after it is written to the WAL.</p> <p>Below is a diagram that illustrates the WAL in ChromaDB (ca. v0.4.22):</p> <p></p>"},{"location":"core/advanced/wal/#vector-indices-overview","title":"Vector Indices Overview","text":"<p>The diagram below illustrates how data gets transferred from the WAL to the binary vector indices (Bruteforce and HNSW):</p> <p></p> <p>For each collection Chroma maintains two binary indices - Bruteforce (in-memory, fast) and HNSW lib (persisted to disk, slow when adding new vectors and persisting). As you can imagine, the BF index serves the role of a buffer that holds the uncommitted to HNWS persisted index portion of the WAL. The HNSW index itself has a max sequence id counter, stored in a metadata file, that indicates from which position in the WAL the buffering to the BF index should begin. The latter buffering usually happens when the collection is first accessed.</p> <p>There are two transfer points (in the diagram, sync threshold) for BF to HNSW:</p> <ul> <li><code>hnsw:batch_size</code> - forces the BF vectors to be added to HNSW in-memory (this is a slow operation)</li> <li> <p><code>hnsw:sync_threshold</code> - forces Chroma to dump the HNSW in-memory index to disk (this is a slow operation)</p> </li> <li> <p>Both of the above sync points are controlled via Collection-level metadata with respective named params. It is   customary <code>hnsw:sync_threshold</code> &gt; <code>hnsw:batch_size</code></p> </li> </ul>"},{"location":"core/advanced/wal/#metadata-indices-overview","title":"Metadata Indices Overview","text":"<p>The following diagram illustrates how data gets transferred from the WAL to the metadata index:</p> <p></p>"},{"location":"core/advanced/wal/#further-reading","title":"Further Reading","text":"<p>For the DevOps minded folks we have a few more resources:</p> <ul> <li>WAL Pruning - Clean up your WAL</li> </ul>"},{"location":"ecosystem/clients/","title":"Chroma Ecosystem Clients","text":""},{"location":"ecosystem/clients/#python","title":"Python","text":"Maintainer Chroma Core team Repo https://github.com/chroma-core/chroma Status \u2705 Stable Version <code>0.4.25.dev0</code> (PyPi Link) Docs https://docs.trychroma.com/api Compatibility Python: <code>3.7+</code>, Chroma API Version: <code>0.4.15+</code> <p>Feature Support:</p> Feature Supported Create Tenant \u2705 Get Tenant \u2705 Create DB \u2705 Get DB \u2705 Create Collection \u2705 Get Collection \u2705 List Collection \u2705 Count Collection \u2705 Delete Collection \u2705 Add Documents \u2705 Delete Documents \u2705 Update Documents \u2705 Query Documents \u2705 Get Document \u2705 Count Documents \u2705 Auth - Basic \u2705 Auth - Token \u2705 Reset \u2705 <p>Embedding Function Support:</p> Embedding Function Supported OpenAI \u2705 Sentence Transformers \u2705 HuggingFace Inference API \u2705 Cohere \u2705 Google Vertex AI \u2705 Google Generative AI (Gemini) \u2705 OpenCLIP (Multi-modal) \u2705 <p>Embedding Functions</p> <p>The list above is not exhaustive. Check  official docs for up-to-date information.</p>"},{"location":"ecosystem/clients/#javascript","title":"JavaScript","text":"Maintainer Chroma Core team Repo https://github.com/chroma-core/chroma Status \u2705 Stable Version <code>1.8.1</code> (NPM Link) Docs https://docs.trychroma.com/api Compatibility Python: <code>3.7+</code>, Chroma API Version: <code>TBD</code> <p>Feature Support:</p> Feature Supported Create Tenant \u2705 Get Tenant \u2705 Create DB \u2705 Get DB \u2705 Create Collection \u2705 Get Collection \u2705 List Collection \u2705 Count Collection \u2705 Delete Collection \u2705 Add Documents \u2705 Delete Documents \u2705 Update Documents \u2705 Query Documents \u2705 Get Document \u2705 Count Documents \u2705 Auth - Basic \u2705 Auth - Token \u2705 Reset \u2705 <p>Embedding Function Support:</p> Embedding Function Supported OpenAI \u2705 Sentence Transformers \u2705 HuggingFace Inference API \u2705 Cohere \u2705 Google Vertex AI \u2705 Google Generative AI (Gemini) \u2705 OpenCLIP (Multi-modal) \u2705 <p>Embedding Functions</p> <p>The list above is not exhaustive. Check  official docs for up-to-date information.</p>"},{"location":"ecosystem/clients/#ruby-client","title":"Ruby Client","text":"<p>https://github.com/mariochavez/chroma</p>"},{"location":"ecosystem/clients/#java-client","title":"Java Client","text":"<p>https://github.com/amikos-tech/chromadb-java-client</p>"},{"location":"ecosystem/clients/#go-client","title":"Go Client","text":"<p>https://github.com/amikos-tech/chroma-go</p>"},{"location":"ecosystem/clients/#c-client","title":"C# Client","text":"<p>https://github.com/microsoft/semantic-kernel/tree/main/dotnet/src/Connectors/Connectors.Memory.Chroma</p>"},{"location":"ecosystem/clients/#rust-client","title":"Rust Client","text":"<p>https://crates.io/crates/chromadb</p>"},{"location":"ecosystem/clients/#elixir-client","title":"Elixir Client","text":"<p>https://hex.pm/packages/chroma/</p>"},{"location":"ecosystem/clients/#dart-client","title":"Dart Client","text":"<p>https://pub.dev/packages/chromadb</p>"},{"location":"ecosystem/clients/#php-client","title":"PHP Client","text":"<p>https://github.com/CodeWithKyrian/chromadb-php</p>"},{"location":"ecosystem/clients/#php-laravel-client","title":"PHP (Laravel) Client","text":"<p>https://github.com/helgeSverre/chromadb</p>"},{"location":"embeddings/bring-your-own-embeddings/","title":"Creating your own embedding function","text":"<pre><code>from chromadb.api.types import (\n    Documents,\n    EmbeddingFunction,\n    Embeddings\n)\n\n\nclass MyCustomEmbeddingFunction(EmbeddingFunction[Documents]):\n    def __init__(\n            self,\n            my_ef_param: str\n    ):\n        \"\"\"Initialize the embedding function.\"\"\"\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        \"\"\"Embed the input documents.\"\"\"\n        return self._my_ef(input)\n</code></pre> <p>Now let's break the above down.</p> <p>First you create a class that inherits from <code>EmbeddingFunction[Documents]</code>. The <code>Documents</code> type is a list of <code>Document</code> objects. Each <code>Document</code> object has a <code>text</code> attribute that contains the text of the document. Chroma also supports multi-modal</p>"},{"location":"embeddings/bring-your-own-embeddings/#example-implementation","title":"Example Implementation","text":"<p>Below is an implementation of an embedding function that works with <code>transformers</code> models.</p> <p>Note</p> <p>This example requires the <code>transformers</code> and <code>torch</code> python packages. You can install them with <code>pip install transformers torch</code>.</p> <p>By default, all <code>transformers</code> models on HF are supported are also supported by the <code>sentence-transformers</code> package. For which Chroma provides out of the box support.</p> <pre><code>import importlib\nfrom typing import Optional, cast\n\nimport numpy as np\nimport numpy.typing as npt\nfrom chromadb.api.types import EmbeddingFunction, Documents, Embeddings\n\n\nclass TransformerEmbeddingFunction(EmbeddingFunction[Documents]):\n    def __init__(\n            self,\n            model_name: str = \"dbmdz/bert-base-turkish-cased\",\n            cache_dir: Optional[str] = None,\n    ):\n        try:\n            from transformers import AutoModel, AutoTokenizer\n\n            self._torch = importlib.import_module(\"torch\")\n            self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n            self._model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)\n        except ImportError:\n            raise ValueError(\n                \"The transformers and/or pytorch python package is not installed. Please install it with \"\n                \"`pip install transformers` or `pip install torch`\"\n            )\n\n    @staticmethod\n    def _normalize(v: npt.NDArray) -&gt; npt.NDArray:\n        norm = np.linalg.norm(v, axis=1)\n        norm[norm == 0] = 1e-12\n        return cast(npt.NDArray, v / norm[:, np.newaxis])\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        inputs = self._tokenizer(\n            input, padding=True, truncation=True, return_tensors=\"pt\"\n        )\n        with self._torch.no_grad():\n            outputs = self._model(**inputs)\n        embeddings = outputs.last_hidden_state.mean(dim=1)  # mean pooling\n        return [e.tolist() for e in self._normalize(embeddings)]\n</code></pre>"},{"location":"embeddings/embedding-models/","title":"Embedding Models","text":"<p>Work in Progress</p> <p>This page is a work in progress.</p> <p>Embedding Models are your best friends in the world of Chroma, and vector databases in general. They take something you understand in the form of text, images, audio etc. and turn it into a list of numbers (embeddings), which a machine learning model can understand. This process makes documents interpretable by a machine learning model.</p> <p></p>"},{"location":"embeddings/embedding-models/#characteristics-of-an-embedding-model","title":"Characteristics of an Embedding Model","text":"<ul> <li>Modality</li> <li>Context</li> <li>Tokenization</li> <li>Dimensionality</li> </ul>"},{"location":"embeddings/gpu-support/","title":"Embedding Functions GPU Support","text":"<p>By default, Chroma does not require GPU support for embedding functions. However, if you want to use GPU support, some of the functions, especially those running locally provide GPU support.</p>"},{"location":"embeddings/gpu-support/#default-embedding-functions-onnxruntime","title":"Default Embedding Functions (Onnxruntime)","text":"<p>To use the default embedding functions with GPU support, you need to install <code>onnxruntime-gpu</code> package. You can install it with the following command:</p> <pre><code>pip install onnxruntime-gpu\n</code></pre> <p>Note: To ensure no conflicts, you can uninstall <code>onnxruntime</code> (e.g. <code>pip uninstall onnxruntime</code>) in a separate environment.</p> <p>List available providers:</p> <pre><code>import onnxruntime\n\nprint(onnxruntime.get_available_providers())\n</code></pre> <p>Select the desired provider and set it as preferred before using the embedding functions (in the below example, we use <code>CUDAExecutionProvider</code>):</p> <pre><code>import time\nfrom chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2\n\nef = ONNXMiniLM_L6_V2(preferred_providers=['CUDAExecutionProvider'])\n\ndocs = []\nfor i in range(1000):\n    docs.append(f\"this is a document with id {i}\")\n\nstart_time = time.perf_counter()\nembeddings = ef(docs)\nend_time = time.perf_counter()\nprint(f\"Elapsed time: {end_time - start_time} seconds\")\n</code></pre> <p>IMPORTANT OBSERVATION: Our observations are that for GPU support using sentence transformers with model <code>all-MiniLM-L6-v2</code> outperforms onnxruntime with GPU support. In practical terms on a Colab T4 GPU, the onnxruntime example above runs for about 100s whereas the equivalent sentence transformers example runs for about 1.8s.</p>"},{"location":"embeddings/gpu-support/#sentence-transformers","title":"Sentence Transformers","text":"<pre><code>import time\nfrom chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n# This will download the model to your machine and set it up for GPU support\nef = SentenceTransformerEmbeddingFunction(model_name=\"thenlper/gte-small\", device=\"cuda\")\n\n# Test with 10k documents\ndocs = []\nfor i in range(10000):\n    docs.append(f\"this is a document with id {i}\")\n\nstart_time = time.perf_counter()\nembeddings = ef(docs)\nend_time = time.perf_counter()\nprint(f\"Elapsed time: {end_time - start_time} seconds\")\n</code></pre> <p>Note: You can run the above example in google Colab - see the notebook</p>"},{"location":"embeddings/gpu-support/#openclip","title":"OpenCLIP","text":"<p>Prior to PR #1806, we simply used the <code>torch</code> package to load the model and run it on the GPU.</p> <pre><code>import chromadb\nfrom chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\nfrom chromadb.utils.data_loaders import ImageLoader\nimport toch\nimport os\n\nIMAGE_FOLDER = \"images\"\ntoch.device(\"cuda\")\n\nembedding_function = OpenCLIPEmbeddingFunction()\nimage_loader = ImageLoader()\n\nclient = chromadb.PersistentClient(path=\"my_local_data\")\ncollection = client.create_collection(\n    name='multimodal_collection',\n    embedding_function=embedding_function,\n    data_loader=image_loader)\n\nimage_uris = sorted([os.path.join(IMAGE_FOLDER, image_name) for image_name in os.listdir(IMAGE_FOLDER)])\nids = [str(i) for i in range(len(image_uris))]\ncollection.add(ids=ids, uris=image_uris)\n</code></pre> <p>After PR #1806:</p> <pre><code>from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\nembedding_function = OpenCLIPEmbeddingFunction(device=\"cuda\")\n</code></pre>"},{"location":"integrations/langchain/","title":"Chroma Integrations With LangChain","text":"<ul> <li>Embeddings - learn how to use Chroma Embedding functions with LC and vice versa</li> <li>Retrievers - learn how to use LangChain retrievers with Chroma</li> </ul>"},{"location":"integrations/langchain/embeddings/","title":"Langchain Embeddings","text":""},{"location":"integrations/langchain/embeddings/#embedding-functions","title":"Embedding Functions","text":"<p>Chroma and Langchain both offer embedding functions which are wrappers on top of popular embedding models.</p> <p>Unfortunately Chroma and LC's embedding functions are not compatible with each other. Below we offer two adapters to convert Chroma's embedding functions to LC's and vice versa.</p> <p>Here is the adapter to convert Chroma's embedding functions to LC's:</p> <pre><code>from langchain_core.embeddings import Embeddings\nfrom chromadb.api.types import EmbeddingFunction\n\nclass ChromaEmbeddingsAdapter(Embeddings):\n  def __init__(self,ef:EmbeddingFunction):\n    self.ef = ef\n\n  def embed_documents(self,texts):\n    return self.ef(texts)\n\n  def embed_query(self, query):\n    return self.ef([query])[0]\n</code></pre> <p>Here is the adapter to convert LC's embedding functions to Chroma's:</p> <pre><code>from langchain_core.embeddings import Embeddings\nfrom chromadb.api.types import EmbeddingFunction\n\nclass LangChainEmbeddingAdapter(EmbeddingFunction):\n  def __init__(self,ef:Embeddings):\n    self.ef = ef\n\n  def __call__(self, input: Documents) -&gt; Embeddings:\n    # LC EFs also have embed_query but Chroma doesn't support that so we just use embed_documents\n    # TODO: better type checking\n    return self.ef.embed_documents(input)\n</code></pre>"},{"location":"integrations/langchain/embeddings/#example-usage","title":"Example Usage","text":"<p>Using Chroma Embedding Functions with Langchain:</p> <pre><code>from langchain.vectorstores.chroma import Chroma\nfrom chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n\nfrom langchain_core.embeddings import Embeddings\nfrom chromadb.api.types import EmbeddingFunction\n\ndocs_vectorstore = Chroma.from_texts(\n    texts=splits,\n    collection_name=\"docs_store\",\n    embedding=ef,\n)\n</code></pre>"},{"location":"integrations/langchain/retrievers/","title":"\ud83e\udd9c\u26d3\ufe0f Langchain Retriever","text":"<p>TBD: describe what retrievers are in LC and how they work.</p>"},{"location":"integrations/langchain/retrievers/#vector-store-retriever","title":"Vector Store Retriever","text":"<p>In the below example we demonstrate how to use Chroma as a vector store retriever with a filter query.</p> <p>Note that the filter is supplied whenever we create the retriever object so the filter applies to all queries (<code>get_relevant_documents</code>).</p> <pre><code>from langchain.document_loaders import OnlinePDFLoader\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nfrom langchain.vectorstores import Chroma\nfrom typing import Dict, Any\nimport chromadb\nfrom langchain_core.embeddings import Embeddings\n\nclient = chromadb.PersistentClient(path=\"./chroma\")\n\ncol = client.get_or_create_collection(\"test\")\n\ncol.upsert([f\"{i}\" for i in range(10)],documents=[f\"This is document #{i}\" for i in range(10)],metadatas=[{\"id\":f\"{i}\"} for i in range(10)])\n\nef = chromadb.utils.embedding_functions.DefaultEmbeddingFunction()\n\nclass DefChromaEF(Embeddings):\n  def __init__(self,ef):\n    self.ef = ef\n\n  def embed_documents(self,texts):\n    return self.ef(texts)\n\n  def embed_query(self, query):\n    return self.ef([query])[0]\n\n\ndb = Chroma(client=client, collection_name=\"test\",embedding_function=DefChromaEF(ef))\n\nretriever = db.as_retriever(search_kwargs={\"filter\":{\"id\":\"1\"}})\n\ndocs = retriever.get_relevant_documents(\"document\")\n\nassert len(docs)==1\n</code></pre> <p>Ref: https://colab.research.google.com/drive/1L0RwQVVBtvTTd6Le523P4uzz3m3fm0pH#scrollTo=xROOfxLohE5j</p>"},{"location":"integrations/llamaindex/","title":"Chroma Integrations With LlamaIndex","text":"<ul> <li>Embeddings - learn how to use LlamaIndex embeddings functions with Chroma and vice versa</li> </ul>"},{"location":"integrations/llamaindex/embeddings/","title":"LlamaIndex Embeddings","text":""},{"location":"integrations/llamaindex/embeddings/#embedding-functions","title":"Embedding Functions","text":"<p>Chroma and LlamaIndex both offer embedding functions which are wrappers on top of popular embedding models.</p> <p>Unfortunately Chroma and LI's embedding functions are not compatible with each other. Below we offer an adapters to convert LI embedding function to Chroma one.</p> <pre><code>from llama_index.core.schema import TextNode\nfrom llama_index.core.base.embeddings.base import BaseEmbedding\nfrom chromadb import EmbeddingFunction, Documents, Embeddings\n\n\nclass LlamaIndexEmbeddingAdapter(EmbeddingFunction):\n    def __init__(self, ef: BaseEmbedding):\n        self.ef = ef\n\n    def __call__(self, input: Documents) -&gt; Embeddings:\n        return [node.embedding for node in self.ef([TextNode(text=doc) for doc in input])]\n</code></pre> <p>Text modality</p> <p>The above adapter assumes that the input documents are text. If you are using a different modality,  you will need to modify the adapter accordingly.</p> <p>An example of how to use the above with LlamaIndex:</p> <p>Prerequisites for example</p> <p>Run <code>pip install llama-index chromadb llama-index-embeddings-fastembed fastembed</code></p> <pre><code>import chromadb\nfrom llama_index.embeddings.fastembed import FastEmbedEmbedding\n\n# make sure to include the above adapter and imports\nembed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test_collection\", embedding_function=LlamaIndexEmbeddingAdapter(embed_model))\n\ncol.add(ids=[\"1\"], documents=[\"this is a test document\"])\n</code></pre>"},{"location":"integrations/ollama/","title":"Chroma Integrations With Ollama","text":"<ul> <li>Embeddings - learn how to use Ollama as embedder for Chroma documents</li> <li>\u2728<code>Coming soon</code> RAG with Ollama - a primer on how to build a simple RAG app with Ollama and Chroma</li> </ul>"},{"location":"integrations/ollama/embeddings/","title":"Ollama","text":"<p>First let's run a local docker container with Ollama. We'll pull <code>nomic-embed-text</code> model:</p> <pre><code>docker run -d -v ./ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\ndocker exec -it ollama ollama run nomic-embed-text # press Ctrl+D to exit after model downloads successfully\n# test it\ncurl http://localhost:11434/api/embeddings -d '{\"model\": \"nomic-embed-text\",\"prompt\": \"Here is an article about llamas...\"}'\n</code></pre> <p>Ollama Docs</p> <p>For more information on Ollama, visit the Ollama GitHub repository.</p> <p>Now let's configure our OllamaEmbeddingFunction Embedding (python) function with the default Ollama endpoint:</p> <pre><code>import chromadb\nfrom chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n\nclient = chromadb.PersistentClient(path=\"ollama\")\n\n# create EF with custom endpoint\nef = OllamaEmbeddingFunction(\n    model_name=\"nomic-embed-text\",\n    url=\"http://localhost:11434/api/embeddings\",\n)\n\nprint(ef([\"Here is an article about llamas...\"]))\n</code></pre> <p>For JS users, you can use the <code>OllamaEmbeddingFunction</code> class to create embeddings:</p> <pre><code>const {OllamaEmbeddingFunction} = require('chromadb');\nconst embedder = new OllamaEmbeddingFunction({\n    url: \"http://localhost:11434/api/embeddings\",\n    model: \"nomic-embed-text\"\n})\n\n// use directly\nconst embeddings = embedder.generate([\"Here is an article about llamas...\"])\n</code></pre> <p>For Golang you can use the <code>chroma-go</code> client's <code>OllamaEmbeddingFunction</code> embedding function to generate embeddings for your documents:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    ollama \"github.com/amikos-tech/chroma-go/ollama\"\n)\n\nfunc main() {\n    documents := []string{\n        \"Document 1 content here\",\n        \"Document 2 content here\",\n    }\n    // the `/api/embeddings` endpoint is automatically appended to the base URL\n    ef, err := ollama.NewOllamaEmbeddingFunction(ollama.WithBaseURL(\"http://127.0.0.1:11434\"), ollama.WithModel(\"nomic-embed-text\"))\n    if err != nil {\n        fmt.Printf(\"Error creating Ollama embedding function: %s \\n\", err)\n    }\n    resp, err := ef.EmbedDocuments(context.Background(), documents)\n    if err != nil {\n        fmt.Printf(\"Error embedding documents: %s \\n\", err)\n    }\n    fmt.Printf(\"Embedding response: %v \\n\", resp)\n}\n</code></pre> <p>Golang Client</p> <p>You can install the Golang client by running the following command:</p> <pre><code>go get github.com/amikos-tech/chroma-go\n</code></pre> <p>For more information visit https://go-client.chromadb.dev/</p>"},{"location":"running/health-checks/","title":"Health Checks","text":""},{"location":"running/health-checks/#docker-compose","title":"Docker Compose","text":"<p>The simples form of health check is to use the <code>healthcheck</code> directive in the <code>docker-compose.yml</code> file. This is useful if you are deploying Chroma alongside other services that may depend on it.</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: server\n    build:\n      context: .\n      dockerfile: Dockerfile\n    volumes:\n      # Be aware that indexed data are located in \"/chroma/chroma/\"\n      # Default configuration for persist_directory in chromadb/config.py\n      # Read more about deployments: https://docs.trychroma.com/deployment\n      - chroma-data:/chroma/chroma\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n    ports:\n      - 8000:8000\n    healthcheck:\n      test: [ \"CMD\", \"/bin/bash\", \"-c\", \"cat &lt; /dev/null &gt; /dev/tcp/localhost/8001\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\nvolumes:\n  chroma-data:\n    driver: local\n</code></pre>"},{"location":"running/health-checks/#kubernetes","title":"Kubernetes","text":"<p>In kubernetes you can use the <code>livenessProbe</code> and <code>readinessProbe</code> to check the health of the server. This is useful if you are deploying Chroma in a kubernetes cluster.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: chroma\n  labels:\n    app: chroma\nspec:\n    replicas: 1\n    selector:\n        matchLabels:\n          app: chroma\n    template:\n        metadata:\n            labels:\n                app: chroma\n        spec:\n            containers:\n              - name: chroma\n                image: &lt;chroma-image&gt;\n                ports:\n                - containerPort: 8000\n                livenessProbe:\n                    httpGet:\n                        path: /api/v1\n                        port: 8000\n                    initialDelaySeconds: 5\n                    periodSeconds: 5\n                readinessProbe:\n                    httpGet:\n                        path: /api/v1\n                        port: 8000\n                    initialDelaySeconds: 5\n                    periodSeconds: 5\n                startupProbe:\n                    httpGet:\n                      path: /api/v1\n                      port: 8000\n                    failureThreshold: 3\n                    periodSeconds: 60\n                    initialDelaySeconds: 60\n</code></pre> <p>Alternative to the <code>httpGet</code> you can also use <code>tcpSocket</code>:</p> <pre><code>          readinessProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            timeoutSeconds: 30\n            periodSeconds: 60\n          livenessProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            timeoutSeconds: 30\n            periodSeconds: 60\n          startupProbe:\n            tcpSocket:\n              port: 8000\n            failureThreshold: 3\n            periodSeconds: 60\n            initialDelaySeconds: 60\n</code></pre>"},{"location":"running/running-chroma/","title":"Running Chroma","text":""},{"location":"running/running-chroma/#local-server","title":"Local Server","text":"<p>Article Link</p> <p>This article is also available on Medium Running ChromaDB \u2014 Part 1: Local Server.</p>"},{"location":"running/running-chroma/#chroma-cli","title":"Chroma CLI","text":"<p>The simplest way to run Chroma locally is via the Chroma <code>cli</code> which is part of the core Chroma package.</p> <p>Prerequisites:</p> <ul> <li>Python 3.8 to 3.11 - Download Python | Python.org</li> </ul> <pre><code>pip install chromadb\nchroma run --host localhost --port 8000 --path ./my_chroma_data\n</code></pre> <p><code>--host</code> The host to which to listen to, by default it is <code>[localhost](http://localhost:8000/docs)</code> , but if you want to expose it to your entire network then you can specify `0.0.0.0``</p> <p><code>--port</code> The port on which to listen to, by default this is <code>8000</code>.</p> <p><code>--path</code> The path where to persist your Chroma data locally.</p>"},{"location":"running/running-chroma/#docker","title":"Docker","text":"<p>Running Chroma server locally can be achieved via a simple docker command as shown below.</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> </ul> <pre><code>docker run -d --rm --name chromadb -v ./chroma:/chroma/chroma -e IS_PERSISTENT=TRUE -e ANONYMIZED_TELEMETRY=TRUE chromadb/chroma:latest\n</code></pre> <p>Options:</p> <ul> <li><code>-v</code> specifies a local dir which is where Chroma will store its data so when the container is destroyed the data   remains. Note: If you are using <code>-e PERSIST_DIRECTORY</code> then you need to point the volume to that directory.</li> <li><code>-e</code> <code>IS_PERSISTENT=TRUE</code> let\u2019s Chroma know to persist data</li> <li><code>-e</code> <code>PERSIST_DIRECTORY=/path/in/container</code> specifies the path in the container where the data will be stored, by   default it is <code>/chroma/chroma</code></li> <li><code>-e ANONYMIZED_TELEMETRY=TRUE</code> allows you to turn on (<code>TRUE</code>) or off (<code>FALSE</code>) anonymous product telemetry which helps   the Chroma team in making informed decisions about Chroma OSS and commercial direction.</li> <li><code>chromadb/chroma:latest</code> indicates the latest Chroma version but can be replaced with any valid tag if a prior version   is needed (e.g. <code>chroma:0.4.24</code>)</li> </ul>"},{"location":"running/running-chroma/#docker-compose-cloned-repo","title":"Docker Compose (Cloned Repo)","text":"<p>If you are feeling adventurous you can also use the Chroma <code>main</code> branch to run a local Chroma server with the latest changes:</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>Git - Git - Downloads (git-scm.com)</li> </ul> <pre><code>git clone https://github.com/chroma-core/chroma &amp;&amp; cd chroma\ndocker compose up -d --build\n</code></pre> <p>If you want to run a specific version of Chroma you can checkout the version tag you need:</p> <pre><code>git checkout release/0.4.24\n</code></pre>"},{"location":"running/running-chroma/#docker-compose-without-cloning-the-repo","title":"Docker Compose (Without Cloning the Repo)","text":"<p>If you do not wish or are able to clone the repo locally, Chroma server can also be run with docker compose by creating (or using a gist) a <code>docker-compose.yaml</code></p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>cURL (if you want to use the gist approach)</li> </ul> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\nservices:\n  chromadb:\n    image: chromadb/chroma:latest\n    volumes:\n      - ./chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma # this is the default path, change it as needed\n      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}\n    ports:\n      - 8000:8000\n    networks:\n      - net\n</code></pre> <p>The above will create a container with the latest Chroma (<code>chromadb/chroma:latest</code>), will expose it to port <code>8000</code> on the local machine and will persist data in <code>./chromadb</code> relative path from where the <code>docker-compose.yaml</code> has been ran.</p> <p>We have also created a small gist with the above file for convenience:</p> <pre><code>curl -s https://gist.githubusercontent.com/tazarov/4fd933274bbacb3b9f286b15c01e904b/raw/87268142d64d8ee0f7f98c27a62a5d089923a1df/docker-compose.yaml | docker-compose -f - up\n</code></pre>"},{"location":"running/running-chroma/#minikube-with-helm-chart","title":"Minikube With Helm Chart","text":"<p>Note: This deployment can just as well be done with <code>KinD</code> depending on your preference.</p> <p>A more advanced approach to running Chroma locally (but also on a remote cluster) is to deploy it using a Helm chart.</p> <p>Disclaimer: The chart used here is not a 1st party chart, but is contributed by a core contributor to Chroma.</p> <p>Prerequisites:</p> <ul> <li>Docker - Overview of Docker Desktop | Docker Docs</li> <li>Install minikube - minikube start | minikube (k8s.io)</li> <li>kubectl - Install Tools | Kubernetes</li> <li>Helm - Helm | Installing Helm</li> </ul> <p>Once you have all of the above running Chroma in a local <code>minikube</code> cluster quite simple</p> <p>Create a <code>minikube</code> cluster:</p> <pre><code>minikube start --addons=ingress -p chroma\nminikube profile chroma\n</code></pre> <p>Get and install the chart:</p> <pre><code>helm repo add chroma https://amikos-tech.github.io/chromadb-chart/\nhelm repo update\nhelm install chroma chroma/chromadb --set chromadb.apiVersion=\"0.4.24\"\n</code></pre> <p>By default the chart will enable authentication in Chroma. To get the token run the following:</p> <pre><code>kubectl --namespace default get secret chromadb-auth -o jsonpath=\"{.data.token}\" | base64 --decode\n# or use this to directly export variable\nexport CHROMA_TOKEN=$(kubectl --namespace default get secret chromadb-auth -o jsonpath=\"{.data.token}\" | base64 --decode)\n</code></pre> <p>The first step to connect and start using Chroma is to forward your port:</p> <pre><code>minikube service chroma-chromadb --url\n</code></pre> <p>The above should print something like this:</p> <pre><code>http://127.0.0.1:61892\n\u2757  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.\n</code></pre> <p>Note: Depending on your OS the message might be slightly different.</p> <p>Test it out (<code>pip install chromadb</code>):</p> <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(host=\"http://127.0.0.1:61892\",\n                             settings=Settings(\n                                 chroma_client_auth_provider=\"chromadb.auth.token.TokenAuthClientProvider\",\n                                 chroma_client_auth_credentials=\"&lt;your_chroma_token&gt;\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\n\nclient.get_version()  # this should work with or without authentication - it is a public endpoint\n\nclient.list_collections()  # this is a protected endpoint and requires authentication\n</code></pre> <p>For more information about the helm chart consult - https://github.com/amikos-tech/chromadb-chart</p>"},{"location":"strategies/backup/","title":"ChromaDB Backups","text":"<p>Depending on your use case there are a few different ways to back up your ChromaDB data.</p> <ul> <li>API export - this approach is relatively simple, slow for large datasets and may result in a backup that is missing   some updates, should your data change frequently.</li> <li>Disk snapshot - this approach is fast, but is highly dependent on the underlying storage. Should your cloud provider   and underlying volume support snapshots, this is a good option.</li> <li>Filesystem backup - this approach is also fast, but requires stopping your Chroma container to avoid data corruption.   This is a good option if you can afford to stop your Chroma container for a few minutes.</li> </ul> <p>Other Options</p> <p>Have another option in mind, feel free to add it to the above list.</p>"},{"location":"strategies/backup/#api-export","title":"API Export","text":""},{"location":"strategies/backup/#with-chroma-datapipes","title":"With Chroma Datapipes","text":"<p>One way to export via the API is to use Tooling like Chroma Data Pipes. Chroma Data Pipes is a command-line tool that provides a simple way import/export/transform ChromaDB data.</p> <p>Exporting from local filesystem:</p> <pre><code>cdp export \"file:///absolute/path/to/chroma-data/my-collection-name\" &gt; my_chroma_data.jsonl\n</code></pre> <p>Exporting from remote server:</p> <pre><code>cdp export \"http://remote-chroma-server:8000/my-collection-name\" &gt; my_chroma_data.jsonl\n</code></pre> <p>Get Help</p> <p>Read more about Chroma Data Pipes here</p>"},{"location":"strategies/backup/#disk-snapshot","title":"Disk Snapshot","text":"<p>TBD</p>"},{"location":"strategies/backup/#filesystem-backup","title":"Filesystem Backup","text":""},{"location":"strategies/backup/#from-docker-container","title":"From Docker Container","text":"<p>Sometimes you have been running Chroma in a Docker container without a host mount, intentionally or unintentionally. So all your data is now stored in the container's filesystem. Here's how you can back up your data:</p> <ol> <li>Stop the container:</li> </ol> <pre><code>docker stop &lt;chroma-container-id/name&gt;\n</code></pre> <ol> <li>Create a backup of the container's filesystem:</li> </ol> <pre><code>docker cp &lt;chroma-container-id/name&gt;:/chroma/chroma /path/to/backup\n</code></pre> <p><code>/path/to/backup</code> is the directory where you want to store the backup on your host machine.</p>"},{"location":"strategies/batching/","title":"Batching","text":"<p>It is often that you may need to ingest a large number of documents into Chroma. The problem you may face is related to the underlying SQLite version of the machine running Chroma which imposes a maximum number of statements and parameters which Chroma translates into a batchable record size, exposed via the <code>max_batch_size</code> parameter of the <code>ChromaClient</code> class.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient(path=\"test\")\nprint(\"Number of documents that can be inserted at once: \",client.max_batch_size)\n</code></pre>"},{"location":"strategies/batching/#creating-batches","title":"Creating Batches","text":"<p>Due to consistency and data integrity reasons, Chroma does not offer, yet, out-of-the-box batching support. The below code snippet shows how to create batches of documents and ingest them into Chroma.</p> <pre><code>import chromadb\nfrom chromadb.utils.batch_utils import create_batches\nimport uuid\n\nclient = chromadb.PersistentClient(path=\"test-large-batch\")\nlarge_batch = [(f\"{uuid.uuid4()}\", f\"document {i}\", [0.1] * 1536) for i in range(100000)]\nids, documents, embeddings = zip(*large_batch)\nbatches = create_batches(api=client,ids=list(ids), documents=list(documents), embeddings=list(embeddings))\ncollection = client.get_or_create_collection(\"test\")\nfor batch in batches:\n    print(f\"Adding batch of size {len(batch[0])}\")\n    collection.add(ids=batch[0],\n                   documents=batch[3],\n                   embeddings=batch[1],\n                   metadatas=batch[2])\n</code></pre>"},{"location":"strategies/cors/","title":"CORS Configuration for Browser-Based Access","text":"<p>Chroma JS package allows you to use Chroma in your browser-based SPA application. This is great, but that means that you'll need to configure Chroma to work with your browser to avoid CORS issues.</p>"},{"location":"strategies/cors/#setting-up-chroma-for-browser-based-access","title":"Setting up Chroma for Browser-Based Access","text":"<p>To allow browsers to directly access your Chroma instance you'll need to configure the <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code>. The <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> environment variable controls the hosts which are allowed to access your Chroma instance.</p> <p>Note</p> <p>The <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> environment variable is a list of strings. Each string is a URL that is allowed to access your Chroma instance. If you want to allow all hosts to access your Chroma instance, you can set <code>CHROMA_SERVER_CORS_ALLOW_ORIGINS</code> to <code>[\"*\"]</code>. This is not recommended for production environments.</p> <p>The below examples assume that your web app is running on <code>http://localhost:3000</code>. You can find an example of NextJS and Langchain here.</p> <p>Using Chroma run:</p> <pre><code>export CHROMA_SERVER_CORS_ALLOW_ORIGINS='[\"http://localhost:3000\"]'\nchroma run --path /path/to/chroma-data\n</code></pre> <p>Or with docker:</p> <pre><code>docker run -e CHROMA_SERVER_CORS_ALLOW_ORIGINS='[\"http://localhost:3000\"]' -v /path/to/chroma-data:/chroma/chroma -p 8000:8000 chromadb/chroma\n</code></pre> <p>Or in your <code>docker-compose.yml</code>:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: chromadb/chroma:0.5.0\n    volumes:\n      # Be aware that indexed data are located in \"/chroma/chroma/\"\n      # Default configuration for persist_directory in chromadb/config.py\n      # Read more about deployments: https://docs.trychroma.com/deployment\n      - chroma-data:/chroma/chroma\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS_FILE=${CHROMA_SERVER_AUTHN_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTHN_CREDENTIALS=${CHROMA_SERVER_AUTHN_CREDENTIALS}\n      - CHROMA_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=[\"http://localhost:3000\"]\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n\nvolumes:\n  chroma-data:\n    driver: local\n</code></pre>"},{"location":"strategies/keyword-search/","title":"Keyword Search","text":"<p>Chroma uses SQLite for storing metadata and documents. Additionally documents are indexed using SQLite FTS5 for fast text search.</p> <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.PersistentClient(path=\"test\", settings=Settings(allow_reset=True))\n\nclient.reset()\ncol = client.get_or_create_collection(\"test\")\n\ncol.upsert(ids=[\"1\", \"2\", \"3\"], documents=[\"He is a technology freak and he loves AI topics\", \"AI technology are advancing at a fast pace\", \"Innovation in LLMs is a hot topic\"],metadatas=[{\"author\": \"John Doe\"}, {\"author\": \"Jane Doe\"}, {\"author\": \"John Doe\"}])\ncol.query(query_texts=[\"technology\"], where_document={\"$or\":[{\"$contains\":\"technology\"}, {\"$contains\":\"freak\"}]})\n</code></pre> <p>The above should return:</p> <pre><code>{'ids': [['2', '1']],\n 'distances': [[1.052205477809135, 1.3074231535113972]],\n 'metadatas': [[{'author': 'Jane Doe'}, {'author': 'John Doe'}]],\n 'embeddings': None,\n 'documents': [['AI technology are advancing at a fast pace',\n   'He is a technology freak and he loves AI topics']],\n 'uris': None,\n 'data': None}\n</code></pre>"},{"location":"strategies/memory-management/","title":"Memory Management","text":""},{"location":"strategies/memory-management/#persistentclient","title":"PersistentClient","text":"<p>Note: The below code snippets assume you are working with a <code>PersistentClient</code></p> <p>At the time of writing (Chroma v0.4.22), Chroma does not allow you to manually unloading of collections from memory.</p> <p>Here we provide a simple utility function to help users unload collections from memory.</p> <p>Note: The function relies on Chroma internal APIs which may change. While we try to keep this documentation up-to-date, there may be versions of Chroma for which the below code won't work.</p> <pre><code>import chromadb\nfrom chromadb.segment import VectorReader\nfrom chromadb.types import SegmentScope\n\n\ndef unload_index(collection_name:str, chroma_client:chromadb.PersistentClient):\n    \"\"\"\n    Unloads binary hnsw index from memory and removes both segments (binary and metadata) from the segment cache.\n    \"\"\"\n    collection = chroma_client.get_collection(collection_name)\n    segment_manager = chroma_client._server._manager\n    segment = segment_manager.get_segment(collection.id, VectorReader)\n    segment.close_persistent_index()\n    if collection.id in segment_manager._segment_cache:\n        for scope in [SegmentScope.VECTOR, SegmentScope.METADATA]:\n            if scope in segment_manager._segment_cache[collection.id]:\n                del segment_manager._segment_cache[collection.id][segment[\"scope\"]]\n        del segment_manager._segment_cache[collection.id]\n</code></pre>"},{"location":"strategies/privacy/","title":"Privacy Strategies","text":""},{"location":"strategies/privacy/#overview","title":"Overview","text":"<p>TBD</p>"},{"location":"strategies/privacy/#encryption","title":"Encryption","text":""},{"location":"strategies/privacy/#document-encryption","title":"Document Encryption","text":""},{"location":"strategies/privacy/#client-side-document-encryption","title":"Client-side Document Encryption","text":"<p>See the notebook on client-side document encryption.</p>"},{"location":"strategies/rebuilding/","title":"Rebuilding Chroma DB","text":""},{"location":"strategies/rebuilding/#rebuilding-a-collection","title":"Rebuilding a Collection","text":"<p>Here are several reasons you might want to rebuild a collection:</p> <ul> <li>Your metadata or binary index is corrupted or even deleted</li> <li>Optimize performance of HNSW index after a large number of updates</li> </ul> <p>WAL Consistency and Backups</p> <p>Before you proceed, make sure to backup your data. Secondly make sure that your WAL contains all the data to allow  the proper rebuilding of the collection. For instance, after v0.4.22 you should not have run optimizations or WAL  cleanup.</p> <p>IMPORTANT</p> <p>Only do this on a stopped Chroma instance.</p> <p>Find the UUID of the target binary index directory to remove. Typically, the binary index directory is located in the persistent directory and is named after the collection vector segment (in <code>segments</code> table). You can find the UUID by running the following SQL query:</p> <pre><code>sqlite3 /path/to/db/chroma.sqlite3 \"select s.id, c.name from segments s join collections c on  s.collection=c.id where s.scope='VECTOR';\"\n</code></pre> <p>The above should print UUID dir and collection names.</p> <p>Once you remove/rename the UUID dir, restart Chroma and query your collection like so:</p> <p>import chromadb client = chromadb.HttpClient() # Adjust as per your client res = client.get_collection(\"my_collection\").get(limit=1,include=['embeddings'])</p> <p>Your collection will be recreated.</p> <p>Rebuilding the collection</p> <p>Depending on how large your collection is, this process can take a while.</p>"},{"location":"strategies/time-based-queries/","title":"Time-based Queries","text":""},{"location":"strategies/time-based-queries/#filtering-documents-by-timestamps","title":"Filtering Documents By Timestamps","text":"<p>In the example below, we create a collection with 100 documents, each with a random timestamp in the last two weeks. We then query the collection for documents that were created in the last week.</p> <p>The example demonstrates how Chroma metadata can be leveraged to filter documents based on how recently they were added or updated.</p> <pre><code>import uuid\nimport chromadb\n\nimport datetime\nimport random\n\nnow = datetime.datetime.now()\ntwo_weeks_ago = now - datetime.timedelta(days=14)\n\ndates = [\n    two_weeks_ago + datetime.timedelta(days=random.randint(0, 14))\n    for _ in range(100)\n]\ndates = [int(date.timestamp()) for date in dates]\n\n# convert epoch seconds to iso format\n\ndef iso_date(epoch_seconds): return datetime.datetime.fromtimestamp(\n    epoch_seconds).isoformat()\n\nclient = chromadb.EphemeralClient()\n\ncol = client.get_or_create_collection(\"test\")\n\ncol.add(ids=[f\"{uuid.uuid4()}\" for _ in range(100)], documents=[\n    f\"document {i}\" for i in range(100)], metadatas=[{\"date\": date} for date in dates])\n\nres = col.get(where={\"date\": {\"$gt\": (now - datetime.timedelta(days=7)).timestamp()}})\n\nfor i in res['metadatas']:\n    print(iso_date(i['date']))\n</code></pre> <p>Ref: https://gist.github.com/tazarov/3c9301d22ab863dca0b6fb1e5e3511b1</p>"},{"location":"strategies/multi-tenancy/","title":"Multi-Tenancy Strategies","text":""},{"location":"strategies/multi-tenancy/#introduction","title":"Introduction","text":"<p>Some deployment settings of Chroma may require multi-tenancy support. This document outlines the strategies for multi-tenancy approaches in Chroma.</p>"},{"location":"strategies/multi-tenancy/#approaches","title":"Approaches","text":"<ul> <li>Naive approach - This is a simple approach puts the onus of enforcing multi-tenancy on the   application. It is the simplest approach to implement, but is not very well suited for production environments.</li> <li>Multi-User Basic Auth - This article provides a stepping stone to more advanced   multi-tenancy where the Chroma   authentication allows for multiple users to access the same Chroma instance with their own credentials.</li> <li>Authorization Model with OpenFGA - Implement an advanced authorization model   with OpenFGA.</li> <li>Implementing OpenFGA Authorization Model In Chroma - Learn how to   implement OpenFGA authorization model in Chroma with full code example.</li> </ul>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/","title":"Implementing OpenFGA Authorization Model In Chroma","text":"<p>Source Code</p> <p>The source code for this article can be found here.</p>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#preparation","title":"Preparation","text":"<p>To make things useful we also introduce an initial tuple set with permissions which will allows us to test the authorization model.</p> <p>We define three users:</p> <ul> <li><code>admin</code> part of <code>chroma</code> team as <code>owner</code></li> <li><code>user1</code> part of <code>chroma</code> team as <code>reader</code></li> <li><code>admin-ext</code> part of <code>external</code> team as <code>owner</code></li> </ul> <p>We will give enough permissions to these three users and their respective teams so that they can perform collection creation, deletion, add records, remove records, get records and query records in the context of their role within the team - <code>owner</code> has access to all API actions while <code>reader</code> can only read, list get, query.</p> <p>Abbreviate Example</p> <p>We have removed some of the data from the above example for brevity. The full tuple set can be found under data/data/initial-data.json</p> <pre><code>[\n  {\n    \"object\": \"team:chroma\",\n    \"relation\": \"owner\",\n    \"user\": \"user:admin\"\n  },\n  {\n    \"object\": \"team:chroma\",\n    \"relation\": \"reader\",\n    \"user\": \"user:user1\"\n  },\n  {\n    \"object\": \"team:external\",\n    \"relation\": \"owner\",\n    \"user\": \"user:admin-ext\"\n  },\n  {\n    \"object\": \"server:localhost\",\n    \"relation\": \"can_get_tenant\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"tenant:default_tenant-default_database\",\n    \"relation\": \"can_get_database\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_create_collection\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_list_collections\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_get_or_create_collection\",\n    \"user\": \"team:chroma#owner\"\n  },\n  {\n    \"object\": \"database:default_tenant-default_database\",\n    \"relation\": \"can_count_collections\",\n    \"user\": \"team:chroma#owner\"\n  }\n]\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#testing-the-model","title":"Testing the model","text":"<p>Let\u2019s spin up a quick docker compose to test our setup. In the repo we have provided <code>openfga/docker-compose.openfga-standalone.yaml</code></p> <pre><code>docker compose -f openfga/docker-compose.openfga-standalone.yaml up\n</code></pre> <p>For this next part ensure you have FGA CLI installed.</p> <p>Once the containers are up and running let\u2019s create a store and import the model:</p> <pre><code>export FGA_API_URL=http://localhost:8082 # our OpenFGA binds to 8082 on localhost\nfga store create --model data/models/model-article-p4.fga --name chromadb-auth\n</code></pre> <p>You should see a response like this:</p> <pre><code>{\n  \"store\": {\n    \"created_at\": \"2024-04-09T18:37:26.367747Z\",\n    \"id\": \"01HV3VB347NPY3NMX6VQ5N2E23\",\n    \"name\": \"chromadb-auth\",\n    \"updated_at\": \"2024-04-09T18:37:26.367747Z\"\n  },\n  \"model\": {\n    \"authorization_model_id\": \"01HV3VB34JAXWF0F3C00DFBZV4\"\n  }\n}\n</code></pre> <p>Let\u2019s import our initial tuple set. Before that make sure to export <code>FGA_STORE_ID</code> and <code>FGA_MODEL_ID</code> as per the output of the previous command:</p> <pre><code>export FGA_STORE_ID=01HV3VB347NPY3NMX6VQ5N2E23\nexport FGA_MODEL_ID=01HV3VB34JAXWF0F3C00DFBZV4\nfga tuple write --file data/data/initial-data.json\n</code></pre> <p>Let\u2019s test our imported model and tuples:</p> <pre><code>fga query check user:admin can_get_preflight server:localhost\n</code></pre> <p>If everything is working you should see this:</p> <pre><code>{\n  \"allowed\": true,\n  \"resolution\": \"\"\n}\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#implementing-authorization-plumbing-in-chroma","title":"Implementing Authorization Plumbing in Chroma","text":"<p>First we will start with making a few small changes to the authorization plugin we\u2019ve made. Why you ask? We need to introduce teams (aka groups). For that we\u2019ll resort to standard Apache <code>groupfile</code> as follows:</p> <pre><code>chroma: admin, user1\nexternal: admin-ext\n</code></pre> <p>The <code>groupfile</code> will be mounted to our Chroma container and read by the multi-user basic auth plugin. The changes to the authentication plugin are as follows:</p> <pre><code># imports as before\n\n@register_provider(\"multi_user_htpasswd_file\")\nclass MultiUserHtpasswdFileServerAuthCredentialsProvider(ServerAuthCredentialsProvider):\n    _creds: Dict[str, SecretStr]  # contains user:password-hash\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        try:\n            self.bc = importlib.import_module(\"bcrypt\")\n        except ImportError:\n            raise ValueError(aa\n                \"The bcrypt python package is not installed. \"\n                \"Please install it with `pip install bcrypt`\"\n            )\n        system.settings.require(\"chroma_server_auth_credentials_file\")\n        _file = str(system.settings.chroma_server_auth_credentials_file)\n        ...  # as before\n        _basepath = path.dirname(_file)\n        self._user_group_map = dict()\n        if path.exists(path.join(_basepath, \"groupfile\")):\n            _groups = dict()\n            with open(path.join(_basepath, \"groupfile\"), \"r\") as f:\n                for line in f:\n                    _raw_group = [v for v in line.strip().split(\":\")]\n                    if len(_raw_group) &lt; 2:\n                        raise ValueError(\n                            \"Invalid Htpasswd group file found in \"\n                            f\"[{path.join(_basepath, 'groupfile')}]. \"\n                            \"Must be &lt;groupname&gt;:&lt;username1&gt;,&lt;username2&gt;,...,&lt;usernameN&gt;.\"\n                        )\n                    _groups[_raw_group[0]] = [u.strip() for u in _raw_group[1].split(\",\")]\n                    for _group, _users in _groups.items():\n                        for _user in _users:\n                            if _user not in self._user_group_map:\n                                self._user_group_map[_user] = _group\n\n    @trace_method(  # type: ignore\n        \"MultiUserHtpasswdFileServerAuthCredentialsProvider.validate_credentials\",\n        OpenTelemetryGranularity.ALL,\n    )\n    @override\n    def validate_credentials(self, credentials: AbstractCredentials[T]) -&gt; bool:\n        ...  # as before\n\n    @override\n    def get_user_identity(\n            self, credentials: AbstractCredentials[T]\n    ) -&gt; Optional[SimpleUserIdentity]:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n        if _creds[\"username\"].get_secret_value() in self._user_group_map.keys():\n            return SimpleUserIdentity(\n                _creds[\"username\"].get_secret_value(),\n                attributes={\n                    \"team\": self._user_group_map[_creds[\"username\"].get_secret_value()]\n                },\n            )\n        return SimpleUserIdentity(_creds[\"username\"].get_secret_value(), attributes={\"team\": \"public\"})\n</code></pre> <p>Full code</p> <p>The code can be found under <code>chroma_auth/authn/basic/__**init__**.py</code></p> <p>We read the group file and for each user create a key in <code>self._user_group_map</code> to specify the group or team of that user. The information is returned as user identity attributes that is further used by the authz plugin.</p> <p>Now let\u2019s turn our attention to the authorization plugin. First let\u2019s start with that we\u2019re trying to achieve with it:</p> <ul> <li>Handle OpenFGA configuration from the import of the model as per the snippet above. This will help us to wire all   necessary parts of the code with correct authorization model configuration.</li> <li>Map all existing Chroma authorization actions to our authorization model</li> <li>Adapt any shortcomings or quirks in Chroma authorization to the way OpenFGA works</li> <li>Implement the Enforcement Point (EP) logic</li> <li>Implement OpenFGA Permissions API wrapper - this is a utility class that will help us update and keep updating the   OpenFGA tuples throughout collections\u2019 lifecycle.</li> </ul> <p>We\u2019ve split the implementation in two files:</p> <ul> <li><code>chroma_auth/authz/openfga/__init__.py</code> - Storing our OpenFGA authorization configuration reader and our authorization   plugin that adapts to Chroma authz model and enforces authorization decisions</li> <li><code>chroma_auth/authz/openfga/openfga_permissions.py</code> - Holds our OpenFGA permissions update logic.</li> <li><code>chroma_auth/instr/**__init__**.py</code> - holds our adapted FastAPI server from Chroma <code>0.4.24</code>. While the authz plugin   system in Chroma makes it easy to write the enforcement of authorization decisions, the update of permissions does   require us to into this rabbit hole. Don\u2019t worry the actual changes are minimal</li> </ul> <p>Let\u2019s cover things in a little more detail.</p> <p>Reading the configuration.</p> <pre><code>@register_provider(\"openfga_config_provider\")\nclass OpenFGAAuthorizationConfigurationProvider(\n    ServerAuthorizationConfigurationProvider[ClientConfiguration]\n):\n    _config_file: str\n    _config: ClientConfiguration\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        self._settings = system.settings\n        if \"FGA_API_URL\" not in os.environ:\n            raise ValueError(\"FGA_API_URL not set\")\n        self._config = self._try_load_from_file()\n\n        # TODO in the future we can also add credentials (preshared) or OIDC\n\n    def _try_load_from_file(self) -&gt; ClientConfiguration:\n        store_id = None\n        model_id = None\n        if \"FGA_STORE_ID\" in os.environ and \"FGA_MODEL_ID\" in os.environ:\n            return ClientConfiguration(\n                api_url=os.environ.get(\"FGA_API_URL\"),\n                store_id=os.environ[\"FGA_STORE_ID\"],\n                authorization_model_id=os.environ[\"FGA_MODEL_ID\"],\n            )\n        if \"FGA_CONFIG_FILE\" not in os.environ and not store_id and not model_id:\n            raise ValueError(\"FGA_CONFIG_FILE or FGA_STORE_ID/FGA_MODEL_ID env vars not set\")\n        with open(os.environ[\"FGA_CONFIG_FILE\"], \"r\") as f:\n            config = json.load(f)\n            return ClientConfiguration(\n                api_url=os.environ.get(\"FGA_API_URL\"),\n                store_id=config[\"store\"][\"id\"],\n                authorization_model_id=config[\"model\"][\"authorization_model_id\"],\n            )\n\n    @override\n    def get_configuration(self) -&gt; ClientConfiguration:\n        return self._config\n</code></pre> <p>This is a pretty simple and straightforward implementation that will either take env variables for the FGA Server URL, Store and Model or it will only take the server ULR + json configuration (the same as above).</p> <p>Next let\u2019s have a look at our <code>OpenFGAAuthorizationProvider</code> implementation. We\u2019ll start with the constructor where we adapt existing Chroma authorization actions to our model:</p> <pre><code>def __init__(self, system: System) -&gt; None:\n    # more code here, but we're skipping for brevity\n    self._authz_to_model_action_map = {\n        AuthzResourceActions.CREATE_DATABASE.value: \"can_create_database\",\n        AuthzResourceActions.GET_DATABASE.value: \"can_get_database\",\n        AuthzResourceActions.CREATE_TENANT.value: \"can_create_tenant\",\n        AuthzResourceActions.GET_TENANT.value: \"can_get_tenant\",\n        AuthzResourceActions.LIST_COLLECTIONS.value: \"can_list_collections\",\n        AuthzResourceActions.COUNT_COLLECTIONS.value: \"can_count_collections\",\n        AuthzResourceActions.GET_COLLECTION.value: \"can_get_collection\",\n        AuthzResourceActions.CREATE_COLLECTION.value: \"can_create_collection\",\n        AuthzResourceActions.GET_OR_CREATE_COLLECTION.value: \"can_get_or_create_collection\",\n        AuthzResourceActions.DELETE_COLLECTION.value: \"can_delete_collection\",\n        AuthzResourceActions.UPDATE_COLLECTION.value: \"can_update_collection\",\n        AuthzResourceActions.ADD.value: \"can_add_records\",\n        AuthzResourceActions.DELETE.value: \"can_delete_records\",\n        AuthzResourceActions.GET.value: \"can_get_records\",\n        AuthzResourceActions.QUERY.value: \"can_query_records\",\n        AuthzResourceActions.COUNT.value: \"can_count_records\",\n        AuthzResourceActions.UPDATE.value: \"can_update_records\",\n        AuthzResourceActions.UPSERT.value: \"can_upsert_records\",\n        AuthzResourceActions.RESET.value: \"can_reset\",\n    }\n\n    self._authz_to_model_object_map = {\n        AuthzResourceTypes.DB.value: \"database\",\n        AuthzResourceTypes.TENANT.value: \"tenant\",\n        AuthzResourceTypes.COLLECTION.value: \"collection\",\n    }\n</code></pre> <p>The above is located in <code>chroma_auth/authz/openfga/__init__.py</code></p> <p>The above is fairly straightforward mapping between <code>AuthzResourceActions</code> part of Chroma\u2019s auth framework and the relations (aka actions) we\u2019ve defined in our model above. Next we map also the <code>AuthzResourceTypes</code> to OpenFGA objects. This seem pretty simple right? Wrong, things are not so perfect and nothing exhibits this more than our next portion that takes the action and resource and returns object and relation to be checked:</p> <pre><code>def resolve_resource_action(self, resource: AuthzResource, action: AuthzAction) -&gt; tuple:\n    attrs = \"\"\n    tenant = None,\n    database = None\n    if \"tenant\" in resource.attributes:\n        attrs += f\"{resource.attributes['tenant']}\"\n        tenant = resource.attributes['tenant']\n    if \"database\" in resource.attributes:\n        attrs += f\"-{resource.attributes['database']}\"\n        database = resource.attributes['database']\n    if action.id == AuthzResourceActions.GET_TENANT.value or action.id == AuthzResourceActions.CREATE_TENANT.value:\n        return \"server:localhost\", self._authz_to_model_action_map[action.id]\n    if action.id == AuthzResourceActions.GET_DATABASE.value or action.id == AuthzResourceActions.CREATE_DATABASE.value:\n        return f\"tenant:{attrs}\", self._authz_to_model_action_map[action.id]\n    if action.id == AuthzResourceActions.CREATE_COLLECTION.value:\n        try:\n            cole_exists = self._api.get_collection(\n                resource.id, tenant=tenant, database=database\n            )\n            return f\"collection:{attrs}-{cole_exists.name}\", self._authz_to_model_action_map[\n                AuthzResourceActions.GET_COLLECTION.value]\n        except Exception as e:\n            return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}\", self._authz_to_model_action_map[\n                action.id]\n    if resource.id == \"*\":\n        return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}\", self._authz_to_model_action_map[action.id]\n    else:\n        return f\"{self._authz_to_model_object_map[resource.type]}:{attrs}-{resource.id}\",\n        self._authz_to_model_action_map[action.id]\n</code></pre> <p>Full code</p> <p>The above is located in <code>chroma_auth/authz/openfga/__init__.py</code></p> <p>The <code>resolve_resource_action</code> function demonstrates the idiosyncrasies of Chroma\u2019s auth. I have only myself to blame. The key takeaway is that there is room for improvement.</p> <p>The actual authorization enforcement is then dead simple:</p> <pre><code>def authorize(self, context: AuthorizationContext) -&gt; bool:\n    with OpenFgaClient(self._authz_config_provider.get_configuration()) as fga_client:\n        try:\n            obj, act = self.resolve_resource_action(resource=context.resource, action=context.action)\n            resp = fga_client.check(body=ClientCheckRequest(\n                user=f\"user:{context.user.id}\",\n                relation=act,\n                object=obj,\n            ))\n            # openfga_sdk.models.check_response.CheckResponse\n            return resp.allowed\n        except Exception as e:\n            logger.error(f\"Error while authorizing: {str(e)}\")\n            return False\n</code></pre> <p>At the end we\u2019ll look at the our permissions API wrapper. While a full-blown solution will implement all possible object lifecycle hooks, we\u2019re content with collections. Therefore we\u2019ll add lifecycle callbacks for creating and deleting collection (we\u2019re not considering, sharing of the collection with other users and change of ownership). So how does our create collection hook might look like you ask?</p> <pre><code>def create_collection_permissions(self, collection: Collection, request: Request) -&gt; None:\n    if not hasattr(request.state, \"user_identity\"):\n        return\n    identity = request.state.user_identity  # AuthzUser\n    tenant = request.query_params.get(\"tenant\")\n    database = request.query_params.get(\"database\")\n    _object = f\"collection:{tenant}-{database}-{collection.id}\"\n    _object_for_get_collection = f\"collection:{tenant}-{database}-{collection.name}\"  # this is a bug in the Chroma Authz that feeds in the name of the collection instead of ID\n    _user = f\"team:{identity.get_user_attributes()['team']}#owner\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else f\"user:{identity.get_user_id()}\"\n    _user_writer = f\"team:{identity.get_user_attributes()['team']}#writer\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    _user_reader = f\"team:{identity.get_user_attributes()['team']}#reader\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    with OpenFgaClient(self._fga_configuration) as fga_client:\n        fga_client.write_tuples(\n            body=[\n                ClientTuple(_user, \"can_add_records\", _object),\n                ClientTuple(_user, \"can_delete_records\", _object),\n                ClientTuple(_user, \"can_update_records\", _object),\n                ClientTuple(_user, \"can_get_records\", _object),\n                ClientTuple(_user, \"can_upsert_records\", _object),\n                ClientTuple(_user, \"can_count_records\", _object),\n                ClientTuple(_user, \"can_query_records\", _object),\n                ClientTuple(_user, \"can_get_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_delete_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_update_collection\", _object),\n            ]\n        )\n        if _user_writer:\n            fga_client.write_tuples(\n                body=[\n                    ClientTuple(_user_writer, \"can_add_records\", _object),\n                    ClientTuple(_user_writer, \"can_delete_records\", _object),\n                    ClientTuple(_user_writer, \"can_update_records\", _object),\n                    ClientTuple(_user_writer, \"can_get_records\", _object),\n                    ClientTuple(_user_writer, \"can_upsert_records\", _object),\n                    ClientTuple(_user_writer, \"can_count_records\", _object),\n                    ClientTuple(_user_writer, \"can_query_records\", _object),\n                    ClientTuple(_user_writer, \"can_get_collection\", _object_for_get_collection),\n                    ClientTuple(_user_writer, \"can_delete_collection\", _object_for_get_collection),\n                    ClientTuple(_user_writer, \"can_update_collection\", _object),\n                ]\n            )\n        if _user_reader:\n            fga_client.write_tuples(\n                body=[\n                    ClientTuple(_user_reader, \"can_get_records\", _object),\n                    ClientTuple(_user_reader, \"can_query_records\", _object),\n                    ClientTuple(_user_reader, \"can_count_records\", _object),\n                    ClientTuple(_user_reader, \"can_get_collection\", _object_for_get_collection),\n                ]\n            )\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/authz/openfga/openfga_permissions.py</code></p> <p>Looks pretty straight, but hold on I hear a thought creeping in your mind. \u201cWhy are you adding roles manually?\u201d</p> <p>You are right, it lacks that DRY-je-ne-sais-quoi, and I\u2019m happy to keep it simple an explicit. A more mature implementation can read the model figure out what type we\u2019re adding permissions for and then for each relation add the requisite users, but premature optimization is difficult to put in an article that won\u2019t turn into a book.</p> <p>With the above code we make the assumption that the collection doesn\u2019t exist ergo its permissions tuples don\u2019t exist. ( OpenFGA will fail to add tuples that already exist and there is not way around it other than deleting them first). Remember permission tuple lifecycle is your responsibility when adding authz to your application.</p> <p>The delete is oddly similar (that\u2019s why we\u2019ve skipped the bulk of it):</p> <pre><code>def delete_collection_permissions(self, collection: Collection, request: Request) -&gt; None:\n    if not hasattr(request.state, \"user_identity\"):\n        return\n    identity = request.state.user_identity\n\n    _object = f\"collection:{collection.tenant}-{collection.database}-{collection.id}\"\n    _object_for_get_collection = f\"collection:{collection.tenant}-{collection.database}-{collection.name}\"  # this is a bug in the Chroma Authz that feeds in the name of the collection instead of ID\n    _user = f\"team:{identity.get_user_attributes()['team']}#owner\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else f\"user:{identity.get_user_id()}\"\n    _user_writer = f\"team:{identity.get_user_attributes()['team']}#writer\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    _user_reader = f\"team:{identity.get_user_attributes()['team']}#reader\" if identity.get_user_attributes() and \"team\" in identity.get_user_attributes() else None\n    with OpenFgaClient(self._fga_configuration) as fga_client:\n        fga_client.delete_tuples(\n            body=[\n                ClientTuple(_user, \"can_add_records\", _object),\n                ClientTuple(_user, \"can_delete_records\", _object),\n                ClientTuple(_user, \"can_update_records\", _object),\n                ClientTuple(_user, \"can_get_records\", _object),\n                ClientTuple(_user, \"can_upsert_records\", _object),\n                ClientTuple(_user, \"can_count_records\", _object),\n                ClientTuple(_user, \"can_query_records\", _object),\n                ClientTuple(_user, \"can_get_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_delete_collection\", _object_for_get_collection),\n                ClientTuple(_user, \"can_update_collection\", _object),\n            ]\n        )\n    # more code in the repo\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/authz/openfga/openfga_permissions.py</code></p> <p>Let\u2019s turn our attention at the last piece of code - the necessary evil of updating the FastAPI in Chroma to add our Permissions API hooks. We start simple by injecting our component using Chroma\u2019s DI (dependency injection).</p> <pre><code>from chroma_auth.authz.openfga.openfga_permissions import OpenFGAPermissionsAPI\n\nself._permissionsApi: OpenFGAPermissionsAPI = self._system.instance(OpenFGAPermissionsAPI)\n</code></pre> <p>The we add a hook for collection creation:</p> <pre><code>def create_collection(\n        self,\n        request: Request,\n        collection: CreateCollection,\n        tenant: str = DEFAULT_TENANT,\n        database: str = DEFAULT_DATABASE,\n) -&gt; Collection:\n    existing = None\n    try:\n        existing = self._api.get_collection(collection.name, tenant=tenant, database=database)\n    except ValueError as e:\n        if \"does not exist\" not in str(e):\n            raise e\n    collection = self._api.create_collection(\n        name=collection.name,\n        metadata=collection.metadata,\n        get_or_create=collection.get_or_create,\n        tenant=tenant,\n        database=database,\n    )\n    if not existing:\n        self._permissionsApi.create_collection_permissions(collection=collection, request=request)\n    return collection\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/instr/__init__.py</code></p> <p>And one for collection removal:</p> <pre><code>def delete_collection(\n        self,\n        request: Request,\n        collection_name: str,\n        tenant: str = DEFAULT_TENANT,\n        database: str = DEFAULT_DATABASE,\n) -&gt; None:\n    collection = self._api.get_collection(collection_name, tenant=tenant, database=database)\n    resp = self._api.delete_collection(\n        collection_name, tenant=tenant, database=database\n    )\n\n    self._permissionsApi.delete_collection_permissions(collection=collection, request=request)\n    return resp\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>chroma_auth/instr/__init__.py</code></p> <p>The key thing to observe about the above snippets is that we invoke permissions API when we\u2019re sure things have been persisted in the DB. I know, I know, atomicity here is also important, but that is for another article. Just keep in mind that it is easier to fix broken permission than broken data.</p> <p>I promise this was the last bit of python code you\u2019ll see in this article.</p>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#the-infra","title":"The Infra","text":"<p>Infrastructure!!! Finally, a sigh of relieve.</p> <p>Let\u2019s draw a diagrams:</p> <p></p> <p>Link</p> <p>We have our Chroma server, that relies on OpenFGA which persists data in PostgreSQL. \u201cOk, but \u2026\u201d, I can see you scratch your head, \u201c\u2026 how do I bring this magnificent architecture to live?\u201d. I thought you\u2019d never ask. We\u2019ll rely on our trusty docker compose skills with the following sequence in mind:</p> <p></p> <p>\u201cWhere is the <code>docker-compose.yaml</code>!\u201d. Voil\u00e0, my impatient friends:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    depends_on:\n      openfga:\n        condition: service_healthy\n      import:\n        condition: service_completed_successfully\n    image: chroma-server\n    build:\n      dockerfile: Dockerfile\n    volumes:\n      - ./chroma-data:/chroma/chroma\n      - ./server.htpasswd:/chroma/server.htpasswd\n      - ./groupfile:/chroma/groupfile\n      - ./data/:/data\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n      - CHROMA_SERVER_AUTHZ_PROVIDER=${CHROMA_SERVER_AUTHZ_PROVIDER}\n      - CHROMA_SERVER_AUTHZ_CONFIG_PROVIDER=${CHROMA_SERVER_AUTHZ_CONFIG_PROVIDER}\n      - FGA_API_URL=http://openfga:8080\n      - FGA_CONFIG_FILE=/data/store.json # we expect that the import job will create this file\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n  postgres:\n    image: postgres:14\n    container_name: postgres\n    networks:\n      - net\n    ports:\n      - \"5432:5432\"\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=password\n    healthcheck:\n      test: [ \"CMD-SHELL\", \"pg_isready -U postgres\" ]\n      interval: 5s\n      timeout: 5s\n      retries: 5\n    volumes:\n      - postgres_data_openfga:/var/lib/postgresql/data\n\n  migrate:\n    depends_on:\n      postgres:\n        condition: service_healthy\n    image: openfga/openfga:latest\n    container_name: migrate\n    command: migrate\n    environment:\n      - OPENFGA_DATASTORE_ENGINE=postgres\n      - OPENFGA_DATASTORE_URI=postgres://postgres:password@postgres:5432/postgres?sslmode=disable\n    networks:\n      - net\n  openfga:\n    depends_on:\n      migrate:\n        condition: service_completed_successfully\n    image: openfga/openfga:latest\n    container_name: openfga\n    environment:\n      - OPENFGA_DATASTORE_ENGINE=postgres\n      - OPENFGA_DATASTORE_URI=postgres://postgres:password@postgres:5432/postgres?sslmode=disable\n      - OPENFGA_LOG_FORMAT=json\n    command: run\n    networks:\n      - net\n    ports:\n      # Needed for the http server\n      - \"8082:8080\"\n      # Needed for the grpc server (if used)\n      - \"8083:8081\"\n      # Needed for the playground (Do not enable in prod!)\n      - \"3003:3000\"\n    healthcheck:\n      test: [ \"CMD\", \"/usr/local/bin/grpc_health_probe\", \"-addr=openfga:8081\" ]\n      interval: 5s\n      timeout: 30s\n      retries: 3\n  import:\n    depends_on:\n      openfga:\n        condition: service_healthy\n    image: fga-cli\n    build:\n      context: .\n      dockerfile: Dockerfile-fgacli\n    container_name: import\n    volumes:\n      - ./data/:/data\n    command: |\n      /bin/sh -c \"/data/create_store_and_import.sh\"\n    environment:\n      - FGA_SERVER_URL=http://openfga:8080\n    networks:\n      - net\nvolumes:\n  postgres_data_openfga:\n    driver: local\n</code></pre> <p>Don\u2019t forget to create an <code>.env</code> file:</p> <pre><code>CHROMA_SERVER_AUTH_PROVIDER = \"chromadb.auth.basic.BasicAuthServerProvider\"\nCHROMA_SERVER_AUTH_CREDENTIALS_FILE = \"server.htpasswd\"\nCHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER = \"chroma_auth.authn.basic.MultiUserHtpasswdFileServerAuthCredentialsProvider\"\nCHROMA_SERVER_AUTHZ_PROVIDER = \"chroma_auth.authz.openfga.OpenFGAAuthorizationProvider\"\nCHROMA_SERVER_AUTHZ_CONFIG_PROVIDER = \"chroma_auth.authz.openfga.OpenFGAAuthorizationConfigurationProvider\"\n</code></pre> <p>Update your <code>server.htpasswd</code> to include the new user:</p> <pre><code>admin:$2\ny$05$vkBK4b1Vk5O98jNHgr.uduTJsTOfM395sKEKe48EkJCVPH / MBIeHK\nuser1:$2\ny$05$UQ0kC2x3T2XgeN4WU12BdekUwCJmLjJNhMaMtFNolYdj83OqiEpVu\nadmin - ext:$2\ny$05$9.\nL13wKQTHeXz9IH2UO2RurWEK. / Z24qapzyi6ywQGJds2DaC36C2\n</code></pre> <p>And the <code>groupfile</code> from before. And don\u2019t forget to take a look at the import script under - <code>data/create_store_and_import.sh</code></p> <p>Run the following command at the root of the repo and let things fail and burn down (or in the event this works - awe you, disclaimer - it worked on my machine):</p> <pre><code>docker\ncompose\nup - -build\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-impl-with-openfga/#tests-who-needs-test-when-you-have-stable-infra","title":"Tests, who needs test when you have stable infra!","text":"<p>Authorization is serious stuff, which is why we\u2019ve created a bare minimum set of tests to prove we\u2019re not totally wrong about it!</p> <p>Real Serious Note</p> <p>Serious Note: Take these things seriously and write a copious amounts of tests before rolling out things to prod. Don\u2019t become OWASP Top10 \u201cHero\u201d. Broken access controls is a thing that WILL keep you up at night.</p> <p>We\u2019ll focus on three areas:</p> <ul> <li>Testing admin (owner) access</li> <li>Testing team access for owner and reader roles</li> <li>Testing cross team permissions</li> </ul> <p>Admin Access</p> <p>Simple check to ensure that whoever created the collection (aka the owner) is allowed all actions.</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\n\ncol = client.get_or_create_collection(f\"test_collection-{str(uuid.uuid4())}\")\ncol.add(ids=[\"1\"], documents=[\"test doc\"])\n\ncol.get()\ncol.update(ids=[\"1\"], documents=[\"test doc 2\"])\ncol.count()\ncol.upsert(ids=[\"1\"], documents=[\"test doc 3\"])\ncol.delete(ids=[\"1\"])\n\nclient.delete_collection(col.name)\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p> <p>Team Access</p> <p>Team access tests whether roles and permissions associated with those roles are correctly enforced.</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\n\ncol_name = f\"test_collection-{str(uuid.uuid4())}\"\ncol = client.get_or_create_collection(col_name)\nprint(f\"Creating collection {col.id}\")\ncol.add(ids=[\"1\"], documents=[\"test doc\"])\n\nclient.get_collection(col_name)\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"user1:password123\"))\n\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.list_collections()  # this is a protected endpoint and requires authentication\nclient.count_collections()\nprint(\"Getting collection \" + col_name)\ncol = client.get_collection(col_name)\ncol.get()\ncol.count()\n\ntry:\n    client.delete_collection(col_name)\nexcept Exception as e:\n    print(e)  #expect unauthorized error\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\n\nclient.delete_collection(col_name)\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p> <p>Cross-team access</p> <p>In the cross team access scenario we\u2019ll create a collection with one team owner (<code>admin</code>) and will try to access it (aka delete it) with another team\u2019s owner in a very mano-a-mano (owner-to-owner way). It is important to observe that all these collections are created within the same database (<code>default_database</code>)</p> <pre><code>import uuid\nimport chromadb\nfrom chromadb.config import Settings\n\ncol_name = f\"test_collection-{str(uuid.uuid4())}\"\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\n\nclient.get_or_create_collection(col_name)\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin-ext:password123\"))\n\nclient.get_or_create_collection(\"external-collection\")\n\ntry:\n    client.delete_collection(col_name)\nexcept Exception as e:\n    print(\"Expected error for admin-ext: \", str(e))  #expect unauthorized error\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",\n                      chroma_client_auth_credentials=\"admin:password123\"))\nclient.delete_collection(col_name)\ntry:\n    client.delete_collection(\"external-collection\")\nexcept Exception as e:\n    print(\"Expected error for admin: \", str(e))  #expect unauthorized error\n</code></pre> <p>Full code</p> <p>You can find the full code in <code>test_auth.ipynb</code></p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/","title":"Chroma Authorization Model with OpenFGA","text":"<p>Source Code</p> <p>The source code for this article can be found here.</p> <p>This article will not provide any code that you can use immediately but will set the stage for our next article, which will introduce the actual Chroma-OpenFGA integration.</p> <p>With that in mind, let\u2019s get started.</p> <p>Who is this article for? The intended audience is DevSecOps, but engineers and architects could also use this to learn about Chroma and the authorization models.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#authorization-model","title":"Authorization Model","text":"<p>Authorization models are an excellent way to abstract the way you wish your users to access your application form the actual implementation.</p> <p>There are many ways to do authz, ranging from commercial Auth0 FGA to OSS options like Ory Keto/Kratos, CASBIN, Permify, and Kubescape, but for this article, we\u2019ve decided to use OpenFGA (which technically is Auth0\u2019s open-source framework for FGA).</p> <p>Why OpenFGA, I hear you ask? Here are a few reasons:</p> <ul> <li>Apache-2 licensed</li> <li>CNCF Incubating project</li> <li>Zanzibar alignment in that it is a ReBAC (Relation-based access control) system</li> <li>DSL for modeling and testing permissions (as well as JSON-base version for those with masochistic tendencies)</li> </ul> <p>OpenFGA has done a great job explaining the steps to building an Authorization model, which you can read here. We will go over those while keeping our goal of creating an authorization model for Chroma.</p> <p>It is worth noting that the resulting authorization model that we will create here will be suitable for many GenAI applications, such as general-purpose RAG systems. Still, it is not a one-size-fits-all solution to all problems. For instance, if you want to implement authz in Chroma within your organization, OpenFGA might not be the right tool for the job, and you should consult with your IT/Security department for guidance on integrating with existing systems.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#the-goal","title":"The Goal","text":"<p>Our goal is to achieve the following:</p> <ul> <li>Allow fine-grained access to the following resources - collection, database, tenant, and Chroma server.</li> <li>AlGrouping of users for improved permission management.</li> <li>Individual user access to resources</li> <li>Roles - owner, writer, reader</li> </ul> <p>Document-Level Access</p> <p>Although granting access to individual documents in a collection can be beneficial in some contexts, we have left that part out of our goals to keep things as simple and short as possible. If you are interested in this topic, reach out, and we will help you.</p> <p>This article will not cover user management, commonly called Identity Access Management (IAM). We\u2019ll cover that in a subsequent article.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#modeling-fundamentals","title":"Modeling Fundamentals","text":"<p>Let\u2019s start with the fundamentals:</p> <p><code>Why could user U perform an action A on an object O?</code></p> <p>We will attempt to answer the question in the context of Chroma by following OpenFGA approach to refining the model. The steps are:</p> <ol> <li>Pick the most important features.</li> <li>List of object types</li> <li>List of relations for the types</li> <li>Test the model</li> <li>Iterate</li> </ol> <p>Given that OpenFGA is Zanzibar inspired, the basic primitive for it is a tuple of the following format:</p> <pre><code>(User,Relation,Object)\n</code></pre> <p>With the above we can express any relation between a user (or a team or even another object) the action the user performs (captured by object relations) and the object (aka API resource).</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#pick-the-features","title":"Pick the features","text":"<p>In the context of Chroma, the features are the actions the user can perform on Chroma API (as of this writing v0.4.24).</p> <p>Let\u2019s explore what are the actions that users can perform:</p> <ul> <li>Create a tenant</li> <li>Get a tenant</li> <li>Create a database for a tenant</li> <li>Get a database for a tenant</li> <li>Create a collection in a database</li> <li>Delete a collection from a database</li> <li>Update collection name and metadata</li> <li>List collections in a database</li> <li>Count collections in a database</li> <li>Add records to a collection</li> <li>Delete records from a collection</li> <li>Update records in a collection</li> <li>Upsert records in a collection</li> <li>Count records in a collection</li> <li>Get records from a collection</li> <li>Query records in a collection</li> <li>Get pre-flight-checks</li> </ul> <p>Open Endpoints</p> <p>Note we will omit get <code>hearbeat</code> and get <code>version</code>actions as this is generally a good idea to be open so that orchestrators (docker/k8s) can get the health status of chroma.</p> <p>To make it easy to reason about relations in our authorization model we will rephrase the above to the following format:</p> <pre><code>A user {user} can perform action {action} to/on/in {object types} ... IF {conditions}\n</code></pre> <ul> <li>A user can perform action create tenant on Chroma server if they are owner of the server</li> <li>A user can perform action get tenant on Chroma server if they are a reader or writer or owner of the server</li> <li>A user can perform action create database on a tenant if they are an owner of the tenant</li> <li>A user can perform action get database on a tenant if they are reader, writer or owner of the tenant</li> <li>A user can perform action create collection on a database if they are a writer or an owner of the database</li> <li>A user can perform action delete collection on a database if they are a writer or an owner of the database</li> <li>A user can perform action update collection name or metadata on a database if they are a writer or an owner of the   database</li> <li>A user can perform action list collections in a database if they are a writer or an owner of the database</li> <li>A user can perform action count collections in a database if they are a writer or an owner of the database</li> <li>A user can perform action add records on a collection if they are writer or owner of the collection</li> <li>A user can perform action delete records on a collection if they are writer or owner of the collection</li> <li>A user can perform action update records on a collection if they are writer or owner of the collection</li> <li>A user can perform action upsert records on a collection if they are writer or owner of the collection</li> <li>A user can perform action get records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action count records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action query records on a collection if they are writer or owner or reader of the collection</li> <li>A user can perform action get pre-flight-checks on a Chroma server if they are writer or owner or reader of the server</li> </ul> <p>We don\u2019t have to get it all right in the first iteration, but the above is a good starting point that can be adapted further.</p> <p>The above statements alone are already a great introspection as to what we can do within Chroma and who is supposed to be able to do what. Please note that your mileage may vary, as per your authz requirements, but in our experience the variations are generally around the who.</p> <p>As an astute reader you have already noted that we\u2019re generally outlined some RBAC stuff in the form of owner, writer and reader.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#list-the-objects","title":"List the objects!!!","text":"<p>Now that we know what our users can do, let\u2019s figure solidify our understanding of on what our users will be performing these actions, aka the object types.</p> <p>Let\u2019s call them out:</p> <ul> <li>User - this is basic and pretty obvious object type that we want to model our users after</li> <li>Chroma server - this is our top level object in the access relations</li> <li>Tenant - for most Chroma developers this will equate to a team or a group</li> <li>Database</li> <li>Collection</li> </ul> <p>We can also examine all of the <code>of the &lt;object&gt;</code> in the above statements to ensure we haven\u2019t missed any objects. So far seems we\u2019re all good.</p> <p>Now that we have our objects let\u2019s create a first iteration of our authorization model using OpenFGA DSL:</p> <pre><code>model\n  schema 1.1\n\ntype server\ntype user\ntype tenant\ntype database\ntype collection\n</code></pre> <p>OpenFGA CLI</p> <p>You will need to install openfga CLI - https://openfga.dev/docs/getting-started/install-sdk. Also check the VSCode extension for OpenFGA.</p> <p>Let\u2019s validate our work:</p> <pre><code>fga model validate --file model-article-p1.fga\n</code></pre> <p>You should see the following output:</p> <pre><code>{\n  \"is_valid\":true\n}\n</code></pre>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#relations","title":"Relations","text":"<p>Now that we have the actions and the objects, let us figure out the relationships we want to build into our model.</p> <p>To come up with our relations we can follow these two rules:</p> <ul> <li>Any noun of the type <code>{noun} of a/an/the {type}</code> expression (e.g. <code>of the collection</code>)</li> <li>Any verb or action described with <code>can {action} on/in {type}</code></li> </ul> <p>So now let\u2019s work on our model to expand it with relationships:</p> <pre><code>model\n  schema 1.1\n\ntype user\n\ntype server\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define can_get_preflight: reader or owner or writer\n    define can_create_tenant: owner or writer\n\ntype tenant\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [server]\n    define can_create_database: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_get_database: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n\ntype database\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [tenant]\n    define can_create_collection: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_delete_collection: owner from belongsTo or writer from belongsTo or owner or writer\n    define can_list_collections: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_get_collection: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_get_or_create_collection: owner or writer or owner from belongsTo or writer from belongsTo\n    define can_count_collections: owner or writer or owner from belongsTo or writer from belongsTo\n\ntype collection\n  relations\n    define owner: [user]\n    define reader: [user]\n    define writer: [user]\n    define belongsTo: [database]\n    define can_add_records: writer or reader or owner from belongsTo or writer from belongsTo\n    define can_delete_records: writer or owner from belongsTo or writer from belongsTo\n    define can_update_records: writer or owner from belongsTo or writer from belongsTo\n    define can_get_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n    define can_upsert_records: writer or owner from belongsTo or writer from belongsTo\n    define can_count_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n    define can_query_records: reader or owner or writer or owner from belongsTo or reader from belongsTo or writer from belongsTo\n</code></pre> <p>Let\u2019s validated:</p> <pre><code>fga model validate --file model-article-p2.fga\n</code></pre> <p>This seems mostly accurate and should do ok as Authorization model. But let us see if we can make it better. If we are to implement the above we will end up with lots of permissions in OpenFGA, not that it can\u2019t handle them, but as we go into the implementation details it will become cumbersome to update and maintain all these permissions. So let\u2019s look for opportunity to simplify things a little.</p> <p>Can we make the model a little simpler and the first question we ask is do we really need owner, reader, writer on every object or can we make a decision about our model and simplify this. As it turns out we can. The way that most multi-user systems work is that they tend to gravitate to grouping things as a way to reduce the need to maintain a large number of permissions. In our case we can group our users into <code>team</code> and in each team we\u2019ll have owner, writer, reader</p> <p>Let\u2019s see the results:</p> <pre><code>model\n  schema 1.1\n\ntype user\n\ntype team\n  relations\n    define owner: [user]\n    define writer: [user]\n    define reader: [user]\n\ntype server\n  relations\n    define can_get_preflight: [user, team#owner, team#writer, team#reader]\n    define can_create_tenant: [user, team#owner, team#writer]\n    define can_get_tenant: [user, team#owner, team#writer, team#reader]\n\ntype tenant\n  relations\n    define can_create_database: [user, team#owner, team#writer]\n    define can_get_database: [user, team#owner, team#writer, team#reader]\n\ntype database\n  relations\n    define can_create_collection: [user, team#owner, team#writer]\n    define can_list_collections: [user, team#owner, team#writer, team#reader]\n    define can_get_or_create_collection: [user, team#owner, team#writer]\n    define can_count_collections: [user, team#owner, team#writer, team#reader]\n\ntype collection\n  relations\n    define can_delete_collection: [user, team#owner, team#writer]\n    define can_get_collection: [user, team#owner, team#writer, team#reader]\n    define can_update_collection: [user, team#owner, team#writer]\n    define can_add_records: [user, team#owner, team#writer]\n    define can_delete_records: [user, team#owner, team#writer]\n    define can_update_records: [user, team#owner, team#writer]\n    define can_get_records: [user, team#owner, team#writer, team#reader]\n    define can_upsert_records: [user, team#owner, team#writer]\n    define can_count_records: [user, team#owner, team#writer, team#reader]\n    define can_query_records: [user, team#owner, team#writer, team#reader]\n</code></pre> <p>That is arguably more readable.</p> <p>As you will observe we have also added <code>[user]</code> in the permissions of each object, why is that you may ask. The reason is that we want to build a fine-grained authorization, which means while a collection can be belong to a team, we can also grant individual permissions to users. This gives us a great way to play around with permissions at the cost of a more complex implementation of how permissions are managed, but we will get to that in the next post.</p> <p>We have also removed the <code>belongsTo</code> relationship as we no longer need it. Reason: OpenFGA does not allow access of relations more than a single layer into the hierarchy thus a collection cannot use the owner of its team for permissions (there are other ways to implement that outside of the scope of this article).</p> <p>Let\u2019s recap what is our model capable of doing:</p> <ul> <li>Fine-grained access control to objects is possible via relations</li> <li>Users can be grouped into teams (a single user per team is also acceptable for cases where you need a user to be the   sole owner of a collection or a database)</li> <li>Access to resources can be granted to individual users via object relations</li> <li>Define roles within a team (this can be extended to allow roles per resource, but is outside of the scope of this   article)</li> </ul> <p>In short we have achieved the goals we have initially set, with a relatively simple and understandable model. However, does our model work? Let\u2019s find out in the next section.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#testing-the-model","title":"Testing the model","text":"<p>Luckily OpenFGA folks have provided a great developer experience by making it easy to write and run tests. This is a massive W and time-saver.</p> <ul> <li>An individual user can be given access to specific resources via relations</li> <li>Users can be part of any of the team roles</li> <li>An object can access by a team</li> </ul> <pre><code>name: Chroma Authorization Model Tests # optional\n\nmodel_file: ./model-article-p4.fga # you can specify an external .fga file, or include it inline\n\n# tuple_file: ./tuples.yaml # you can specify an external file, or include it inline\ntuples:\n  - user: user:jane\n    relation: owner\n    object: team:chroma\n  - user: user:john\n    relation: writer\n    object: team:chroma\n  - user: user:jill\n    relation: reader\n    object: team:chroma\n  - user: user:sam\n    relation: can_create_tenant\n    object: server:server1\n  - user: user:sam\n    relation: can_get_tenant\n    object: server:server1\n  - user: user:sam\n    relation: can_get_preflight\n    object: server:server1\n  - user: user:michelle\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#owner\n    relation: can_get_tenant\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_create_tenant\n    object: server:server1\n  - user: team:chroma#writer\n    relation: can_get_tenant\n    object: server:server1\n  - user: team:chroma#reader\n    relation: can_get_preflight\n    object: server:server1\n  - user: team:chroma#reader\n    relation: can_get_tenant\n    object: server:server1\n\ntests:\n  - name: Users should have team roles\n    check:\n      - user: user:jane\n        object: team:chroma\n        assertions:\n          owner: true\n          writer: false\n          reader: false\n      - user: user:john\n        object: team:chroma\n        assertions:\n          writer: true\n          owner: false\n          reader: false\n      - user: user:jill\n        object: team:chroma\n        assertions:\n          writer: false\n          owner: false\n          reader: true\n      - user: user:unknown\n        object: team:chroma\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n      - user: user:jane\n        object: team:unknown\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n      - user: user:unknown\n        object: team:unknown\n        assertions:\n          writer: false\n          owner: false\n          reader: false\n  - name: Users should have direct access to server\n    check:\n      - user: user:sam\n        object: server:server1\n        assertions:\n          can_get_preflight: true\n          can_create_tenant: true\n          can_get_tenant: true\n      - user: user:michelle\n        object: server:server1\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: true\n          can_get_tenant: false\n      - user: user:unknown\n        object: server:server1\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: false\n          can_get_tenant: false\n      - user: user:jill\n        object: server:serverX\n        assertions:\n          can_get_preflight: false\n          can_create_tenant: false\n          can_get_tenant: false\n  - name: Users of a team should have access to server\n    check:\n      - user: user:jane\n        object: server:server1\n        assertions:\n          can_create_tenant: true\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:john\n        object: server:server1\n        assertions:\n          can_create_tenant: true\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:jill\n        object: server:server1\n        assertions:\n          can_create_tenant: false\n          can_get_tenant: true\n          can_get_preflight: true\n      - user: user:unknown\n        object: server:server1\n        assertions:\n          can_create_tenant: false\n          can_get_tenant: false\n          can_get_preflight: false\n</code></pre> <p>Let\u2019s run the tests:</p> <pre><code>fga model test --tests test.model-article-p4.fga.yaml\n</code></pre> <p>This will result in the following output:</p> <pre><code># Test Summary #\nTests 3/3 passing\nChecks 42/42 passing\n</code></pre> <p>That is all folks. We try to keep things as concise as possible and this article has already our levels of comfort in that area. The bottom line is that authorization is no joke and it should take as long of a time as needed.</p> <p>Writing out all tests will not be concise (maybe we\u2019ll add that to the repo).</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#conclusion","title":"Conclusion","text":"<p>In this article we\u2019ve have built an authorization model for Chroma from scratch using OpenFGA. Admittedly it is a simple model, it still gives is a lot of flexibility to control access to Chroma resources.</p>"},{"location":"strategies/multi-tenancy/authorization-model-with-openfga/#resources","title":"Resources","text":"<ul> <li>https://github.com/amikos-tech/chromadb-auth - the companion repo for this article (files are stored   under <code>openfga/basic/</code>)</li> <li>https://openfga.dev/docs - Read it, understand it, code it!</li> <li>https://marketplace.visualstudio.com/items?itemName=openfga.openfga-vscode - It makes your life easier</li> </ul>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/","title":"Multi-User Basic Auth","text":""},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#why-multi-user-auth","title":"Why Multi-user Auth?","text":"<p>Multi-user authentication can be crucial for several reasons. Let's delve into this topic.</p> <p>Security\u2014The primary concern is the security of your deployments. You need to control who can access your data and ensure they are authorized to do so. You may wonder, since Chroma offers basic and token-based authentication, why is multi-user authentication necessary?</p> <p>You should never share your Chroma access credentials with your users or any app that depends on Chroma. The answer to this concern is a categorical NO.</p> <p>Another reason to consider multi-user authentication is to differentiate access to your data. However, the solution presented here doesn't provide this. It's a stepping stone towards our upcoming article on multi-tenancy and securing Chroma data.</p> <p>Last but not least is auditing. While we acknowledge this is not for everybody, there is ~~an~~ increasing pressure to provide visibility into your app via auditable events.</p> <p>Multi-user experiences - Not all GenAI apps are intended to be private or individual. This is another reason to consider and implement multi-user authentication and authorization.</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#dive-right-in","title":"Dive right in.","text":"<p>Let's get straight to the point and build a multi-user authorization with basic authentication. Here's our goal:</p> <ul> <li>Develop a server-side authorization provider that can read multiple users from a <code>.htpasswd</code> file</li> <li>Generate a multi-user <code>.htpasswd</code> file with several test users</li> <li>Package our plugin with the Chroma base image and execute it using Docker Compose</li> </ul> <p>Auth CIP</p> <p>Chroma has detailed info about how its authentication and authorization are implemented. Should you want to learn more go read the CIP (Chroma Improvement Proposal doc).</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#the-plugin","title":"The Plugin","text":"<pre><code>import importlib\nimport logging\nfrom typing import Dict, cast, TypeVar, Optional\n\nfrom chromadb.auth import (\n    ServerAuthCredentialsProvider,\n    AbstractCredentials,\n    SimpleUserIdentity,\n)\nfrom chromadb.auth.registry import register_provider\nfrom chromadb.config import System\nfrom chromadb.telemetry.opentelemetry import (\n    OpenTelemetryGranularity,\n    trace_method,\n    add_attributes_to_current_span,\n)\nfrom pydantic import SecretStr\nfrom overrides import override\n\nT = TypeVar(\"T\")\n\nlogger = logging.getLogger(__name__)\n\n\n@register_provider(\"multi_user_htpasswd_file\")\nclass MultiUserHtpasswdFileServerAuthCredentialsProvider(ServerAuthCredentialsProvider):\n    _creds: Dict[str, SecretStr]  # contains user:password-hash\n\n    def __init__(self, system: System) -&gt; None:\n        super().__init__(system)\n        try:\n            self.bc = importlib.import_module(\"bcrypt\")\n        except ImportError:\n            raise ValueError(\n                \"The bcrypt python package is not installed. \"\n                \"Please install it with `pip install bcrypt`\"\n            )\n        system.settings.require(\"chroma_server_auth_credentials_file\")\n        _file = str(system.settings.chroma_server_auth_credentials_file)\n        self._creds = dict()\n        with open(_file, \"r\") as f:\n            for line in f:\n                _raw_creds = [v for v in line.strip().split(\":\")]\n                if len(_raw_creds) != 2:\n                    raise ValueError(\n                        \"Invalid Htpasswd credentials found in \"\n                        f\"[{str(system.settings.chroma_server_auth_credentials_file)}]. \"\n                        \"Must be &lt;username&gt;:&lt;bcrypt passwd&gt;.\"\n                    )\n                self._creds[_raw_creds[0]] = SecretStr(_raw_creds[1])\n\n    @trace_method(  # type: ignore\n        \"MultiUserHtpasswdFileServerAuthCredentialsProvider.validate_credentials\",\n        OpenTelemetryGranularity.ALL,\n    )\n    @override\n    def validate_credentials(self, credentials: AbstractCredentials[T]) -&gt; bool:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n\n        if len(_creds) != 2 or \"username\" not in _creds or \"password\" not in _creds:\n            logger.error(\n                \"Returned credentials did match expected format: \"\n                \"dict[username:SecretStr, password: SecretStr]\"\n            )\n            add_attributes_to_current_span(\n                {\n                    \"auth_succeeded\": False,\n                    \"auth_error\": \"Returned credentials did match expected format: \"\n                                  \"dict[username:SecretStr, password: SecretStr]\",\n                }\n            )\n            return False  # early exit on wrong format\n        _user_pwd_hash = (\n            self._creds[_creds[\"username\"].get_secret_value()]\n            if _creds[\"username\"].get_secret_value() in self._creds\n            else None\n        )\n        validation_response = _user_pwd_hash is not None and self.bc.checkpw(\n            _creds[\"password\"].get_secret_value().encode(\"utf-8\"),\n            _user_pwd_hash.get_secret_value().encode(\"utf-8\"),\n        )\n        add_attributes_to_current_span(\n            {\n                \"auth_succeeded\": validation_response,\n                \"auth_error\": f\"Failed to validate credentials for user {_creds['username'].get_secret_value()}\"\n                if not validation_response\n                else \"\",\n            }\n        )\n        return validation_response\n\n    @override\n    def get_user_identity(\n            self, credentials: AbstractCredentials[T]\n    ) -&gt; Optional[SimpleUserIdentity]:\n        _creds = cast(Dict[str, SecretStr], credentials.get_credentials())\n        return SimpleUserIdentity(_creds[\"username\"].get_secret_value())\n</code></pre> <p>In less than 80 lines of code, we have our plugin. Let's delve into and explain some of the key points of the code above:</p> <ul> <li><code>__init__</code> - Here, we dynamically import bcrypt, which we'll use to check user credentials. We also read the   configured credentials file - <code>server.htpasswd</code> line by line, to retrieve each user (we assume each line contains a   new user with its bcrypt hash).</li> <li><code>validate_credentials</code> - This is where the magic happens. We initially perform some lightweight validations on the   credentials parsed by Chroma and passed to the plugin. Then, we attempt to retrieve the user and its hash from   the <code>_creds</code> dictionary. The final step is to verify the hash. We've also added some attributes to monitor our   authentication process in our observability layer (we have an upcoming article about this).</li> <li><code>get_user_identity</code> - Constructs a simple user identity, which the authorization plugin uses to verify permissions.   Although not needed for now, each authentication plugin must implement this, as user identities are crucial for   authorization.</li> </ul> <p>We'll store our plugin in <code>__init__.py</code> within the following directory structure - <code>chroma_auth/authn/basic/__init__.py</code> (refer to the repository for details).</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#password-file","title":"Password file","text":"<p>Now that we have our plugin let\u2019s create a password file with a few users:</p> <p>Initial user:</p> <pre><code>echo \"password123\" | htpasswd -iBc server.htpasswd admin\n</code></pre> <p>The above will create (<code>-c</code> flag) a new server.htpasswd file with initial user <code>admin</code> and the password will be read from stdin (<code>-i</code> flag) and saved as bcrypt hash (<code>-B</code> flag)</p> <p>Let\u2019s add another user:</p> <pre><code>echo \"password123\" | htpasswd -iB server.htpasswd user1\n</code></pre> <p>Now our <code>server.htpasswd</code> file will look like this:</p> <pre><code>admin:$2y$05$vkBK4b1Vk5O98jNHgr.uduTJsTOfM395sKEKe48EkJCVPH/MBIeHK\nuser1:$2y$05$UQ0kC2x3T2XgeN4WU12BdekUwCJmLjJNhMaMtFNolYdj83OqiEpVu\n</code></pre> <p>Moving on to docker setup.</p>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#docker-compose-setup","title":"Docker compose setup","text":"<p>Let\u2019s create a <code>Dockerfile</code> to bundle our plugin with the official Chroma image:</p> <pre><code>ARG CHROMA_VERSION=0.4.24\nFROM ghcr.io/chroma-core/chroma:${CHROMA_VERSION} as base\n\nCOPY chroma_auth/ /chroma/chroma_auth\n</code></pre> <p>This will pick up the official docker image for Chroma and will add our plugin directory structure so that we can use it.</p> <p>Now let\u2019s create an <code>.env</code> file to load our plugin:</p> <pre><code>CHROMA_SERVER_AUTH_PROVIDER=\"chromadb.auth.basic.BasicAuthServerProvider\"\nCHROMA_SERVER_AUTH_CREDENTIALS_FILE=\"server.htpasswd\"\nCHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=\"chroma_auth.authn.basic.MultiUserHtpasswdFileServerAuthCredentialsProvider\"\n</code></pre> <p>And finally our <code>docker-compose.yaml</code>:</p> <pre><code>version: '3.9'\n\nnetworks:\n  net:\n    driver: bridge\n\nservices:\n  server:\n    image: chroma-server\n    build:\n      dockerfile: Dockerfile\n    volumes:\n      - ./chroma-data:/chroma/chroma\n      - ./server.htpasswd:/chroma/server.htpasswd\n    command: \"--workers 1 --host 0.0.0.0 --port 8000 --proxy-headers --log-config chromadb/log_config.yml --timeout-keep-alive 30\"\n    environment:\n      - IS_PERSISTENT=TRUE\n      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}\n      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}\n      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}\n      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=${CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER}\n      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}\n      - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}\n      - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}\n      - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}\n      - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}\n      - CHROMA_SERVER_NOFILE=${CHROMA_SERVER_NOFILE}\n    restart: unless-stopped # possible values are: \"no\", always\", \"on-failure\", \"unless-stopped\"\n    ports:\n      - \"8000:8000\"\n    healthcheck:\n      # Adjust below to match your container port\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/heartbeat\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - net\n</code></pre>"},{"location":"strategies/multi-tenancy/multi-user-basic-auth/#the-test","title":"The test","text":"<p>Let\u2019s run our docker compose setup:</p> <pre><code>docker compose --env-file ./.env up --build\n</code></pre> <p>You should see the following log message if the plugin was successfully loaded:</p> <pre><code>server-1  | DEBUG:    [01-04-2024 14:10:13] Starting component MultiUserHtpasswdFileServerAuthCredentialsProvider\nserver-1  | DEBUG:    [01-04-2024 14:10:13] Starting component BasicAuthServerProvider\nserver-1  | DEBUG:    [01-04-2024 14:10:13] Starting component FastAPIChromaAuthMiddleware\n</code></pre> <p>Once our container is up and running, let\u2019s see if our multi-user auth works:</p> <pre><code>import chromadb\nfrom chromadb.config import Settings\n\nclient = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"admin:password123\"))\nclient.heartbeat()  # this should work with or without authentication - it is a public endpoint\nclient.get_or_create_collection(\"test_collection\")  # this is a protected endpoint and requires authentication\nclient.list_collections()  # this is a protected endpoint and requires authentication\n</code></pre> <p>The above code should return the list of collections, a single collection <code>test_collection</code> that we created.</p> <pre><code>(chromadb-multi-user-basic-auth-py3.11) [chromadb-multi-user-basic-auth]python                                                                                                                                                                                                            19:51:38  \u2601  main \u2602 \u26a1 \u271a\nPython 3.11.7 (main, Dec 30 2023, 14:03:09) [Clang 15.0.0 (clang-1500.1.0.2.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import chromadb\n&gt;&gt;&gt; from chromadb.config import Settings\n&gt;&gt;&gt; \n&gt;&gt;&gt; client = chromadb.HttpClient(\n...     settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"admin:password123\"))\n&gt;&gt;&gt; client.heartbeat()  # this should work with or without authentication - it is a public endpoint\n1711990302270211007\n&gt;&gt;&gt; \n&gt;&gt;&gt; client.list_collections()  # this is a protected endpoint and requires authentication\n[]\n</code></pre> <p>Great, now let\u2019s test for our other user:</p> <pre><code>client = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"user1:password123\"))\n</code></pre> <p>Works just as well (logs omitted for brevity).</p> <p>To ensure that our plugin works as expected let\u2019s also test with an user that is not in our <code>server.htpasswd</code> file:</p> <pre><code>client = chromadb.HttpClient(\n    settings=Settings(chroma_client_auth_provider=\"chromadb.auth.basic.BasicAuthClientProvider\",chroma_client_auth_credentials=\"invalid_user:password123\"))\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/__init__.py\", line 197, in HttpClient\n    return ClientCreator(tenant=tenant, database=database, settings=settings)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 144, in __init__\n    self._validate_tenant_database(tenant=tenant, database=database)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 445, in _validate_tenant_database\n    raise e\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 438, in _validate_tenant_database\n    self._admin_client.get_tenant(name=tenant)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/client.py\", line 486, in get_tenant\n    return self._server.get_tenant(name=name)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py\", line 127, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/fastapi.py\", line 200, in get_tenant\n    raise_chroma_error(resp)\n  File \"/Users/tazarov/Library/Caches/pypoetry/virtualenvs/chromadb-multi-user-basic-auth-vIZuPNTE-py3.11/lib/python3.11/site-packages/chromadb/api/fastapi.py\", line 649, in raise_chroma_error\n    raise chroma_error\nchromadb.errors.AuthorizationError: Unauthorized\n</code></pre> <p>As expected, we get auth error when trying to connect to Chroma (the client initialization validates the tenant and DB which are both protected endpoints which raises the exception above).</p>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/","title":"Naive Multi-tenancy Strategies","text":"<p>Single-note Chroma</p> <p>The below strategies are applicable to single-node Chroma only. The strategies require your app to act as both PEP (Policy Enforcement Point)  and PDP (Policy Decision Point) for authorization. This is a naive approach to multi-tenancy and is probably not suited for production environments, however it is a good and simple way to get started with multi-tenancy in Chroma.</p> <p>Authorization</p> <p>We are in the process of creating a list of articles on how to implement proper authorization in Chroma,  leveraging the an external service and Chroma's auth plugins. The first article of the series is available in  Medium  and will also be made available here soon.</p>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#introduction","title":"Introduction","text":"<p>There are several multi-tenancy strategies available to users of Chroma. The actual strategy will depend on the needs of the user and the application. The strategies below apply to multi-user environments, but do no factor in partly-shared resources like groups or teams.</p> <ul> <li>User-Per-Doc: In this scenario, the app maintains multiple collections and each collection document is associated   with a single user.</li> <li>User-Per-Collection: In this scenario, the app maintains multiple collections and each collection is   associated with a single user.</li> <li>User-Per-Database: In this scenario, the app maintains multiple databases with a single tenant and each database   is   associated with a single user.</li> <li>User-Per-Tenant: In this scenario, the app maintains multiple tenants and each tenant is associated with a single   user.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-doc","title":"User-Per-Doc","text":"<p>The goal of this strategy is to grant user permissions to access individual documents.</p> <p></p> <p>To implement this strategy you need to add some sort of user identification to each document that belongs to a user. For this example we will assume it is <code>user_id</code>.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient()\ncollection = client.get_or_create_collection(\"my-collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    metadatas=[{\"user_id\": \"user1\"}, {\"user_id\": \"user2\"}],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>At query time you will have to provide the <code>user_id</code> as a filter to your query like so:</p> <pre><code>results = collection.query(\n    query_texts=[\"This is a query document\"],\n    where=[{\"user_id\": \"user1\"}],\n)\n</code></pre> <p>To successfully implement this strategy your code needs to consistently add and filter on the <code>user_id</code> metadata to ensure separation of data.</p> <p>Drawbacks:</p> <ul> <li>Error-prone: Messing up the filtering can lead to data being leaked across users.</li> <li>Scalability: As the number of users and documents grow, doing filtering on metadata can become slow.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-collection","title":"User-Per-Collection","text":"<p>The goal of this strategy is to grant a user access to all documents in a collection.</p> <p></p> <p>To implement this strategy you need to create a collection for each user. For this example we will assume it is <code>user_id</code>.</p> <pre><code>import chromadb\n\nclient = chromadb.PersistentClient()\nuser_id = \"user1\"\ncollection = client.get_or_create_collection(f\"user-collection:{user_id}\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>At query time you will have to provide the <code>user_id</code> as a filter to your query like so:</p> <pre><code>user_id = \"user1\"\nuser_collection = client.get_collection(f\"user-collection:{user_id}\")\nresults = user_collection.query(\n    query_texts=[\"This is a query document\"],\n)\n</code></pre> <p>To successfully implement this strategy your code needs to consistently create and query the correct collection for the user.</p> <p>Drawbacks:</p> <ul> <li>Error-prone: Messing up the collection name can lead to data being leaked across users.</li> <li>Shared document search: If you want to maintain some documents shared then you will have to create a separate   collection for those documents and allow users to query the shared collection as well.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-database","title":"User-Per-Database","text":"<p>The goal of this strategy is to associate a user with a single database thus granting them access to all collections and documents within the database.</p> <p></p> <pre><code>import chromadb\nfrom chromadb import DEFAULT_TENANT\nfrom chromadb import Settings\n\nadminClient = chromadb.AdminClient(Settings(\n    is_persistent=True,\n    persist_directory=\"multitenant\",\n))\n\n\n# For Remote Chroma server:\n# \n# adminClient= chromadb.AdminClient(Settings(\n#   chroma_api_impl=\"chromadb.api.fastapi.FastAPI\",\n#   chroma_server_host=\"localhost\",\n#   chroma_server_http_port=\"8000\",\n# ))\n\ndef get_or_create_db_for_user(user_id):\n    database = f\"db:{user_id}\"\n    try:\n        adminClient.get_database(database)\n    except Exception as e:\n        adminClient.create_database(database, DEFAULT_TENANT)\n    return DEFAULT_TENANT, database\n\n\nuser_id = \"user_John\"\n\ntenant, database = get_or_create_db_for_user(user_id)\n# replace with chromadb.HttpClient for remote Chroma server\nclient = chromadb.PersistentClient(path=\"multitenant\", tenant=tenant, database=database)\ncollection = client.get_or_create_collection(\"user_collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>In the above code we do the following:</p> <ul> <li>We create or get a database for each user in the <code>DEFAULT_TENANT</code> using the <code>chromadb.AdminClient</code>.</li> <li>We then create a <code>PersistentClient</code> for each user with the <code>tenant</code> and <code>database</code> we got from the <code>AdminClient</code>.</li> <li>We then create or get collection and add data to it.</li> </ul> <p>Drawbacks:</p> <ul> <li>This strategy requires consistent management of tenants and databases and their use in the client application.</li> </ul>"},{"location":"strategies/multi-tenancy/naive-multi-tenancy/#user-per-tenant","title":"User-Per-Tenant","text":"<p>The goal of this strategy is to associate a user with a single tenant thus granting them access to all databases, collections, and documents within the tenant.</p> <p></p> <pre><code>import chromadb\nfrom chromadb import DEFAULT_DATABASE\nfrom chromadb import Settings\n\nadminClient = chromadb.AdminClient(Settings(\n    chroma_api_impl=\"chromadb.api.segment.SegmentAPI\",\n    is_persistent=True,\n    persist_directory=\"multitenant\",\n))\n\n\n# For Remote Chroma server:\n# \n# adminClient= chromadb.AdminClient(Settings(\n#   chroma_api_impl=\"chromadb.api.fastapi.FastAPI\",\n#   chroma_server_host=\"localhost\",\n#   chroma_server_http_port=\"8000\",\n# ))\n\ndef get_or_create_tenant_for_user(user_id):\n    tenant_id = f\"tenant_user:{user_id}\"\n    try:\n        adminClient.get_tenant(tenant_id)\n    except Exception as e:\n        adminClient.create_tenant(tenant_id)\n        adminClient.create_database(DEFAULT_DATABASE, tenant_id)\n    return tenant_id, DEFAULT_DATABASE\n\n\nuser_id = \"user1\"\n\ntenant, database = get_or_create_tenant_for_user(user_id)\n# replace with chromadb.HttpClient for remote Chroma server\nclient = chromadb.PersistentClient(path=\"multitenant\", tenant=tenant, database=database)\ncollection = client.get_or_create_collection(\"user_collection\")\ncollection.add(\n    documents=[\"This is document1\", \"This is document2\"],\n    ids=[\"doc1\", \"doc2\"],\n)\n</code></pre> <p>In the above code we do the following:</p> <ul> <li>We create or get a tenant for each user with <code>DEFAULT_DATABASE</code> using the <code>chromadb.AdminClient</code>.</li> <li>We then create a <code>PersistentClient</code> for each user with the <code>tenant</code> and <code>database</code> we got from the <code>AdminClient</code>.</li> <li>We then create or get collection and add data to it.</li> </ul> <p>Drawbacks:</p> <ul> <li>This strategy requires consistent management of tenants and databases and their use in the client application.</li> </ul>"}]}